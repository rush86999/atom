# Environment variables for the Ingestion Pipeline

# Required for Notion API access by notion_extractor.py
NOTION_API_KEY="your_notion_api_key_here"

# Required: The ID of the Notion Database containing transcripts/notes to be ingested.
NOTION_TRANSCRIPTS_DATABASE_ID="your_notion_database_id_for_transcripts"

# Required for OpenAI API access by text_processor.py (for generating embeddings)
OPENAI_API_KEY="sk-your_openai_api_key_here"

# Required for LanceDB connection by lancedb_handler.py and query services.
# This should point to a directory that will be used to store LanceDB data.
# If running in Docker, this path is INSIDE the container.
# A volume should be mounted to this path for persistence.
LANCEDB_URI="/app/lance_data/atom_core_db"
# Example for local Docker volume: mount ./lance_db_data_host:/app/lance_data

# Optional: Custom name for the LanceDB table. Defaults to 'meeting_transcripts_embeddings'.
# LANCEDB_TABLE_NAME="custom_embeddings_table"

# Required: The Atom user ID to associate with the ingested data.
# For a single-user setup or a pipeline dedicated to one user's data.
ATOM_USER_ID_FOR_INGESTION="default_atom_user_id"

# Optional: Processing mode for the pipeline.
# "incremental" (default): Only processes new or updated Notion pages based on last edit times.
# "full": Re-processes all pages from the Notion database.
PROCESSING_MODE="incremental"

# Optional: Logging level for the pipeline scripts (e.g., DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL="INFO"
