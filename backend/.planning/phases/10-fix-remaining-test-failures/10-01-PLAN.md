---
phase: 10-fix-remaining-test-failures
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/conftest.py
  - tests/test_webhook_bridge.py
  - tests/test_browser_agent_ai.py
autonomous: true

must_haves:
  truths:
    - "All tests collect successfully without TypeError from Hypothesis"
    - "Property tests run without isinstance() errors"
    - "Test suite collects all 10,000+ tests"
  artifacts:
    - path: "tests/conftest.py"
      provides: "Fixed module restoration for numpy/pandas/lancedb"
      contains: "MagicMock"
    - path: "tests/test_webhook_bridge.py"
      provides: "Fixed mocking approach"
      min_lines: 40
  key_links:
    - from: "tests/conftest.py"
      to: "sys.modules"
      via: "Module restoration logic"
      pattern: "sys\\.modules\\[.*\\]\\s*=\\s*None|MagicMock"
---

<objective>
Fix collection errors preventing property tests from being discovered.

Root cause: `test_webhook_bridge.py` and `test_browser_agent_ai.py` set `sys.modules["numpy"] = MagicMock()`, which causes Hypothesis's internal `check_sample()` to fail with `TypeError: isinstance() arg 2 must be a type`. This happens because `MagicMock().ndarray` is also a MagicMock, not a type.

The existing conftest.py only handles modules set to `None`, not MagicMock objects. We need to restore these modules to real objects before Hypothesis tries to use them.

Purpose: Enable property test collection so full test suite can run
Output: All 10,176 tests collect successfully
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/09-test-suite-stabilization/PHASE-09-COMPLETE.md
@.planning/ROADMAP.md

Key issue from Phase 09 completion:
- Property tests collect successfully when run in isolation
- Full test suite collection fails with `TypeError: isinstance() arg 2 must be a type`
- Error originates from Hypothesis's check_sample() function
- Two test files mock numpy/pandas/lancedb with MagicMock()
</context>

<tasks>

<task type="auto">
  <name>Fix conftest.py module restoration to handle MagicMock</name>
  <files>tests/conftest.py</files>
  <action>
  Update the module-level module restoration loop in conftest.py (lines 25-27) to also remove MagicMock objects:

  ```python
  for mod in ["numpy", "pandas", "lancedb", "pyarrow"]:
      if mod in sys.modules:
          module = sys.modules[mod]
          # Remove if set to None OR mocked as MagicMock
          if module is None or hasattr(module, '_spec_class'):
              sys.modules.pop(mod, None)
  ```

  Also update the ensure_numpy_available fixture (lines 50-53) with the same logic.

  This works because MagicMock has a _spec_class attribute that real modules don't have. By removing the mocked modules, subsequent imports will load the real module.
  </action>
  <verify>PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/property_tests/ --collect-only -q 2>&1 | grep "tests collected"</verify>
  <done>Property tests collect without TypeError</done>
</task>

<task type="auto">
  <name>Verify full test suite collection succeeds</name>
  <files>tests/conftest.py</files>
  <action>
  Run full test suite collection to verify all tests collect successfully:

  ```bash
  PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/ --collect-only -q 2>&1 | tail -20
  ```

  Expected output should show:
  - "collected" with count >= 10000
  - No "ERROR collecting" messages
  - No "TypeError: isinstance()" errors
  </action>
  <verify>PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/ --collect-only 2>&1 | grep -E "(collected|ERROR)" | tail -5</verify>
  <done>All 10,176+ tests collect successfully with 0 errors</done>
</task>

<task type="auto">
  <name>Run property tests to verify they execute correctly</name>
  <files>tests/property_tests/conftest.py</files>
  <action>
  Run a sample of property tests to verify they not only collect but also execute:

  ```bash
  PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/property_tests/analytics/test_analytics_invariants.py -v --tb=short 2>&1 | head -50
  ```

  Then run all property tests to verify no collection or execution errors:

  ```bash
  PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/property_tests/ -v --tb=short 2>&1 | tail -30
  ```

  Expected output should show:
  - Tests marked as PASSED, not ERROR
  - No TypeError messages
  - Property tests running with Hypothesis
  </action>
  <verify>PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/property_tests/ -q 2>&1 | grep -E "(passed|ERROR|failed)"</verify>
  <done>Property tests execute without TypeError, all collect and run</done>
</task>

</tasks>

<verification>
1. Full test suite collection completes with 0 errors
2. Property tests collect and execute successfully
3. No isinstance() TypeError in output
4. All 10,176+ tests are discoverable
</verification>

<success_criteria>
- pytest --collect-only shows >= 10,000 tests collected
- No "ERROR collecting" messages in output
- Property tests execute without TypeError
- Full test suite can be run (not just collect)
</success_criteria>

<output>
After completion, create `.planning/phases/10-fix-remaining-test-failures/10-01-SUMMARY.md`
</output>
