"""
Google Drive Automation Workflow Service
Integration with ATOM's automation workflow engine for Google Drive events
"""

import json
import logging
import asyncio
import re
from datetime import datetime, timezone, timedelta
from typing import Dict, Any, List, Optional, Callable, Union, Set
from dataclasses import dataclass, field
from enum import Enum
from loguru import logger

# Google Drive imports
from google_drive_service import GoogleDriveService, GoogleDriveFile
from google_drive_realtime_sync import RealtimeSyncEvent, RealtimeSyncEventType

# ATOM automation imports
from automation.workflow_engine import WorkflowEngine
from automation.trigger_manager import TriggerManager
from automation.action_executor import ActionExecutor
from automation.workflow_scheduler import WorkflowScheduler

class TriggerType(Enum):
    """Trigger types for Google Drive automation"""
    FILE_CREATED = "file_created"
    FILE_UPDATED = "file_updated"
    FILE_DELETED = "file_deleted"
    FILE_MOVED = "file_moved"
    FILE_SHARED = "file_shared"
    FOLDER_CREATED = "folder_created"
    FOLDER_UPDATED = "folder_updated"
    FOLDER_DELETED = "folder_deleted"
    FOLDER_MOVED = "folder_moved"
    PERMISSION_CHANGED = "permission_changed"
    SCHEDULE = "schedule"
    MANUAL = "manual"

class ActionType(Enum):
    """Action types for Google Drive automation"""
    # File operations
    COPY_FILE = "copy_file"
    MOVE_FILE = "move_file"
    DELETE_FILE = "delete_file"
    RENAME_FILE = "rename_file"
    CREATE_FOLDER = "create_folder"
    SHARE_FILE = "share_file"
    UNSHARE_FILE = "unshare_file"
    
    # Content operations
    EXTRACT_TEXT = "extract_text"
    COMPRESS_FILE = "compress_file"
    CONVERT_FILE = "convert_file"
    WATERMARK_FILE = "watermark_file"
    ENCRYPT_FILE = "encrypt_file"
    DECRYPT_FILE = "decrypt_file"
    
    # Integration operations
    SEND_EMAIL = "send_email"
    POST_TO_SLACK = "post_to_slack"
    ADD_TO_TRELLO = "add_to_trello"
    CREATE_JIRA_TICKET = "create_jira_ticket"
    UPDATE_DATABASE = "update_database"
    CALL_WEBHOOK = "call_webhook"
    EXECUTE_SCRIPT = "execute_script"
    
    # Workflow operations
    START_WORKFLOW = "start_workflow"
    STOP_WORKFLOW = "stop_workflow"
    DELAY = "delay"
    CONDITION_CHECK = "condition_check"
    PARALLEL_EXECUTION = "parallel_execution"

class Operator(Enum):
    """Operators for conditions"""
    EQUALS = "equals"
    NOT_EQUALS = "not_equals"
    CONTAINS = "contains"
    NOT_CONTAINS = "not_contains"
    STARTS_WITH = "starts_with"
    ENDS_WITH = "ends_with"
    GREATER_THAN = "greater_than"
    LESS_THAN = "less_than"
    GREATER_EQUAL = "greater_equal"
    LESS_EQUAL = "less_equal"
    REGEX_MATCH = "regex_match"
    IN = "in"
    NOT_IN = "not_in"
    IS_EMPTY = "is_empty"
    IS_NOT_EMPTY = "is_not_empty"
    IS_TRUE = "is_true"
    IS_FALSE = "is_false"

class ConditionLogic(Enum):
    """Logic for combining conditions"""
    AND = "and"
    OR = "or"
    NOT = "not"

@dataclass
class AutomationTrigger:
    """Automation trigger model"""
    id: str
    type: TriggerType
    config: Dict[str, Any]
    conditions: List[Dict[str, Any]] = field(default_factory=list)
    enabled: bool = True
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class AutomationAction:
    """Automation action model"""
    id: str
    type: ActionType
    config: Dict[str, Any]
    retry_count: int = 0
    max_retries: int = 3
    timeout: int = 300  # seconds
    enabled: bool = True
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class AutomationWorkflow:
    """Automation workflow model"""
    id: str
    name: str
    description: str
    user_id: str
    triggers: List[AutomationTrigger] = field(default_factory=list)
    actions: List[AutomationAction] = field(default_factory=list)
    enabled: bool = True
    run_count: int = 0
    success_count: int = 0
    error_count: int = 0
    last_run: Optional[datetime] = None
    last_success: Optional[datetime] = None
    last_error: Optional[datetime] = None
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    updated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

@dataclass
class WorkflowExecution:
    """Workflow execution model"""
    id: str
    workflow_id: str
    user_id: str
    trigger_type: TriggerType
    trigger_data: Dict[str, Any]
    status: str = "pending"  # pending, running, completed, failed, cancelled
    started_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    completed_at: Optional[datetime] = None
    duration: Optional[float] = None
    input_data: Dict[str, Any] = field(default_factory=dict)
    output_data: Dict[str, Any] = field(default_factory=dict)
    error_message: Optional[str] = None
    actions_executed: List[str] = field(default_factory=list)
    logs: List[str] = field(default_factory=list)
    variables: Dict[str, Any] = field(default_factory=dict)

@dataclass
class WorkflowTemplate:
    """Workflow template model"""
    id: str
    name: str
    description: str
    category: str
    triggers: List[Dict[str, Any]] = field(default_factory=list)
    actions: List[Dict[str, Any]] = field(default_factory=list)
    variables: List[Dict[str, Any]] = field(default_factory=list)
    icon: str = ""
    tags: List[str] = field(default_factory=list)
    public: bool = False
    created_by: str = ""
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    usage_count: int = 0

class GoogleDriveAutomationService:
    """Google Drive automation workflow service"""
    
    def __init__(
        self,
        drive_service: GoogleDriveService,
        workflow_engine: WorkflowEngine,
        trigger_manager: TriggerManager,
        action_executor: ActionExecutor,
        workflow_scheduler: WorkflowScheduler,
        db_pool=None
    ):
        self.drive_service = drive_service
        self.workflow_engine = workflow_engine
        self.trigger_manager = trigger_manager
        self.action_executor = action_executor
        self.workflow_scheduler = workflow_scheduler
        self.db_pool = db_pool
        
        # Storage
        self.workflows: Dict[str, AutomationWorkflow] = {}
        self.executions: Dict[str, WorkflowExecution] = {}
        self.templates: Dict[str, WorkflowTemplate] = {}
        
        # Event handlers
        self.event_handlers: List[Callable] = []
        self.active_executions: Dict[str, asyncio.Task] = {}
        
        # Configuration
        self.max_concurrent_executions = 10
        self.default_timeout = 300  # seconds
        self.cleanup_interval = timedelta(hours=1)
        self.max_execution_history = 10000
        
        # Statistics
        self.total_executions = 0
        self.total_errors = 0
        self.active_workflows = 0
        
        # Background tasks
        self.background_tasks: List[asyncio.Task] = []
        self.running = False
        
        # Initialize built-in templates
        self._initialize_builtin_templates()
        
        logger.info("Google Drive Automation Service initialized")
    
    def start(self):
        """Start automation service"""
        if self.running:
            return
        
        self.running = True
        logger.info("Starting Google Drive Automation Service")
        
        # Start background tasks
        self.background_tasks = [
            asyncio.create_task(self._cleanup_worker()),
            asyncio.create_task(self._execution_monitor()),
            asyncio.create_task(self._scheduled_trigger_worker())
        ]
        
        # Register event handlers
        self._register_event_handlers()
        
        logger.info(f"Started {len(self.background_tasks)} background tasks")
    
    def stop(self):
        """Stop automation service"""
        if not self.running:
            return
        
        self.running = False
        logger.info("Stopping Google Drive Automation Service")
        
        # Cancel background tasks
        for task in self.background_tasks:
            if not task.done():
                task.cancel()
        
        # Cancel active executions
        for task in self.active_executions.values():
            if not task.done():
                task.cancel()
        
        logger.info("Google Drive Automation Service stopped")
    
    def register_event_handler(self, handler: Callable):
        """Register event handler"""
        self.event_handlers.append(handler)
        logger.info("Registered automation event handler")
    
    async def create_workflow(
        self,
        user_id: str,
        name: str,
        description: str,
        triggers: List[Dict[str, Any]],
        actions: List[Dict[str, Any]],
        enabled: bool = True
    ) -> AutomationWorkflow:
        """Create new automation workflow"""
        
        try:
            workflow_id = self._generate_workflow_id()
            
            # Convert triggers and actions to objects
            trigger_objects = []
            for trigger_data in triggers:
                trigger = AutomationTrigger(
                    id=self._generate_trigger_id(),
                    type=TriggerType(trigger_data["type"]),
                    config=trigger_data.get("config", {}),
                    conditions=trigger_data.get("conditions", []),
                    enabled=trigger_data.get("enabled", True)
                )
                trigger_objects.append(trigger)
            
            action_objects = []
            for action_data in actions:
                action = AutomationAction(
                    id=self._generate_action_id(),
                    type=ActionType(action_data["type"]),
                    config=action_data.get("config", {}),
                    retry_count=action_data.get("retry_count", 0),
                    max_retries=action_data.get("max_retries", 3),
                    timeout=action_data.get("timeout", self.default_timeout),
                    enabled=action_data.get("enabled", True)
                )
                action_objects.append(action)
            
            # Create workflow
            workflow = AutomationWorkflow(
                id=workflow_id,
                name=name,
                description=description,
                user_id=user_id,
                triggers=trigger_objects,
                actions=action_objects,
                enabled=enabled
            )
            
            # Store workflow
            self.workflows[workflow_id] = workflow
            
            # Store in database
            if self.db_pool:
                await self._store_workflow_in_db(workflow, self.db_pool)
            
            # Register triggers with trigger manager
            await self._register_workflow_triggers(workflow)
            
            # Update statistics
            self.active_workflows += 1
            
            logger.info(f"Created automation workflow: {workflow_id} - {name}")
            
            return workflow
        
        except Exception as e:
            logger.error(f"Error creating workflow: {e}")
            raise
    
    async def update_workflow(
        self,
        workflow_id: str,
        updates: Dict[str, Any]
    ) -> bool:
        """Update automation workflow"""
        
        try:
            if workflow_id not in self.workflows:
                return False
            
            workflow = self.workflows[workflow_id]
            
            # Apply updates
            for key, value in updates.items():
                if key in ["name", "description", "enabled"]:
                    setattr(workflow, key, value)
                elif key == "triggers":
                    # Update triggers
                    workflow.triggers = []
                    for trigger_data in value:
                        trigger = AutomationTrigger(
                            id=self._generate_trigger_id(),
                            type=TriggerType(trigger_data["type"]),
                            config=trigger_data.get("config", {}),
                            conditions=trigger_data.get("conditions", []),
                            enabled=trigger_data.get("enabled", True)
                        )
                        workflow.triggers.append(trigger)
                elif key == "actions":
                    # Update actions
                    workflow.actions = []
                    for action_data in value:
                        action = AutomationAction(
                            id=self._generate_action_id(),
                            type=ActionType(action_data["type"]),
                            config=action_data.get("config", {}),
                            retry_count=action_data.get("retry_count", 0),
                            max_retries=action_data.get("max_retries", 3),
                            timeout=action_data.get("timeout", self.default_timeout),
                            enabled=action_data.get("enabled", True)
                        )
                        workflow.actions.append(action)
            
            workflow.updated_at = datetime.now(timezone.utc)
            
            # Update in database
            if self.db_pool:
                await self._store_workflow_in_db(workflow, self.db_pool)
            
            # Re-register triggers
            await self._register_workflow_triggers(workflow)
            
            logger.info(f"Updated automation workflow: {workflow_id}")
            
            return True
        
        except Exception as e:
            logger.error(f"Error updating workflow {workflow_id}: {e}")
            return False
    
    async def delete_workflow(self, workflow_id: str) -> bool:
        """Delete automation workflow"""
        
        try:
            if workflow_id not in self.workflows:
                return False
            
            workflow = self.workflows[workflow_id]
            
            # Unregister triggers
            await self._unregister_workflow_triggers(workflow)
            
            # Cancel active executions
            active_executions = [
                execution_id for execution_id, execution in self.executions.items()
                if execution.workflow_id == workflow_id and execution.status == "running"
            ]
            
            for execution_id in active_executions:
                await self._cancel_execution(execution_id)
            
            # Remove from storage
            del self.workflows[workflow_id]
            
            # Remove from database
            if self.db_pool:
                await self._delete_workflow_from_db(workflow_id, self.db_pool)
            
            # Update statistics
            self.active_workflows = max(0, self.active_workflows - 1)
            
            logger.info(f"Deleted automation workflow: {workflow_id}")
            
            return True
        
        except Exception as e:
            logger.error(f"Error deleting workflow {workflow_id}: {e}")
            return False
    
    async def execute_workflow(
        self,
        workflow_id: str,
        trigger_type: TriggerType,
        trigger_data: Dict[str, Any],
        manual_trigger: bool = False
    ) -> Optional[WorkflowExecution]:
        """Execute automation workflow"""
        
        try:
            if workflow_id not in self.workflows:
                logger.error(f"Workflow not found: {workflow_id}")
                return None
            
            workflow = self.workflows[workflow_id]
            
            # Check if workflow is enabled
            if not workflow.enabled and not manual_trigger:
                logger.info(f"Workflow {workflow_id} is disabled")
                return None
            
            # Check concurrent execution limit
            running_executions = len([
                exec for exec in self.executions.values()
                if exec.status == "running"
            ])
            
            if running_executions >= self.max_concurrent_executions:
                logger.warning(f"Max concurrent executions reached: {running_executions}")
                return None
            
            # Create execution
            execution_id = self._generate_execution_id()
            execution = WorkflowExecution(
                id=execution_id,
                workflow_id=workflow_id,
                user_id=workflow.user_id,
                trigger_type=trigger_type,
                trigger_data=trigger_data,
                input_data=trigger_data.copy()
            )
            
            # Store execution
            self.executions[execution_id] = execution
            
            # Store in database
            if self.db_pool:
                await self._store_execution_in_db(execution, self.db_pool)
            
            # Start execution task
            task = asyncio.create_task(
                self._execute_workflow_task(execution, workflow)
            )
            self.active_executions[execution_id] = task
            
            # Update statistics
            self.total_executions += 1
            workflow.run_count += 1
            workflow.last_run = datetime.now(timezone.utc)
            
            logger.info(f"Started workflow execution: {execution_id} ({workflow.name})")
            
            return execution
        
        except Exception as e:
            logger.error(f"Error executing workflow {workflow_id}: {e}")
            return None
    
    async def handle_drive_event(self, event: RealtimeSyncEvent) -> None:
        """Handle Google Drive sync event"""
        
        try:
            # Find matching workflows
            matching_workflows = await self._find_matching_workflows(event)
            
            logger.info(f"Found {len(matching_workflows)} matching workflows for event: {event.event_type.value}")
            
            # Execute matching workflows
            for workflow in matching_workflows:
                # Convert event type
                trigger_type_map = {
                    RealtimeSyncEventType.FILE_CREATED: TriggerType.FILE_CREATED,
                    RealtimeSyncEventType.FILE_UPDATED: TriggerType.FILE_UPDATED,
                    RealtimeSyncEventType.FILE_DELETED: TriggerType.FILE_DELETED,
                    RealtimeSyncEventType.FILE_MOVED: TriggerType.FILE_MOVED,
                    RealtimeSyncEventType.FILE_SHARED: TriggerType.FILE_SHARED,
                    RealtimeSyncEventType.FOLDER_CREATED: TriggerType.FOLDER_CREATED,
                    RealtimeSyncEventType.FOLDER_UPDATED: TriggerType.FOLDER_UPDATED,
                    RealtimeSyncEventType.FOLDER_DELETED: TriggerType.FOLDER_DELETED,
                    RealtimeSyncEventType.FOLDER_MOVED: TriggerType.FOLDER_MOVED,
                    RealtimeSyncEventType.PERMISSION_CHANGED: TriggerType.PERMISSION_CHANGED,
                }
                
                trigger_type = trigger_type_map.get(
                    event.event_type, TriggerType.FILE_UPDATED
                )
                
                # Prepare trigger data
                trigger_data = {
                    "file_id": event.file_id,
                    "file_name": event.file_name,
                    "mime_type": event.mime_type,
                    "user_id": event.user_id,
                    "timestamp": event.timestamp.isoformat(),
                    "old_name": event.old_name,
                    "new_name": event.new_name,
                    "old_parent_ids": event.old_parent_ids,
                    "new_parent_ids": event.new_parent_ids,
                    "old_shared": event.old_shared,
                    "new_shared": event.new_shared,
                    "content_hash": event.content_hash,
                    "change_id": event.change_id
                }
                
                # Execute workflow
                await self.execute_workflow(
                    workflow.id,
                    trigger_type,
                    trigger_data
                )
        
        except Exception as e:
            logger.error(f"Error handling drive event: {e}")
    
    async def get_workflows(
        self,
        user_id: Optional[str] = None,
        enabled_only: bool = False
    ) -> List[AutomationWorkflow]:
        """Get automation workflows"""
        
        workflows = list(self.workflows.values())
        
        # Filter by user
        if user_id:
            workflows = [w for w in workflows if w.user_id == user_id]
        
        # Filter by enabled status
        if enabled_only:
            workflows = [w for w in workflows if w.enabled]
        
        return workflows
    
    async def get_workflow(self, workflow_id: str) -> Optional[AutomationWorkflow]:
        """Get specific workflow"""
        return self.workflows.get(workflow_id)
    
    async def get_executions(
        self,
        workflow_id: Optional[str] = None,
        user_id: Optional[str] = None,
        status: Optional[str] = None,
        limit: int = 50
    ) -> List[WorkflowExecution]:
        """Get workflow executions"""
        
        executions = list(self.executions.values())
        
        # Apply filters
        if workflow_id:
            executions = [e for e in executions if e.workflow_id == workflow_id]
        
        if user_id:
            executions = [e for e in executions if e.user_id == user_id]
        
        if status:
            executions = [e for e in executions if e.status == status]
        
        # Sort by started_at (newest first) and limit
        executions.sort(key=lambda e: e.started_at, reverse=True)
        
        return executions[:limit]
    
    async def get_execution(self, execution_id: str) -> Optional[WorkflowExecution]:
        """Get specific execution"""
        return self.executions.get(execution_id)
    
    async def create_template(
        self,
        name: str,
        description: str,
        category: str,
        triggers: List[Dict[str, Any]],
        actions: List[Dict[str, Any]],
        variables: Optional[List[Dict[str, Any]]] = None,
        icon: str = "",
        tags: Optional[List[str]] = None,
        public: bool = False,
        created_by: str = ""
    ) -> WorkflowTemplate:
        """Create workflow template"""
        
        try:
            template_id = self._generate_template_id()
            
            template = WorkflowTemplate(
                id=template_id,
                name=name,
                description=description,
                category=category,
                triggers=triggers,
                actions=actions,
                variables=variables or [],
                icon=icon,
                tags=tags or [],
                public=public,
                created_by=created_by
            )
            
            # Store template
            self.templates[template_id] = template
            
            # Store in database
            if self.db_pool:
                await self._store_template_in_db(template, self.db_pool)
            
            logger.info(f"Created workflow template: {template_id} - {name}")
            
            return template
        
        except Exception as e:
            logger.error(f"Error creating template: {e}")
            raise
    
    async def get_templates(
        self,
        category: Optional[str] = None,
        public_only: bool = False,
        limit: int = 50
    ) -> List[WorkflowTemplate]:
        """Get workflow templates"""
        
        templates = list(self.templates.values())
        
        # Apply filters
        if category:
            templates = [t for t in templates if t.category == category]
        
        if public_only:
            templates = [t for t in templates if t.public]
        
        # Sort by usage count and limit
        templates.sort(key=lambda t: t.usage_count, reverse=True)
        
        return templates[:limit]
    
    async def create_workflow_from_template(
        self,
        template_id: str,
        user_id: str,
        name: str,
        description: str,
        variable_values: Optional[Dict[str, Any]] = None
    ) -> Optional[AutomationWorkflow]:
        """Create workflow from template"""
        
        try:
            template = self.templates.get(template_id)
            if not template:
                return None
            
            # Apply variable substitutions
            triggers = self._substitute_template_variables(
                template.triggers, variable_values or {}
            )
            
            actions = self._substitute_template_variables(
                template.actions, variable_values or {}
            )
            
            # Create workflow
            workflow = await self.create_workflow(
                user_id=user_id,
                name=name,
                description=description,
                triggers=triggers,
                actions=actions,
                enabled=True
            )
            
            # Update template usage count
            template.usage_count += 1
            if self.db_pool:
                await self._update_template_usage_count(template_id, template.usage_count, self.db_pool)
            
            logger.info(f"Created workflow from template: {template_id} -> {workflow.id}")
            
            return workflow
        
        except Exception as e:
            logger.error(f"Error creating workflow from template {template_id}: {e}")
            return None
    
    def get_automation_statistics(self) -> Dict[str, Any]:
        """Get automation service statistics"""
        
        total_workflows = len(self.workflows)
        enabled_workflows = len([w for w in self.workflows.values() if w.enabled])
        total_templates = len(self.templates)
        public_templates = len([t for t in self.templates.values() if t.public])
        
        # Execution statistics
        total_executions = len(self.executions)
        running_executions = len([
            e for e in self.executions.values() if e.status == "running"
        ])
        completed_executions = len([
            e for e in self.executions.values() if e.status == "completed"
        ])
        failed_executions = len([
            e for e in self.executions.values() if e.status == "failed"
        ])
        
        # Workflow performance
        top_workflows = []
        for workflow in self.workflows.values():
            if workflow.run_count > 0:
                success_rate = (workflow.success_count / workflow.run_count) * 100
                top_workflows.append({
                    "id": workflow.id,
                    "name": workflow.name,
                    "run_count": workflow.run_count,
                    "success_rate": success_rate,
                    "last_run": workflow.last_run.isoformat() if workflow.last_run else None
                })
        
        top_workflows.sort(key=lambda w: w["run_count"], reverse=True)
        
        return {
            "service_running": self.running,
            "workflows": {
                "total": total_workflows,
                "enabled": enabled_workflows,
                "disabled": total_workflows - enabled_workflows,
                "active": self.active_workflows
            },
            "templates": {
                "total": total_templates,
                "public": public_templates,
                "private": total_templates - public_templates
            },
            "executions": {
                "total": total_executions,
                "running": running_executions,
                "completed": completed_executions,
                "failed": failed_executions,
                "total_processed": self.total_executions,
                "total_errors": self.total_errors,
                "success_rate": (
                    (completed_executions / total_executions * 100)
                    if total_executions > 0 else 0
                )
            },
            "top_workflows": top_workflows[:10],
            "active_executions": len(self.active_executions),
            "max_concurrent_executions": self.max_concurrent_executions,
            "background_tasks": len(self.background_tasks)
        }
    
    async def _execute_workflow_task(
        self,
        execution: WorkflowExecution,
        workflow: AutomationWorkflow
    ):
        """Execute workflow task"""
        
        try:
            execution.status = "running"
            execution.variables = execution.input_data.copy()
            
            # Update workflow statistics
            workflow.last_run = execution.started_at
            
            # Log start
            await self._log_execution(execution, "info", f"Started execution of workflow: {workflow.name}")
            
            # Execute actions
            for action in workflow.actions:
                if not action.enabled:
                    continue
                
                if execution.status != "running":
                    break  # Execution was cancelled
                
                try:
                    # Prepare action context
                    action_context = {
                        "execution": execution,
                        "workflow": workflow,
                        "variables": execution.variables,
                        "drive_service": self.drive_service,
                        "user_id": execution.user_id
                    }
                    
                    # Execute action
                    await self._execute_action(action, action_context)
                    
                    execution.actions_executed.append(action.id)
                    await self._log_execution(execution, "info", f"Executed action: {action.type.value}")
                
                except Exception as e:
                    await self._log_execution(execution, "error", f"Action failed: {action.type.value} - {str(e)}")
                    
                    # Check if action should retry
                    if action.retry_count < action.max_retries:
                        action.retry_count += 1
                        await asyncio.sleep(2 ** action.retry_count)  # Exponential backoff
                        
                        # Retry action
                        await self._execute_action(action, action_context)
                        execution.actions_executed.append(action.id)
                        await self._log_execution(execution, "info", f"Retried action: {action.type.value}")
                    else:
                        # Max retries reached, fail execution
                        raise
            
            # Mark as completed
            execution.status = "completed"
            execution.completed_at = datetime.now(timezone.utc)
            execution.duration = (execution.completed_at - execution.started_at).total_seconds()
            
            # Update workflow statistics
            workflow.success_count += 1
            workflow.last_success = execution.completed_at
            
            await self._log_execution(execution, "info", f"Completed execution successfully (duration: {execution.duration:.2f}s)")
            
            # Call event handlers
            for handler in self.event_handlers:
                try:
                    if asyncio.iscoroutinefunction(handler):
                        await handler(execution, workflow)
                    else:
                        handler(execution, workflow)
                except Exception as e:
                    logger.error(f"Event handler error: {e}")
        
        except Exception as e:
            # Mark as failed
            execution.status = "failed"
            execution.completed_at = datetime.now(timezone.utc)
            execution.duration = (execution.completed_at - execution.started_at).total_seconds()
            execution.error_message = str(e)
            
            # Update workflow statistics
            workflow.error_count += 1
            workflow.last_error = execution.completed_at
            
            await self._log_execution(execution, "error", f"Execution failed: {str(e)}")
        
        finally:
            # Clean up
            if execution.id in self.active_executions:
                del self.active_executions[execution.id]
            
            # Update in database
            if self.db_pool:
                await self._update_execution_in_db(execution, self.db_pool)
            
            # Update workflow in database
            if self.db_pool:
                await self._store_workflow_in_db(workflow, self.db_pool)
    
    async def _execute_action(
        self,
        action: AutomationAction,
        context: Dict[str, Any]
    ):
        """Execute specific action"""
        
        execution = context["execution"]
        workflow = context["workflow"]
        variables = context["variables"]
        
        try:
            # Substitute variables in action config
            config = self._substitute_variables(action.config, variables)
            
            if action.type == ActionType.COPY_FILE:
                await self._action_copy_file(config, context)
            
            elif action.type == ActionType.MOVE_FILE:
                await self._action_move_file(config, context)
            
            elif action.type == ActionType.DELETE_FILE:
                await self._action_delete_file(config, context)
            
            elif action.type == ActionType.RENAME_FILE:
                await self._action_rename_file(config, context)
            
            elif action.type == ActionType.CREATE_FOLDER:
                await self._action_create_folder(config, context)
            
            elif action.type == ActionType.SHARE_FILE:
                await self._action_share_file(config, context)
            
            elif action.type == ActionType.UNSHARE_FILE:
                await self._action_unshare_file(config, context)
            
            elif action.type == ActionType.EXTRACT_TEXT:
                await self._action_extract_text(config, context)
            
            elif action.type == ActionType.COMPRESS_FILE:
                await self._action_compress_file(config, context)
            
            elif action.type == ActionType.CONVERT_FILE:
                await self._action_convert_file(config, context)
            
            elif action.type == ActionType.WATERMARK_FILE:
                await self._action_watermark_file(config, context)
            
            elif action.type == ActionType.ENCRYPT_FILE:
                await self._action_encrypt_file(config, context)
            
            elif action.type == ActionType.DECRYPT_FILE:
                await self._action_decrypt_file(config, context)
            
            elif action.type == ActionType.SEND_EMAIL:
                await self._action_send_email(config, context)
            
            elif action.type == ActionType.POST_TO_SLACK:
                await self._action_post_to_slack(config, context)
            
            elif action.type == ActionType.ADD_TO_TRELLO:
                await self._action_add_to_trello(config, context)
            
            elif action.type == ActionType.CREATE_JIRA_TICKET:
                await self._action_create_jira_ticket(config, context)
            
            elif action.type == ActionType.UPDATE_DATABASE:
                await self._action_update_database(config, context)
            
            elif action.type == ActionType.CALL_WEBHOOK:
                await self._action_call_webhook(config, context)
            
            elif action.type == ActionType.EXECUTE_SCRIPT:
                await self._action_execute_script(config, context)
            
            elif action.type == ActionType.START_WORKFLOW:
                await self._action_start_workflow(config, context)
            
            elif action.type == ActionType.STOP_WORKFLOW:
                await self._action_stop_workflow(config, context)
            
            elif action.type == ActionType.DELAY:
                await self._action_delay(config, context)
            
            elif action.type == ActionType.CONDITION_CHECK:
                await self._action_condition_check(config, context)
            
            elif action.type == ActionType.PARALLEL_EXECUTION:
                await self._action_parallel_execution(config, context)
            
            else:
                raise ValueError(f"Unsupported action type: {action.type}")
        
        except Exception as e:
            await self._log_execution(execution, "error", f"Action {action.type.value} failed: {str(e)}")
            raise
    
    async def _action_copy_file(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Copy file action"""
        file_id = config["file_id"]
        new_name = config.get("new_name")
        parent_ids = config.get("parent_ids", [])
        
        drive_service = context["drive_service"]
        user_id = context["user_id"]
        
        copied_file = await drive_service.copy_file(
            user_id=user_id,
            file_id=file_id,
            name=new_name,
            parents=parent_ids
        )
        
        if copied_file:
            # Update variables
            context["variables"]["copied_file_id"] = copied_file.id
            context["variables"]["copied_file_name"] = copied_file.name
            context["variables"]["copied_file_url"] = copied_file.web_view_link
        else:
            raise Exception("Failed to copy file")
    
    async def _action_move_file(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Move file action"""
        file_id = config["file_id"]
        add_parents = config.get("add_parents", [])
        remove_parents = config.get("remove_parents", [])
        
        drive_service = context["drive_service"]
        user_id = context["user_id"]
        
        moved_file = await drive_service.move_file(
            user_id=user_id,
            file_id=file_id,
            add_parents=add_parents,
            remove_parents=remove_parents
        )
        
        if not moved_file:
            raise Exception("Failed to move file")
    
    async def _action_delete_file(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Delete file action"""
        file_id = config["file_id"]
        
        drive_service = context["drive_service"]
        user_id = context["user_id"]
        
        success = await drive_service.delete_file(
            user_id=user_id,
            file_id=file_id
        )
        
        if not success:
            raise Exception("Failed to delete file")
    
    async def _action_rename_file(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Rename file action"""
        file_id = config["file_id"]
        new_name = config["new_name"]
        
        drive_service = context["drive_service"]
        user_id = context["user_id"]
        
        renamed_file = await drive_service.update_file(
            user_id=user_id,
            file_id=file_id,
            name=new_name
        )
        
        if renamed_file:
            # Update variables
            context["variables"]["renamed_file_name"] = renamed_file.name
        else:
            raise Exception("Failed to rename file")
    
    async def _action_create_folder(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Create folder action"""
        name = config["name"]
        parent_ids = config.get("parent_ids", [])
        
        drive_service = context["drive_service"]
        user_id = context["user_id"]
        
        created_folder = await drive_service.create_file(
            user_id=user_id,
            name=name,
            mime_type="application/vnd.google-apps.folder",
            parents=parent_ids
        )
        
        if created_folder:
            # Update variables
            context["variables"]["created_folder_id"] = created_folder.id
            context["variables"]["created_folder_name"] = created_folder.name
            context["variables"]["created_folder_url"] = created_folder.web_view_link
        else:
            raise Exception("Failed to create folder")
    
    async def _action_send_email(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Send email action"""
        to = config["to"]
        subject = config["subject"]
        body = config["body"]
        attachments = config.get("attachments", [])
        
        # This would integrate with email service
        # For now, just log the action
        await self._log_execution(
            context["execution"],
            "info",
            f"Would send email to {to}: {subject}"
        )
        
        # Update variables
        context["variables"]["email_sent"] = True
        context["variables"]["email_recipients"] = to
    
    async def _action_post_to_slack(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Post to Slack action"""
        channel = config["channel"]
        message = config["message"]
        attachments = config.get("attachments", [])
        
        # This would integrate with Slack API
        # For now, just log the action
        await self._log_execution(
            context["execution"],
            "info",
            f"Would post to Slack channel {channel}: {message}"
        )
        
        # Update variables
        context["variables"]["slack_message_id"] = "mock_message_id"
        context["variables"]["slack_channel"] = channel
    
    async def _action_delay(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Delay action"""
        duration = config["duration"]
        
        await self._log_execution(
            context["execution"],
            "info",
            f"Delaying execution for {duration} seconds"
        )
        
        await asyncio.sleep(duration)
        
        # Update variables
        context["variables"]["delay_completed"] = True
    
    async def _action_condition_check(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Condition check action"""
        conditions = config["conditions"]
        logic = config.get("logic", "and")
        
        result = await self._evaluate_conditions(conditions, logic, context)
        
        # Update variables
        context["variables"]["condition_result"] = result
        context["variables"]["condition_check_passed"] = result
        
        if not result:
            # Stop execution if condition fails
            context["execution"].status = "completed"
            await self._log_execution(
                context["execution"],
                "info",
                "Execution stopped due to failed condition check"
            )
    
    async def _action_start_workflow(self, config: Dict[str, Any], context: Dict[str, Any]):
        """Start workflow action"""
        workflow_id = config["workflow_id"]
        trigger_data = config.get("trigger_data", {})
        
        # Start workflow
        execution = await self.execute_workflow(
            workflow_id,
            TriggerType.MANUAL,
            trigger_data
        )
        
        if execution:
            # Update variables
            context["variables"]["started_workflow_id"] = workflow_id
            context["variables"]["started_execution_id"] = execution.id
        else:
            raise Exception(f"Failed to start workflow: {workflow_id}")
    
    async def _evaluate_conditions(
        self,
        conditions: List[Dict[str, Any]],
        logic: str,
        context: Dict[str, Any]
    ) -> bool:
        """Evaluate conditions"""
        
        results = []
        
        for condition in conditions:
            field = condition["field"]
            operator = Operator(condition["operator"])
            value = condition["value"]
            
            # Get field value from context
            field_value = self._get_field_value(field, context)
            
            # Evaluate condition
            result = await self._evaluate_condition(field_value, operator, value, context)
            results.append(result)
        
        # Apply logic
        if logic == "and":
            return all(results)
        elif logic == "or":
            return any(results)
        elif logic == "not":
            return not all(results)
        else:
            return all(results)  # Default to AND
    
    def _get_field_value(self, field: str, context: Dict[str, Any]) -> Any:
        """Get field value from context"""
        
        # Handle nested field access
        parts = field.split(".")
        value = context
        
        for part in parts:
            if isinstance(value, dict) and part in value:
                value = value[part]
            else:
                return None
        
        return value
    
    async def _evaluate_condition(
        self,
        field_value: Any,
        operator: Operator,
        condition_value: Any,
        context: Dict[str, Any]
    ) -> bool:
        """Evaluate individual condition"""
        
        try:
            if operator == Operator.EQUALS:
                return field_value == condition_value
            
            elif operator == Operator.NOT_EQUALS:
                return field_value != condition_value
            
            elif operator == Operator.CONTAINS:
                return str(condition_value) in str(field_value)
            
            elif operator == Operator.NOT_CONTAINS:
                return str(condition_value) not in str(field_value)
            
            elif operator == Operator.STARTS_WITH:
                return str(field_value).startswith(str(condition_value))
            
            elif operator == Operator.ENDS_WITH:
                return str(field_value).endswith(str(condition_value))
            
            elif operator == Operator.GREATER_THAN:
                return float(field_value) > float(condition_value)
            
            elif operator == Operator.LESS_THAN:
                return float(field_value) < float(condition_value)
            
            elif operator == Operator.GREATER_EQUAL:
                return float(field_value) >= float(condition_value)
            
            elif operator == Operator.LESS_EQUAL:
                return float(field_value) <= float(condition_value)
            
            elif operator == Operator.REGEX_MATCH:
                pattern = re.compile(str(condition_value))
                return bool(pattern.search(str(field_value)))
            
            elif operator == Operator.IN:
                return field_value in condition_value
            
            elif operator == Operator.NOT_IN:
                return field_value not in condition_value
            
            elif operator == Operator.IS_EMPTY:
                return not field_value
            
            elif operator == Operator.IS_NOT_EMPTY:
                return bool(field_value)
            
            elif operator == Operator.IS_TRUE:
                return bool(field_value) is True
            
            elif operator == Operator.IS_FALSE:
                return bool(field_value) is False
            
            else:
                return False
        
        except Exception as e:
            logger.error(f"Error evaluating condition: {e}")
            return False
    
    def _substitute_variables(self, config: Dict[str, Any], variables: Dict[str, Any]) -> Dict[str, Any]:
        """Substitute variables in config"""
        
        def substitute_value(value):
            if isinstance(value, str):
                # Simple variable substitution using {{variable}} syntax
                import re
                
                def replace_var(match):
                    var_name = match.group(1)
                    return str(variables.get(var_name, match.group(0)))
                
                pattern = r'\{\{(\w+)\}\}'
                return re.sub(pattern, replace_var, value)
            
            elif isinstance(value, dict):
                return {k: substitute_value(v) for k, v in value.items()}
            
            elif isinstance(value, list):
                return [substitute_value(v) for v in value]
            
            else:
                return value
        
        return substitute_value(config)
    
    async def _find_matching_workflows(self, event: RealtimeSyncEvent) -> List[AutomationWorkflow]:
        """Find workflows matching the event"""
        
        matching_workflows = []
        
        for workflow in self.workflows.values():
            if not workflow.enabled:
                continue
            
            # Check if user matches
            if workflow.user_id != event.user_id:
                continue
            
            # Check triggers
            for trigger in workflow.triggers:
                if not trigger.enabled:
                    continue
                
                # Check trigger type
                trigger_type_map = {
                    TriggerType.FILE_CREATED: [RealtimeSyncEventType.FILE_CREATED],
                    TriggerType.FILE_UPDATED: [RealtimeSyncEventType.FILE_UPDATED],
                    TriggerType.FILE_DELETED: [RealtimeSyncEventType.FILE_DELETED],
                    TriggerType.FILE_MOVED: [RealtimeSyncEventType.FILE_MOVED],
                    TriggerType.FILE_SHARED: [RealtimeSyncEventType.FILE_SHARED],
                    TriggerType.FOLDER_CREATED: [RealtimeSyncEventType.FOLDER_CREATED],
                    TriggerType.FOLDER_UPDATED: [RealtimeSyncEventType.FOLDER_UPDATED],
                    TriggerType.FOLDER_DELETED: [RealtimeSyncEventType.FOLDER_DELETED],
                    TriggerType.FOLDER_MOVED: [RealtimeSyncEventType.FOLDER_MOVED],
                    TriggerType.PERMISSION_CHANGED: [RealtimeSyncEventType.PERMISSION_CHANGED],
                }
                
                if trigger.type in trigger_type_map:
                    if event.event_type not in trigger_type_map[trigger.type]:
                        continue
                
                # Check trigger conditions
                if trigger.conditions:
                    context = {
                        "event": event,
                        "trigger_data": {
                            "file_id": event.file_id,
                            "file_name": event.file_name,
                            "mime_type": event.mime_type,
                            "user_id": event.user_id,
                            "timestamp": event.timestamp.isoformat()
                        }
                    }
                    
                    condition_met = await self._evaluate_conditions(
                        trigger.conditions,
                        "and",
                        context
                    )
                    
                    if not condition_met:
                        continue
                
                # Workflow matches
                matching_workflows.append(workflow)
                break
        
        return matching_workflows
    
    async def _register_workflow_triggers(self, workflow: AutomationWorkflow):
        """Register workflow triggers with trigger manager"""
        
        for trigger in workflow.triggers:
            if trigger.type == TriggerType.SCHEDULE:
                # Register scheduled trigger
                schedule_config = trigger.config
                cron_expression = schedule_config.get("cron")
                
                if cron_expression:
                    await self.workflow_scheduler.schedule_workflow(
                        workflow_id=workflow.id,
                        cron_expression=cron_expression,
                        trigger_data={}
                    )
    
    async def _unregister_workflow_triggers(self, workflow: AutomationWorkflow):
        """Unregister workflow triggers"""
        
        for trigger in workflow.triggers:
            if trigger.type == TriggerType.SCHEDULE:
                # Unregister scheduled trigger
                await self.workflow_scheduler.unschedule_workflow(workflow.id)
    
    async def _cancel_execution(self, execution_id: str):
        """Cancel workflow execution"""
        
        if execution_id in self.active_executions:
            task = self.active_executions[execution_id]
            if not task.done():
                task.cancel()
                
                # Update execution status
                execution = self.executions.get(execution_id)
                if execution:
                    execution.status = "cancelled"
                    execution.completed_at = datetime.now(timezone.utc)
                    execution.duration = (execution.completed_at - execution.started_at).total_seconds()
                    
                    if self.db_pool:
                        await self._update_execution_in_db(execution, self.db_pool)
    
    def _register_event_handlers(self):
        """Register event handlers with sync service"""
        
        # Import and register with Google Drive sync service
        try:
            from google_drive_realtime_sync import get_google_drive_realtime_sync_service
            sync_service = get_google_drive_realtime_sync_service()
            
            if sync_service:
                sync_service.register_global_handler(self.handle_drive_event)
                logger.info("Registered automation handler with Google Drive sync service")
        
        except ImportError:
            logger.warning("Google Drive sync service not available")
    
    async def _cleanup_worker(self):
        """Background cleanup worker"""
        
        while self.running:
            try:
                # Clean up old executions
                cutoff_time = datetime.now(timezone.utc) - timedelta(days=30)
                old_executions = [
                    execution_id for execution_id, execution in self.executions.items()
                    if execution.started_at < cutoff_time
                ]
                
                for execution_id in old_executions:
                    del self.executions[execution_id]
                
                if old_executions:
                    logger.info(f"Cleaned up {len(old_executions)} old executions")
                
                # Wait before next cleanup
                await asyncio.sleep(self.cleanup_interval.total_seconds())
            
            except Exception as e:
                logger.error(f"Error in cleanup worker: {e}")
                await asyncio.sleep(300)  # 5 minutes
    
    async def _execution_monitor(self):
        """Background execution monitor"""
        
        while self.running:
            try:
                # Check for timed out executions
                current_time = datetime.now(timezone.utc)
                
                for execution_id, execution in self.executions.items():
                    if execution.status == "running":
                        execution_duration = (current_time - execution.started_at).total_seconds()
                        default_timeout = 300  # 5 minutes
                        
                        # Check if execution has timed out
                        if execution_duration > default_timeout:
                            await self._log_execution(
                                execution,
                                "warning",
                                f"Execution timeout after {execution_duration:.2f}s"
                            )
                            
                            # Cancel execution
                            await self._cancel_execution(execution_id)
                
                # Wait before next check
                await asyncio.sleep(60)  # 1 minute
            
            except Exception as e:
                logger.error(f"Error in execution monitor: {e}")
                await asyncio.sleep(60)
    
    async def _scheduled_trigger_worker(self):
        """Background scheduled trigger worker"""
        
        while self.running:
            try:
                # Get scheduled workflows that need to run
                scheduled_triggers = await self.workflow_scheduler.get_due_triggers()
                
                for trigger in scheduled_triggers:
                    workflow_id = trigger["workflow_id"]
                    trigger_data = trigger.get("trigger_data", {})
                    
                    # Execute workflow
                    await self.execute_workflow(
                        workflow_id,
                        TriggerType.SCHEDULE,
                        trigger_data
                    )
                
                # Wait before next check
                await asyncio.sleep(60)  # 1 minute
            
            except Exception as e:
                logger.error(f"Error in scheduled trigger worker: {e}")
                await asyncio.sleep(60)
    
    def _initialize_builtin_templates(self):
        """Initialize built-in workflow templates"""
        
        # File backup template
        backup_template = WorkflowTemplate(
            id="backup_template",
            name="File Backup",
            description="Automatically backup files to a specific folder",
            category="Backup",
            triggers=[
                {
                    "type": "file_created",
                    "config": {},
                    "conditions": [
                        {
                            "field": "trigger_data.mime_type",
                            "operator": "contains",
                            "value": "application/pdf"
                        }
                    ]
                }
            ],
            actions=[
                {
                    "type": "copy_file",
                    "config": {
                        "file_id": "{{trigger_data.file_id}}",
                        "new_name": "{{trigger_data.file_name}}_backup",
                        "parent_ids": ["backup_folder_id"]
                    }
                }
            ],
            variables=[
                {"name": "backup_folder_id", "type": "string", "required": True}
            ],
            icon="",
            tags=["backup", "copy", "automation"],
            public=True
        )
        
        # File organization template
        organization_template = WorkflowTemplate(
            id="organization_template",
            name="File Organization",
            description="Automatically organize files into folders based on type",
            category="Organization",
            triggers=[
                {
                    "type": "file_created",
                    "config": {},
                    "conditions": []
                }
            ],
            actions=[
                {
                    "type": "condition_check",
                    "config": {
                        "conditions": [
                            {
                                "field": "trigger_data.mime_type",
                                "operator": "contains",
                                "value": "image/"
                            }
                        ],
                        "logic": "and"
                    }
                },
                {
                    "type": "move_file",
                    "config": {
                        "file_id": "{{trigger_data.file_id}}",
                        "add_parents": ["images_folder_id"]
                    }
                }
            ],
            variables=[
                {"name": "images_folder_id", "type": "string", "required": True},
                {"name": "documents_folder_id", "type": "string", "required": True}
            ],
            icon="",
            tags=["organization", "folders", "automation"],
            public=True
        )
        
        # Notification template
        notification_template = WorkflowTemplate(
            id="notification_template",
            name="File Change Notifications",
            description="Send notifications when files are changed",
            category="Notifications",
            triggers=[
                {
                    "type": "file_updated",
                    "config": {},
                    "conditions": []
                }
            ],
            actions=[
                {
                    "type": "send_email",
                    "config": {
                        "to": "{{user_email}}",
                        "subject": "File Updated: {{trigger_data.file_name}}",
                        "body": "File {{trigger_data.file_name}} has been updated in Google Drive."
                    }
                },
                {
                    "type": "post_to_slack",
                    "config": {
                        "channel": "#file-updates",
                        "message": " File {{trigger_data.file_name}} was updated by {{trigger_data.user_id}}"
                    }
                }
            ],
            variables=[
                {"name": "user_email", "type": "string", "required": True},
                {"name": "slack_webhook", "type": "string", "required": False}
            ],
            icon="",
            tags=["notifications", "email", "slack", "automation"],
            public=True
        )
        
        # Content processing template
        processing_template = WorkflowTemplate(
            id="processing_template",
            name="Document Processing",
            description="Process uploaded documents and extract content",
            category="Processing",
            triggers=[
                {
                    "type": "file_created",
                    "config": {},
                    "conditions": [
                        {
                            "field": "trigger_data.mime_type",
                            "operator": "in",
                            "value": ["application/pdf", "application/msword", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"]
                        }
                    ]
                }
            ],
            actions=[
                {
                    "type": "extract_text",
                    "config": {
                        "file_id": "{{trigger_data.file_id}}"
                    }
                },
                {
                    "type": "update_database",
                    "config": {
                        "table": "documents",
                        "data": {
                            "file_id": "{{trigger_data.file_id}}",
                            "file_name": "{{trigger_data.file_name}}",
                            "extracted_text": "{{extracted_text}}"
                        }
                    }
                }
            ],
            variables=[
                {"name": "database_connection", "type": "string", "required": True}
            ],
            icon="",
            tags=["processing", "extraction", "automation"],
            public=True
        )
        
        # Store templates
        self.templates[backup_template.id] = backup_template
        self.templates[organization_template.id] = organization_template
        self.templates[notification_template.id] = notification_template
        self.templates[processing_template.id] = processing_template
        
        logger.info(f"Initialized {len(self.templates)} built-in workflow templates")
    
    async def _log_execution(self, execution: WorkflowExecution, level: str, message: str):
        """Log execution message"""
        
        timestamp = datetime.now(timezone.utc).isoformat()
        log_entry = f"[{timestamp}] [{level.upper()}] {message}"
        
        execution.logs.append(log_entry)
        
        # Log to system logger
        if level == "error":
            logger.error(f"Execution {execution.id}: {message}")
        elif level == "warning":
            logger.warning(f"Execution {execution.id}: {message}")
        else:
            logger.info(f"Execution {execution.id}: {message}")
    
    def _generate_workflow_id(self) -> str:
        """Generate workflow ID"""
        return f"workflow_{datetime.now().timestamp()}"
    
    def _generate_trigger_id(self) -> str:
        """Generate trigger ID"""
        return f"trigger_{datetime.now().timestamp()}"
    
    def _generate_action_id(self) -> str:
        """Generate action ID"""
        return f"action_{datetime.now().timestamp()}"
    
    def _generate_execution_id(self) -> str:
        """Generate execution ID"""
        return f"execution_{datetime.now().timestamp()}"
    
    def _generate_template_id(self) -> str:
        """Generate template ID"""
        return f"template_{datetime.now().timestamp()}"
    
    def _substitute_template_variables(
        self,
        items: List[Dict[str, Any]],
        variable_values: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Substitute variables in template items"""
        
        substituted_items = []
        
        for item in items:
            substituted_item = {}
            
            for key, value in item.items():
                if isinstance(value, str):
                    # Simple variable substitution
                    import re
                    
                    def replace_var(match):
                        var_name = match.group(1)
                        return str(variable_values.get(var_name, match.group(0)))
                    
                    pattern = r'\{\{(\w+)\}\}'
                    substituted_value = re.sub(pattern, replace_var, value)
                    substituted_item[key] = substituted_value
                else:
                    substituted_item[key] = value
            
            substituted_items.append(substituted_item)
        
        return substituted_items
    
    # Database operations (placeholder implementations)
    async def _store_workflow_in_db(self, workflow: AutomationWorkflow, db_pool):
        """Store workflow in database"""
        # Implementation would go here
        pass
    
    async def _delete_workflow_from_db(self, workflow_id: str, db_pool):
        """Delete workflow from database"""
        # Implementation would go here
        pass
    
    async def _store_execution_in_db(self, execution: WorkflowExecution, db_pool):
        """Store execution in database"""
        # Implementation would go here
        pass
    
    async def _update_execution_in_db(self, execution: WorkflowExecution, db_pool):
        """Update execution in database"""
        # Implementation would go here
        pass
    
    async def _store_template_in_db(self, template: WorkflowTemplate, db_pool):
        """Store template in database"""
        # Implementation would go here
        pass
    
    async def _update_template_usage_count(self, template_id: str, usage_count: int, db_pool):
        """Update template usage count in database"""
        # Implementation would go here
        pass

# Global service instance
_google_drive_automation_service: Optional[GoogleDriveAutomationService] = None

def get_google_drive_automation_service(
    drive_service: GoogleDriveService,
    workflow_engine: WorkflowEngine,
    trigger_manager: TriggerManager,
    action_executor: ActionExecutor,
    workflow_scheduler: WorkflowScheduler,
    db_pool=None
) -> GoogleDriveAutomationService:
    """Get global Google Drive automation service instance"""
    global _google_drive_automation_service
    
    if _google_drive_automation_service is None:
        _google_drive_automation_service = GoogleDriveAutomationService(
            drive_service, workflow_engine, trigger_manager,
            action_executor, workflow_scheduler, db_pool
        )
        
        # Start service
        _google_drive_automation_service.start()
    
    return _google_drive_automation_service

# Export classes
__all__ = [
    "GoogleDriveAutomationService",
    "AutomationWorkflow",
    "AutomationTrigger",
    "AutomationAction",
    "WorkflowExecution",
    "WorkflowTemplate",
    "TriggerType",
    "ActionType",
    "Operator",
    "ConditionLogic",
    "get_google_drive_automation_service"
]