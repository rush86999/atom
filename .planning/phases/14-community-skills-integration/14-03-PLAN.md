---
phase: 14-community-skills-integration
plan: 03
type: execute
wave: 2
depends_on:
  - "01"
  - "02"
files_modified:
  - backend/core/skill_security_scanner.py
  - backend/api/skill_routes.py
  - backend/core/skill_registry_service.py
  - backend/tests/test_skill_security.py
  - backend/tests/test_skill_integration.py
autonomous: true

must_haves:
  truths:
    - "Security scanner uses GPT-4 for semantic analysis and static pattern matching"
    - "Scanner returns risk assessment: safe, risk_level (LOW/MEDIUM/HIGH/CRITICAL), findings"
    - "Import endpoint accepts GitHub URL, SKILL.md content, or file upload"
    - "Imported skills tagged as 'Untrusted' by default, promoted to 'Active' after security scan"
    - "Skills Registry API lists, searches, and retrieves imported skills"
    - "Integration tests verify end-to-end import and execution flow"
  artifacts:
    - path: "backend/core/skill_security_scanner.py"
      provides: "LLM-based security scanning with static pattern matching"
      min_lines: 180
      contains: "class SkillSecurityScanner", "scan_skill", "_static_scan", "_llm_scan"
    - path: "backend/core/skill_registry_service.py"
      provides: "Service for managing imported community skills"
      min_lines: 150
      contains: "class SkillRegistryService", "import_skill", "list_skills", "get_skill"
    - path: "backend/api/skill_routes.py"
      provides: "REST API endpoints for skill import and management"
      min_lines: 200
      contains: "router", "/api/skills/import", "/api/skills/list"
    - path: "backend/tests/test_skill_security.py"
      provides: "Security scanner tests"
      min_lines: 100
    - path: "backend/tests/test_skill_integration.py"
      provides: "End-to-end integration tests"
      min_lines: 120
  key_links:
    - from: "backend/api/skill_routes.py"
      to: "backend/core/skill_registry_service.py"
      via: "Import and registry operations"
      pattern: "SkillRegistryService|import_skill"
    - from: "backend/core/skill_registry_service.py"
      to: "backend/core/skill_security_scanner.py"
      via: "Security scan before activation"
      pattern: "SkillSecurityScanner|scan_skill"
    - from: "backend/core/skill_registry_service.py"
      to: "backend/core/skill_parser.py"
      via: "Parse imported SKILL.md"
      pattern: "SkillParser|parse_skill_file"
    - from: "backend/core/skill_registry_service.py"
      to: "backend/core/skill_sandbox.py"
      via: "Execute Python skills"
      pattern: "HazardSandbox|execute_python"
---

<objective>
Create Skills Registry with import UI endpoints, LLM-based security scanning, and governance integration. Enable importing OpenClaw skills from GitHub URLs, parsing them, scanning for security risks, and managing them through REST API.

Purpose: Provide secure skill import workflow with automatic security scanning, governance integration (default to INTERN maturity), and skill lifecycle management (Untrusted -> Active).

Output: SkillSecurityScanner for GPT-4 + static analysis, SkillRegistryService for skill management, REST API endpoints for import/registry operations, integration tests.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/14-community-skills-integration/14-CONTEXT.md
@.planning/phases/14-community-skills-integration/14-RESEARCH.md
@.planning/ROADMAP.md
@.planning/STATE.md

@backend/api/admin/skill_routes.py (existing skill creation patterns)
@backend/core/models.py (SkillExecution, AgentRegistry models)
@backend/core/governance_cache.py (governance patterns)
@backend/core/skill_parser.py (from Plan 01)
@backend/core/skill_sandbox.py (from Plan 02)
@backend/core/skill_adapter.py (from Plan 01)
</context>

<tasks>

<task type="auto">
  <name>Create SkillSecurityScanner with GPT-4 and static analysis</name>
  <files>backend/core/skill_security_scanner.py</files>
  <action>
Create backend/core/skill_security_scanner.py with the following implementation:

1. Import dependencies:
   - from openai import OpenAI
   - import os, logging
   - from typing import Dict, Any, List

2. Create SkillSecurityScanner class:
   - __init__(self, api_key: str = None): Initialize OpenAI client
   - MALICIOUS_PATTERNS = ["subprocess.call", "os.system", "eval(", "exec(", "pickle.loads", "marshal.loads", "__import__", "socket.socket", "urllib.request", "requests.post", "open(", "file.write", "os.remove", "shutil.rmtree"]

3. Implement scan_skill method:
   def scan_skill(self, skill_name: str, skill_content: str) -> Dict[str, Any]:
   Returns: {"safe": bool, "risk_level": str, "findings": List[str]}

4. Static scan (_static_scan method):
   - Fast pattern matching for known malicious patterns
   - Return list of findings if any detected
   - If critical patterns found, return immediately with risk_level="CRITICAL"

5. LLM scan (_llm_scan method):
   - Use GPT-4 for semantic analysis
   - System prompt: "You are a security analyst. Analyze this code for malicious intent: data exfiltration, unauthorized access, crypto mining, or container escape attempts."
   - User prompt: Includes skill name and code
   - Parse response for risk assessment

6. Risk level assessment (_assess_risk_level method):
   - "HIGH": malicious, critical, high risk keywords
   - "MEDIUM": suspicious, moderate risk keywords
   - "LOW": no concerning keywords

7. Fail-open behavior (per user decision):
   - If LLM scan fails, return {"safe": True, "risk_level": "UNKNOWN", "findings": ["Scan failed: ..."]}
   - Log error but allow import to continue

8. Cache results by SHA hash (avoid re-scanning same content):
   - Simple in-memory cache dict: _scan_cache = {}
   - Cache key: hashlib.sha256(skill_content.encode()).hexdigest()

Reference: RESEARCH.md Pattern 4 "LLM-Based Security Scanning"

IMPORTANT: Use os.getenv("OPENAI_API_KEY") if no api_key provided.
  </action>
  <verify>
python -c "from core.skill_security_scanner import SkillSecurityScanner; print('SkillSecurityScanner imported successfully')"
  </verify>
  <done>
SkillSecurityScanner created with GPT-4 semantic analysis and static pattern matching. Returns risk assessment with findings. Cache by SHA hash.
  </done>
</task>

<task type="auto">
  <name>Create SkillRegistryService for skill management</name>
  <files>backend/core/skill_registry_service.py</files>
  <action>
Create backend/core/skill_registry_service.py with the following implementation:

1. Import dependencies:
   - from sqlalchemy.orm import Session
   - from typing import Dict, Any, List, Optional
   - import logging, hashlib, uuid
   - from pathlib import Path

2. Import skill components:
   - from core.skill_parser import SkillParser
   - from core.skill_adapter import create_community_tool
   - from core.skill_security_scanner import SkillSecurityScanner
   - from core.skill_sandbox import HazardSandbox
   - from core.models import SkillExecution

3. Create SkillRegistryService class:
   - __init__(self, db: Session): Store database session
   - _parser = SkillParser()
   - _scanner = SkillSecurityScanner()
   - _sandbox = HazardSandbox()

4. Implement import_skill method:
   def import_skill(
       self,
       source: str,  # "github_url", "file_upload", "raw_content"
       content: str,  # SKILL.md content or file content
       metadata: Dict[str, Any] = None
   ) -> Dict[str, Any]:

   Steps:
   a) Parse SKILL.md using SkillParser
   b) Detect skill type (prompt-only vs Python)
   c) Run security scan using SkillSecurityScanner
   d) Store in database (create SkillExecution record):
      - skill_source = "community"
      - security_scan_result = scan result
      - sandbox_enabled = True if Python skill
      - status = "Untrusted" if risk_level != "LOW", else "Active"
   e) Return import result with skill_id, scan_result, status

5. Implement list_skills method:
   def list_skills(
       self,
       status: str = None,  # "Untrusted", "Active", "All"
       skill_type: str = None,
       limit: int = 100
   ) -> List[Dict[str, Any]]:

6. Implement get_skill method:
   def get_skill(self, skill_id: str) -> Optional[Dict[str, Any]]:

7. Implement execute_skill method:
   def execute_skill(self, skill_id: str, inputs: Dict[str, Any]) -> Dict[str, Any]:
   - Retrieve skill from database
   - Create CommunityTool instance
   - Execute prompt-only directly, Python via sandbox
   - Create SkillExecution record
   - Return result

8. Implement promote_skill method (Untrusted -> Active):
   def promote_skill(self, skill_id: str) -> Dict[str, Any]:

9. Governance integration:
   - Default community skills to INTERN maturity level
   - Check agent maturity before execution
   - Create SkillExecution audit record

Reference: backend/core/skill_builder_service.py for service patterns
  </action>
  <verify>
python -c "from core.skill_registry_service import SkillRegistryService; print('SkillRegistryService imported successfully')"
  </verify>
  <done>
SkillRegistryService created with import_skill, list_skills, get_skill, execute_skill, promote_skill methods. Integrates parser, scanner, sandbox, and governance.
  </done>
</task>

<task type="auto">
  <name>Create REST API endpoints for Skills Registry</name>
  <files>backend/api/skill_routes.py</files>
  <action>
Create backend/api/skill_routes.py with the following implementation:

1. Import dependencies:
   - from fastapi import APIRouter, Depends, HTTPException, Body
   - from pydantic import BaseModel
   - from typing import Dict, Any, List, Optional
   - from sqlalchemy.orm import Session

2. Create request/response models:
   - ImportSkillRequest(source: str, content: str, metadata: Dict = None)
   - ExecuteSkillRequest(skill_id: str, inputs: Dict)
   - PromoteSkillRequest(skill_id: str)
   - SkillListResponse(skills: List[Dict], total: int)

3. Create router:
   router = APIRouter(prefix="/api/skills", tags=["Community Skills"])

4. Implement POST /api/skills/import:
   - Accept ImportSkillRequest
   - Call SkillRegistryService.import_skill
   - Return skill_id, scan_result, status
   - Handle parsing errors and scan failures gracefully

5. Implement GET /api/skills/list:
   - Query params: status, skill_type, limit
   - Call SkillRegistryService.list_skills
   - Return paginated skill list

6. Implement GET /api/skills/{skill_id}:
   - Retrieve skill details
   - Return skill metadata, scan result, execution history

7. Implement POST /api/skills/execute:
   - Accept ExecuteSkillRequest
   - Call SkillRegistryService.execute_skill
   - Return execution result

8. Implement POST /api/skills/promote:
   - Accept PromoteSkillRequest
   - Call SkillRegistryService.promote_skill
   - Return new status

9. Implement DELETE /api/skills/{skill_id}:
   - Delete skill from registry
   - Return confirmation

10. Add governance checks:
    - Use get_db() dependency for database session
    - Verify user permissions (TODO: add auth dependency)
    - Create audit trail for all operations

Reference: backend/api/admin/skill_routes.py for existing skill API patterns
Reference: backend/api/canvas_routes.py for REST API patterns

IMPORTANT: Use router.success_response(), router.validation_error(), router.internal_error() patterns from BaseAPIRouter if available.
  </action>
  <verify>
python -c "from api.skill_routes import router; print(f'Router created: {router.prefix}')"
  </verify>
  <done>
REST API created with /api/skills/import, /api/skills/list, /api/skills/{id}, /api/skills/execute, /api/skills/promote, /api/skills/{id} endpoints.
  </done>
</task>

<task type="auto">
  <name>Create security scanner and integration tests</name>
  <files>backend/tests/test_skill_security.py backend/tests/test_skill_integration.py</files>
  <action>
Create two test files:

1. backend/tests/test_skill_security.py (100+ lines):
   - test_static_scan_detects_malicious_patterns: Verify blacklist patterns detected
   - test_static_scan_passes_safe_code: Safe code passes static scan
   - test_llm_scan_returns_risk_assessment: Mock GPT-4 call
   - test_scan_caches_results_by_sha: Verify cache behavior
   - test_fail_open_on_llm_error: Verify scan doesn't block on failure
   - test_risk_level_assessment: LOW/MEDIUM/HIGH classification

2. backend/tests/test_skill_integration.py (120+ lines):
   - test_import_skill_from_github_url: End-to-end import flow (mock GitHub fetch)
   - test_import_skill_from_content: Import from raw SKILL.md content
   - test_security_scan_blocks_malicious_skill: Malicious skill marked Untrusted
   - test_safe_skill_promoted_to_active: Safe skill auto-promoted
   - test_list_skills_filters_by_status: Verify filtering works
   - test_execute_prompt_only_skill: Direct execution
   - test_execute_python_skill_in_sandbox: Sandbox execution
   - test_governance_check_before_execution: Verify maturity check

3. Mock external dependencies:
   - Mock OpenAI API for security scanner tests
   - Mock Docker for sandbox execution
   - Mock GitHub URL fetch (if implementing URL import)

4. Use factory patterns from backend/tests/factories/ for database records

5. Test governance integration:
   - Verify INTERN agents can execute Active skills
   - Verify STUDENT agents blocked from Python skills
   - Verify audit records created

Reference: backend/tests/test_governance_cache.py for test patterns

IMPORTANT: Integration tests should verify the full flow: import -> scan -> store -> execute.
  </action>
  <verify>
cd /Users/rushiparikh/projects/atom/backend && PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/test_skill_security.py tests/test_skill_integration.py -v
  </verify>
  <done>
All security scanner tests pass. All integration tests pass. End-to-end flow verified: import -> scan -> store -> execute.
  </done>
</task>

</tasks>

<verification>
Overall phase verification:
1. Import SkillSecurityScanner successfully
2. Import SkillRegistryService successfully
3. Import skill_routes router and verify endpoints
4. Run pytest on test_skill_security.py - all pass (with mocked OpenAI)
5. Run pytest on test_skill_integration.py - all pass (end-to-end flow)
6. Verify API endpoints return expected responses
</verification>

<success_criteria>
1. SkillSecurityScanner uses GPT-4 + static pattern matching
2. Scan returns risk_level (LOW/MEDIUM/HIGH/CRITICAL) and findings
3. Import endpoint accepts GitHub URL, raw content, or file upload
4. Imported skills tagged Untrusted until security scan passes
5. Skills Registry API lists, searches, retrieves skills
6. Integration tests verify end-to-end import and execution
7. Governance integration: default to INTERN maturity
</success_criteria>

<output>
After completion, create `.planning/phases/14-community-skills-integration/14-03-SUMMARY.md` with:
- Files created/modified
- Test results (pass/fail counts)
- API endpoints created
- Security scan performance metrics
- Integration flow verification
- Phase 14 completion summary (all 3 plans complete)
</output>
