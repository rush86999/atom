---
phase: 14-community-skills-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/core/skill_parser.py
  - backend/core/skill_adapter.py
  - backend/core/models.py
  - backend/tests/test_skill_parser.py
  - backend/tests/test_skill_adapter.py
autonomous: true

must_haves:
  truths:
    - "Parser can extract YAML frontmatter and Markdown body from SKILL.md files"
    - "Parser auto-fixes missing required fields (name, description) with defaults"
    - "Parser detects skill type: prompt-only (natural language) vs Python code"
    - "Adapter wraps skills as LangChain BaseTool subclasses with Pydantic args_schema"
    - "SkillExecution model extended with skill_source, security_scan_result, sandbox_enabled columns"
    - "Tests cover lenient parsing, auto-fix logic, and BaseTool wrapping"
  artifacts:
    - path: "backend/core/skill_parser.py"
      provides: "SKILL.md parsing with lenient frontmatter extraction and auto-fix"
      min_lines: 150
      contains: "class SkillParser", "parse_skill_file", "_auto_fix_metadata"
    - path: "backend/core/skill_adapter.py"
      provides: "LangChain BaseTool wrapping for community skills"
      min_lines: 200
      contains: "class CommunitySkillTool", "class BaseTool", "args_schema"
    - path: "backend/core/models.py"
      provides: "SkillExecution model extensions for community skills"
      contains: "skill_source", "security_scan_result", "sandbox_enabled"
    - path: "backend/tests/test_skill_parser.py"
      provides: "Parser tests covering lenient parsing and auto-fix"
      min_lines: 100
    - path: "backend/tests/test_skill_adapter.py"
      provides: "Adapter tests covering BaseTool wrapping"
      min_lines: 100
  key_links:
    - from: "backend/core/skill_adapter.py"
      to: "backend/core/models.py"
      via: "SkillExecution model reference"
      pattern: "SkillExecution"
    - from: "backend/core/skill_parser.py"
      to: "backend/core/skill_adapter.py"
      via: "Parser output consumed by adapter"
      pattern: "SkillParser|parse_skill_file"
---

<objective>
Parse OpenClaw SKILL.md files (YAML frontmatter + Markdown body) with lenient error handling, auto-detect skill type (prompt-only vs Python code), and wrap them as LangChain BaseTool subclasses with Pydantic validation.

Purpose: Enable Atom agents to use 5,000+ OpenClaw/ClawHub community skills by creating a robust parsing and adaptation layer that handles malformed files gracefully.

Output: SkillParser service for SKILL.md parsing, CommunitySkillTool (BaseTool subclass) for LangChain integration, SkillExecution model extensions.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/14-community-skills-integration/14-CONTEXT.md
@.planning/phases/14-community-skills-integration/14-RESEARCH.md
@.planning/ROADMAP.md
@.planning/STATE.md

@backend/core/models.py (SkillExecution model, AgentRegistry model)
@backend/core/skill_builder_service.py (existing skill metadata patterns)
@backend/tools/registry.py (ToolRegistry patterns for tool registration)
@backend/tools/canvas_tool.py (example tool implementation patterns)
</context>

<tasks>

<task type="auto">
  <name>Create SkillParser for lenient SKILL.md parsing</name>
  <files>backend/core/skill_parser.py</files>
  <action>
Create backend/core/skill_parser.py with the following implementation:

1. Import dependencies:
   - frontmatter (python-frontmatter) for YAML frontmatter extraction
   - yaml (PyYAML) for YAML parsing
   - ast (stdlib) for Python AST parsing
   - logging for error tracking

2. Create SkillParser class with methods:
   - parse_skill_file(file_path: str) -> Tuple[Dict[str, Any], str]: Parse SKILL.md, return (metadata, body)
   - _auto_fix_metadata(metadata, body, file_path): Apply fixes for missing fields
   - _detect_skill_type(metadata, body): Return "prompt_only" or "python_code"
   - _extract_python_code(body): Extract ```python blocks from markdown body
   - _extract_function_signatures(code): Use ast to find all function definitions

3. Lenient parsing behavior (per user decision):
   - Use python-frontmatter to split frontmatter (handles missing --- gracefully)
   - Missing name: use "Unnamed Skill"
   - Missing description: auto-generate from first line of body (max 100 chars)
   - Invalid YAML: log warning, skip file with clear message
   - Version-agnostic: don't validate openclaw_version field
   - Show summary of successes/failures at batch import end

4. Auto-detect skill type:
   - If body contains ```python fence: type = "python_code"
   - Otherwise: type = "prompt_only"

5. Error handling:
   - Wrap all parsing in try/except
   - Log warnings with file paths
   - Return minimal valid metadata to allow import to continue
   - Never crash the entire import for a single bad file

6. Type hints and docstrings required (Google style)

Reference: RESEARCH.md Pattern 1 "Lenient YAML Frontmatter Parsing"
  </action>
  <verify>
python -c "from core.skill_parser import SkillParser; parser = SkillParser(); print('SkillParser imported successfully')"
  </verify>
  <done>
SkillParser class created with parse_skill_file, _auto_fix_metadata, _detect_skill_type methods. Successfully parses YAML frontmatter with lenient error handling.
  </done>
</task>

<task type="auto">
  <name>Create CommunitySkillTool (LangChain BaseTool adapter)</name>
  <files>backend/core/skill_adapter.py</files>
  <action>
Create backend/core/skill_adapter.py with the following implementation:

1. Import dependencies:
   - from langchain.tools import BaseTool
   - from pydantic import BaseModel, Field
   - from typing import Type, Optional, Any, Dict
   - import uuid

2. Create CommunitySkillInput(BaseModel):
   - Single field: query: str = Field(description="User's request or question")
   - Use ConfigDict with extra='allow' for flexible inputs (per RESEARCH.md pitfall 5)

3. Create CommunitySkillTool(BaseTool):
   - name: str = "community_skill" (overridden per instance)
   - description: str (from skill metadata)
   - args_schema: Type[BaseModel] = CommunitySkillInput
   - skill_id: str (instance attribute)
   - skill_type: str  # "prompt_only" or "python_code"
   - skill_content: str  # Prompt template or Python code
   - sandbox_enabled: bool = False

4. Implement _run(self, query: str) -> str:
   - If skill_type == "prompt_only": format template with query
   - If skill_type == "python_code": raise NotImplementedError("Use sandbox - Plan 02")
   - Return formatted string or error message

5. Implement async _arun: delegate to _run

6. Create factory function create_community_tool(parsed_skill: Dict) -> CommunitySkillTool:
   - Accept parsed skill dict from SkillParser
   - Instantiate CommunitySkillTool with skill metadata
   - Return tool instance

7. Type hints and docstrings required (Google style)

Reference: RESEARCH.md Pattern 2 "LangChain BaseTool Wrapping"
  </action>
  <verify>
python -c "from core.skill_adapter import CommunitySkillTool, create_community_tool; print('CommunitySkillTool imported successfully')"
  </verify>
  <done>
CommunitySkillTool class created as LangChain BaseTool subclass with Pydantic args_schema. create_community_tool factory function works.
  </done>
</task>

<task type="auto">
  <name>Extend SkillExecution model for community skills</name>
  <files>backend/core/models.py</files>
  <action>
Modify backend/core/models.py to extend SkillExecution model (around line 1061):

1. Add new columns to SkillExecution class:
   - skill_source = Column(String, default="cloud")  # "cloud", "community", "custom"
   - security_scan_result = Column(JSON, nullable=True)  # {safe: bool, risk_level: str, findings: []}
   - sandbox_enabled = Column(Boolean, default=False)
   - container_id = Column(String, nullable=True)  # Docker container ID for sandbox

2. Add indexes:
   - Index on skill_source for filtering
   - Index on sandbox_enabled

3. Update docstring to reflect community skills

4. Maintain backward compatibility: default values ensure existing records work

DO NOT create Alembic migration in this task - migration will be created in Plan 02 after all model changes are complete.

Reference: RESEARCH.md Pitfall 6 "Database Schema Mismatch for Skill Storage"
  </action>
  <verify>
grep -n "skill_source\|security_scan_result\|sandbox_enabled" backend/core/models.py
  </verify>
  <done>
SkillExecution model extended with skill_source, security_scan_result, sandbox_enabled, container_id columns. Backward compatible with defaults.
  </done>
</task>

<task type="auto">
  <name>Create tests for parser and adapter</name>
  <files>backend/tests/test_skill_parser.py backend/tests/test_skill_adapter.py</files>
  <action>
Create two test files:

1. backend/tests/test_skill_parser.py (100+ lines):
   - test_parse_valid_skill_with_frontmatter: Successful parse
   - test_parse_missing_name_auto_fixes: Auto-fix missing name to "Unnamed Skill"
   - test_parse_missing_description_autogenerates: Auto-generate from first line
   - test_detect_python_code_skill: Detect ```python blocks
   - test_detect_prompt_only_skill: Default to prompt_only
   - test_extract_function_signatures: Extract from Python code
   - test_malformed_yaml_skips_gracefully: Don't crash on bad YAML

2. backend/tests/test_skill_adapter.py (100+ lines):
   - test_community_skill_tool_is_basetool: Verify LangChain integration
   - test_create_community_tool_factory: Factory function works
   - test_prompt_only_skill_formatting: Template interpolation
   - test_python_skill_raises_without_sandbox: NotImplementedError
   - test_args_schema_validation: Pydantic validation

3. Use pytest patterns from existing tests (backend/tests/test_governance_cache.py for reference)
4. Use factory_boy patterns if needed (see backend/tests/factories/)
5. Mock external dependencies (LangChain, Docker)

Reference: backend/tests/test_governance_cache.py for test patterns
  </action>
  <verify>
cd /Users/rushiparikh/projects/atom/backend && PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest tests/test_skill_parser.py tests/test_skill_adapter.py -v
  </verify>
  <done>
All parser and adapter tests pass. Covers lenient parsing, auto-fix logic, skill type detection, and BaseTool wrapping.
  </done>
</task>

</tasks>

<verification>
Overall phase verification:
1. Import SkillParser and parse a sample SKILL.md file successfully
2. Import CommunitySkillTool and verify it's a LangChain BaseTool subclass
3. Run pytest on test_skill_parser.py and test_skill_adapter.py - all pass
4. Verify SkillExecution model has new columns via grep
5. Check that parser handles malformed files without crashing (test case passes)
</verification>

<success_criteria>
1. SkillParser can parse SKILL.md files with YAML frontmatter and Markdown body
2. Lenient parsing auto-fixes missing fields (name -> "Unnamed Skill", description -> auto-generated)
3. Skill type auto-detection works (prompt-only vs Python code)
4. CommunitySkillTool is a valid LangChain BaseTool with Pydantic args_schema
5. SkillExecution model extended with skill_source, security_scan_result, sandbox_enabled
6. All tests pass (pytest -v tests/test_skill_parser.py tests/test_skill_adapter.py)
</success_criteria>

<output>
After completion, create `.planning/phases/14-community-skills-integration/14-01-SUMMARY.md` with:
- Files created/modified
- Test results (pass/fail counts)
- Decisions made (discretion areas)
- Deviations from plan (if any)
- Next steps (Plan 02: Hazard Sandbox)
</output>
