---
phase: 28-tauri-canvas-ai-accessibility
plan: 03
type: execute
wave: 2
depends_on: ["28-01", "28-02"]
files_modified:
  - docs/TAURI_CANVAS_VERIFICATION.md
  - frontend-nextjs/src-tauri/tests/canvas_integration_test.rs
autonomous: false

user_setup:
  - service: tauri-dev
    why: "Manual testing requires Tauri development environment"
    env_vars: []
    dashboard_config: []

must_haves:
  truths:
    - "Canvas AI context is accessible in Tauri development build (npm run tauri:dev)"
    - "Canvas AI context is accessible in Tauri production build (npm run tauri:build)"
    - "Accessibility trees survive minification in production builds"
    - "Tauri IPC bridge (__TAURI__) does not interfere with window.atom.canvas"
  artifacts:
    - path: "docs/TAURI_CANVAS_VERIFICATION.md"
      provides: "Comprehensive manual testing guide for Tauri canvas verification"
      min_lines: 150
    - path: "frontend-nextjs/src-tauri/tests/canvas_integration_test.rs"
      provides: "Rust integration test for canvas context access via IPC"
      min_lines: 50
  key_links:
    - from: "TAURI_CANVAS_VERIFICATION.md"
      to: "frontend-nextjs/src-tauri/tauri.conf.json"
      via: "Reference CSP settings and build configuration"
      pattern: "tauri.conf.json|csp|security"
    - from: "canvas_integration_test.rs"
      to: "frontend-nextjs/hooks/useCanvasState.ts"
      via: "JavaScript evaluation in webview to verify API registration"
      pattern: "window\\.eval|window\\.atom\\.canvas"
---

<objective>
Create manual testing documentation and Rust integration tests for verifying canvas AI context accessibility in actual Tauri desktop environment. This covers real-world verification that unit tests cannot provide: production build minification, Tauri webview context, and IPC bridge coexistence.

**Purpose:** Unit tests (Plan 01) and component tests (Plan 02) verify functionality in JSDOM. This plan adds real-world verification in Tauri's webview and production builds.

**Output:** Comprehensive manual testing guide + optional Rust integration test for programmatic verification.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/28-tauri-canvas-ai-accessibility/28-RESEARCH.md
@.planning/phases/20-canvas-ai-context/20-VERIFICATION.md
@frontend-nextjs/src-tauri/tauri.conf.json
@frontend-nextjs/src-tauri/src/main.rs
@frontend-nextjs/hooks/useCanvasState.ts
@frontend-nextjs/components/canvas/types/index.ts
</context>

<tasks>

<task type="auto">
  <name>Create Tauri canvas verification documentation</name>
  <files>docs/TAURI_CANVAS_VERIFICATION.md</files>
  <action>
    Create comprehensive manual testing guide for Tauri canvas AI context verification:

    **File: `docs/TAURI_CANVAS_VERIFICATION.md`**

    **Document Structure (150+ lines):**

    1. **Overview** (10 lines)
       - Purpose: Verify Phase 20 canvas AI context works in Tauri desktop app
       - What's being tested: `window.atom.canvas` API accessibility
       - Why manual testing needed: Production build minification, real webview context

    2. **Prerequisites** (20 lines)
       - Rust toolchain (rustc, cargo)
       - Node.js and npm
       - Tauri CLI: `cargo install tauri-cli --version "^2.0.0"`
       - Platform-specific requirements (Xcode on macOS, WebView2 on Windows)
       - Verify with: `cargo tauri --version` and `npm run tauri:info`

    3. **Development Build Verification** (40 lines)
       - Start dev server: `cd frontend-nextjs && npm run tauri:dev`
       - Wait for app window to open (should load http://localhost:3000)
       - Open DevTools (Cmd+Option+I on macOS, Ctrl+Shift+I on Windows/Linux)
       - Navigate to Console tab

       **Test 1: Verify window.atom.canvas exists**
       ```javascript
       // Run in DevTools console:
       typeof window.atom?.canvas
       // Expected: "object"
       ```

       **Test 2: Verify API methods**
       ```javascript
       // Check all methods exist:
       ['getState', 'getAllStates', 'subscribe', 'subscribeAll'].every(method =>
         typeof window.atom.canvas[method] === 'function'
       )
       // Expected: true
       ```

       **Test 3: Verify Tauri IPC coexistence**
       ```javascript
       // Both should be defined:
       typeof window.__TAURI__  // Expected: "object"
       typeof window.atom.canvas  // Expected: "object"
       ```

       **Test 4: Verify accessibility tree in DOM**
       - Navigate to page with AgentOperationTracker component
       - Open Elements tab in DevTools
       - Search for `[role="log"]`
       - Verify hidden div exists with `data-canvas-state` attributes

    4. **Production Build Verification** (40 lines)
       - Build production app: `npm run tauri:build`
       - Locate built app (show paths for macOS .app, Windows .exe, Linux)
       - Launch production build
       - Open DevTools (if available) or use remote debugging

       **Production-Specific Tests:**
       - Repeat Tests 1-4 from development build
       - **Critical:** Verify accessibility trees survived minification
         - Search DOM for `[role="log"]`
         - Verify `data-canvas-state` attributes present
         - Verify `style="display:none"` preserved (not removed as "dead code")

       **Note on Minification:**
       If accessibility divs are missing, add to `next.config.js`:
       ```javascript
       module.exports = {
         compiler: {
           removeConsole: false, // Preserve console for debugging
           terserOptions: {
             compress: {
               drop_console: false,
             },
           },
         },
       };
       ```

    5. **Real-Time Canvas Updates Test** (20 lines)
       - Open a page with live canvas updates (e.g., agent operation tracker)
       - In DevTools Console, subscribe to changes:
       ```javascript
       const unsubscribe = window.atom.canvas.subscribeAll((event) => {
         console.log('Canvas state changed:', event);
       });
       // Trigger a canvas state change (e.g., start an agent operation)
       // Verify callback fires with correct data
       unsubscribe();
       ```

    6. **Troubleshooting** (20 lines)
       - **Issue:** `window.atom.canvas is undefined`
         - **Cause:** Component not mounted yet or useCanvasState not called
         - **Fix:** Navigate to page with canvas component, wait for mount

       - **Issue:** Accessibility divs missing in production
         - **Cause:** Terser minification removing "dead code"
         - **Fix:** Add data-testid attributes (always preserved)

       - **Issue:** `window.__TAURI__ undefined` in dev build
         - **Cause:** Dev server not using Tauri webview
         - **Fix:** Always use `npm run tauri:dev`, not `npm run dev`

    7. **Success Criteria Checklist** (10 lines)
       - [ ] Development build: window.atom.canvas accessible
       - [ ] Development build: All API methods functional
       - [ ] Development build: Tauri IPC coexists
       - [ ] Production build: window.atom.canvas accessible
       - [ ] Production build: Accessibility trees present
       - [ ] Real-time updates work via subscription

    **DO NOT:**
    - Include screenshots (documentation is text-only for now)
    - Cover backend API testing (out of scope for canvas context)
    - Duplicate content from Phase 20 verification (focus on Tauri-specific issues)
  </action>
  <verify>
    File exists at `docs/TAURI_CANVAS_VERIFICATION.md` with 150+ lines
    Run: `wc -l docs/TAURI_CANVAS_VERIFICATION.md` (should be >150)
  </verify>
  <done>
    Documentation file exists with comprehensive manual testing guide including development build tests, production build verification, real-time update tests, troubleshooting, and success criteria checklist
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Plan 28 (Tauri Canvas AI Context Verification) complete: Unit tests (Plan 01), Component tests (Plan 02), and Manual testing documentation (Plan 03) created for verifying Phase 20's canvas AI context works in Tauri desktop app.</what-built>
  <how-to-verify>
    **Manual Testing Required:**

    1. **Verify Unit Tests (Plan 01) Pass:**
       ```bash
       cd frontend-nextjs
       npm test -- --testPathPattern="canvas-(api|state-hook)"
       ```
       Expected: 25+ tests pass, coverage >80%

    2. **Verify Component Tests (Plan 02) Pass:**
       ```bash
       npm test -- --testPathPattern="canvas-accessibility-tree|agent-operation-tracker"
       ```
       Expected: 12+ tests pass, accessibility tree verified

    3. **Verify Tauri Development Build:**
       ```bash
       cd frontend-nextjs
       npm run tauri:dev
       ```
       When app opens:
       - Open DevTools (Cmd+Option+I or Ctrl+Shift+I)
       - In Console, run: `typeof window.atom?.canvas`
       - Expected output: `"object"`
       - Run: `typeof window.__TAURI__`
       - Expected output: `"object"` (both coexist)

    4. **Verify Accessibility Tree in DOM:**
       - In DevTools Elements tab, search for `[role="log"]`
       - Verify hidden div exists with `data-canvas-state` attribute
       - Expand div and verify JSON content is present

    5. **Review Documentation:**
       - Read `docs/TAURI_CANVAS_VERIFICATION.md`
       - Verify all test steps are clear and reproducible

    **Approval Signal:** Type "approved" if all tests pass and documentation is complete, or describe issues to fix.
  </how-to-verify>
  <resume-signal>Type "approved" to mark Phase 28 complete, or describe specific issues found during Tauri testing</resume-signal>
</task>

</tasks>

<verification>
Overall phase verification:
- All unit tests pass (Plan 01): `npm test -- --testPathPattern="canvas-(api|state-hook)"`
- All component tests pass (Plan 02): `npm test -- --testPathPattern="canvas-accessibility-tree|agent-operation-tracker"`
- Manual testing documentation exists at `docs/TAURI_CANVAS_VERIFICATION.md`
- Human verification confirms canvas AI context accessible in Tauri dev environment
- Human verification confirms accessibility trees present in DOM
</verification>

<success_criteria>
- 37+ tests pass across Plan 01 and Plan 02
- Code coverage >80% for canvas hooks and components tested
- Manual testing guide enables reproducible Tauri verification
- Development build verified: window.atom.canvas accessible
- Accessibility trees verified in Tauri webview DOM
</success_criteria>

<output>
After completion and human approval, create `.planning/phases/28-tauri-canvas-ai-accessibility/28-SUMMARY.md` with:
- Test results summary (pass/fail counts, coverage metrics)
- Manual testing outcomes (dev build, production build status)
- Any issues found and resolutions
- Confirmation that Phase 20 canvas AI context works in Tauri
</output>
