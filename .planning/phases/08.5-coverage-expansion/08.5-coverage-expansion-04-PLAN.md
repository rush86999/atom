---
phase: 08.5-coverage-expansion
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/unit/test_validation_service.py
  - backend/tests/unit/test_ai_workflow_optimizer.py
  - backend/tests/unit/test_meta_automation.py
  - backend/tests/unit/test_advanced_workflow_endpoints.py
autonomous: true

must_haves:
  truths:
    - "validation_service.py has baseline test coverage for validation operations"
    - "ai_workflow_optimizer.py has baseline test coverage for optimization logic"
    - "meta_automation.py has baseline test coverage for automation features"
    - "advanced_workflow_endpoints.py has baseline test coverage for advanced endpoints"
    - "All four files show >0% coverage in coverage report"
  artifacts:
    - path: "backend/tests/unit/test_validation_service.py"
      provides: "Validation service unit tests"
      min_lines: 180
    - path: "backend/tests/unit/test_ai_workflow_optimizer.py"
      provides: "AI optimizer unit tests"
      min_lines: 180
    - path: "backend/tests/unit/test_meta_automation.py"
      provides: "Meta automation unit tests"
      min_lines: 100
    - path: "backend/tests/unit/test_advanced_workflow_endpoints.py"
      provides: "Advanced workflow endpoints unit tests"
      min_lines: 180
  key_links:
    - from: "backend/tests/unit/test_validation_service.py"
      to: "core/validation_service.py"
      via: "direct import and testing"
      pattern: "from core.validation_service import"
    - from: "backend/tests/unit/test_ai_workflow_optimizer.py"
      to: "core/ai_workflow_optimizer.py"
      via: "direct import and testing"
      pattern: "from core.ai_workflow_optimizer import"
---

<objective>
Create baseline unit tests for 4 zero-coverage validation, optimization, and endpoint files to establish measurable coverage progress.

**Purpose:** Target validation/optimization files and advanced workflow endpoints (50-275 lines) with focused testing patterns.

**Output:** 4 new test files with ~640 lines total, achieving 30-50% coverage on target files.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/08-80-percent-coverage-push/08-80-percent-coverage-push-10-SUMMARY.md
@backend/tests/unit/test_workflow_engine.py
@backend/tests/unit/test_atom_agent_endpoints.py
@backend/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Create baseline tests for validation_service.py</name>
  <files>backend/tests/unit/test_validation_service.py</files>
  <action>
    Create test file for core/validation_service.py (263 lines):

    1. Import pattern: Follow established pattern from test_workflow_engine.py
    2. Fixtures:
       - validator_instance: Direct instantiation
       - sample_schemas: Dict with various JSON schemas
       - valid_invalid_data: Parametrized test data
    3. Test classes:
       - TestValidationServiceInit: Test initialization, schema loading
       - TestSchemaValidation: Test validate_against_schema, type checking
       - TestBusinessRules: Test business rule validation, custom rules
       - TestValidationErrorHandling: Test error messages, error aggregation
       - TestValidationCaching: Test schema caching, performance
    4. Use @pytest.mark.parametrize for testing various invalid inputs
    5. Target: ~180 lines, 12-15 tests

    Focus on validation rules rather than JSON schema library internals.
  </action>
  <verify>pytest backend/tests/unit/test_validation_service.py -v --cov=core/validation_service --cov-report=term-missing</verify>
  <done>Test file exists with 12+ tests, coverage shows >0% for validation_service.py</done>
</task>

<task type="auto">
  <name>Create baseline tests for ai_workflow_optimizer.py</name>
  <files>backend/tests/unit/test_ai_workflow_optimizer.py</files>
  <action>
    Create test file for core/ai_workflow_optimizer.py (255 lines):

    1. Import pattern: Follow established pattern from test_workflow_engine.py
    2. Fixtures:
       - mock_llm_service: AsyncMock for AI recommendations
       - mock_analytics: AsyncMock for performance data
       - optimizer_instance: Direct instantiation with mocks
       - sample_workflow: Dict with workflow structure
    3. Test classes:
       - TestOptimizerInit: Test initialization, AI handler setup
       - TestWorkflowOptimization: Test optimize_workflow, step suggestions
       - TestPerformanceAnalysis: Test bottleneck detection, optimization opportunities
       - TestAIGeneratedSuggestions: Test AI-driven recommendations
       - TestOptimizationApplication: Test applying optimizations safely
    4. Mock AI responses for deterministic testing
    5. Target: ~180 lines, 12-15 tests

    Test optimization logic, not actual AI API calls.
  </action>
  <verify>pytest backend/tests/unit/test_ai_workflow_optimizer.py -v --cov=core/ai_workflow_optimizer --cov-report=term-missing</verify>
  <done>Test file exists with 12+ tests, coverage shows >0% for ai_workflow_optimizer.py</done>
</task>

<task type="auto">
  <name>Create baseline tests for meta_automation.py and advanced_workflow_endpoints.py</name>
  <files>backend/tests/unit/test_meta_automation.py backend/tests/unit/test_advanced_workflow_endpoints.py</files>
  <action>
    Create test files for core/meta_automation.py (51 lines) and core/advanced_workflow_endpoints.py (275 lines):

    For test_meta_automation.py (smaller file, fewer tests):
    1. Fixtures: mock_automation_engine, meta_config
    2. Test classes: TestMetaAutomationInit, TestAutomationTriggers, TestAutomationExecution
    3. Test meta-automation logic (automating automation, recursive patterns)
    4. Target: ~100 lines, 8-10 tests

    For test_advanced_workflow_endpoints.py:
    1. Follow FastAPI TestClient pattern from test_atom_agent_endpoints.py
    2. Fixtures: app, client, mock_advanced_workflow_service
    3. Test classes: TestAdvancedEndpointsInit, TestAdvancedWorkflowCRUD, TestWorkflowExecutionEndpoints, TestWorkflowAnalyticsEndpoints
    4. Test advanced workflow features (parallel execution, conditional branching)
    5. Target: ~180 lines, 12-15 tests

    Use @patch for mocking service layer in endpoints.
  </action>
  <verify>pytest backend/tests/unit/test_meta_automation.py backend/tests/unit/test_advanced_workflow_endpoints.py -v --cov=core/meta_automation --cov=core/advanced_workflow_endpoints --cov-report=term-missing</verify>
  <done>Both test files exist with tests, coverage shows >0% for both files</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Run: pytest backend/tests/unit/test_validation_service.py backend/tests/unit/test_ai_workflow_optimizer.py backend/tests/unit/test_meta_automation.py backend/tests/unit/test_advanced_workflow_endpoints.py -v
2. Verify: All 4 files show >0% coverage in: pytest --cov=core/validation_service --cov=core/ai_workflow_optimizer --cov=core/meta_automation --cov=core/advanced_workflow_endpoints --cov-report=term-missing
3. Confirm: No import errors or test collection failures
</verification>

<success_criteria>
- 4 new test files created
- All tests pass (no failures, minimal skips)
- Each target file shows >0% coverage (baseline established)
- Overall coverage increases by measurable amount
</success_criteria>

<output>
After completion, create `.planning/phases/08.5-coverage-expansion/08.5-coverage-expansion-04-SUMMARY.md` with:
- Lines of test code added
- Coverage percentage achieved for each file
- Any patterns or issues discovered
- Next file recommendations
</output>
