---
phase: 67-ci-cd-pipeline-fixes
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .github/workflows/ci.yml
  - .github/workflows/deploy.yml
  - backend/Dockerfile
  - backend/.dockerignore
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Docker build cache hit rate exceeds 75% (layer caching working)"
    - "Build time reduced by 60%+ (6m 42s → <2m 40s with cache hits)"
    - "Inline cache export enabled for distributed build acceleration"
    - "Dependencies cached separately from application code (multi-stage pattern)"
    - "BuildKit cache mount used for pip dependency caching"
    - "No cache miss on unchanged code layers"
  artifacts:
    - path: backend/Dockerfile
      provides: "Optimized multi-stage Dockerfile with layer caching"
      min_lines: 120
      contains: "COPY requirements.txt"
    - path: .github/workflows/ci.yml
      provides: "CI workflow with BuildKit cache configuration (mode=max, inline export)"
      exports: ["build-docker"]
    - path: .github/workflows/deploy.yml
      provides: "Deploy workflow with BuildKit cache configuration"
      exports: ["build"]
    - path: backend/.dockerignore
      provides: "Docker ignore file to exclude unnecessary files from build context"
      min_lines: 30
  key_links:
    - from: ".github/workflows/ci.yml"
      to: "backend/Dockerfile"
      via: "cache-from: type=gha,mode=max and cache-to: type=inline,mode=max"
      pattern: "mode=max"
    - from: "backend/Dockerfile"
      to: "backend/.dockerignore"
      via: "COPY requirements.txt with layer optimization"
      pattern: "^\\s*COPY requirements.txt"
    - from: ".github/workflows/deploy.yml"
      to: "backend/Dockerfile"
      via: "BuildKit inline cache export for distributed builds"
      pattern: "type=inline,mode=max"
---

<objective>
Optimize Docker build process with BuildKit layer caching, dependency preloading, and inline cache export to achieve 75% build time reduction.

Purpose: Current Docker builds take 6m 42s due to cache misses on every build. Research identified `mode=min` only caching final layer, missing intermediate layer benefits. This plan implements layer caching, dependency preloading, and BuildKit optimizations.

Output: 75% faster Docker builds (6m 42s → 1m 35s), 75%+ cache hit rate, inline cache export for distributed builds.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md

@.planning/phases/67-ci-cd-pipeline-fixes/67-RESEARCH.md
@.github/workflows/ci.yml
@.github/workflows/deploy.yml
@backend/Dockerfile
@backend/.dockerignore
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Research Context
Phase 67 research identified Docker build inefficiencies:
- **Cache Mode**: `mode=min` only caches final layer (line 514-521 in ci.yml)
- **Layer Ordering**: Requirements.txt copied after source code (prevents layer reuse)
- **No BuildKit Export**: Missing inline cache for distributed builds
- **No Dependency Preloading**: Multi-stage builds don't separate dependencies from code

**Performance Impact** (from research):
- Current: No cache data available, full rebuild every time (6m 42s)
- Industry Standard: 75% reduction with proper layer caching (6m 42s → 1m 35s)
- Potential: 60-90% faster builds with BuildKit optimizations

**Standard Stack**: Docker Buildx v3 for multi-platform builds, GitHub Actions cache@v4 for layer storage, BuildKit cache mounts for pip caching.

**Key Decision**: Switch from `mode=min` to `mode=max` to cache all layers. Add inline cache export for distributed build acceleration across CI runners.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Optimize Dockerfile for layer caching and dependency preloading</name>
  <files>backend/Dockerfile</files>
  <action>
    Rewrite backend/Dockerfile with multi-stage build and layer optimization:

    ```dockerfile
    # Source: https://docs.docker.com/build/cache/backends/gha/
    # Multi-stage build with layer caching optimization

    FROM python:3.11-slim as builder

    # Build arguments for optional dependencies
    ARG ENABLE_DOCLING=false
    ARG ENVIRONMENT=production

    # Set environment variables
    ENV PYTHONUNBUFFERED=1 \
        PYTHONDONTWRITEBYTECODE=1 \
        PIP_NO_CACHE_DIR=1 \
        PIP_DISABLE_PIP_VERSION_CHECK=1

    WORKDIR /app

    # Install system dependencies
    RUN apt-get update && apt-get install -y --no-install-recommends \
        gcc \
        g++ \
        libpq-dev \
        && rm -rf /var/lib/apt/lists/*

    # Copy requirements FIRST (before source code)
    # This layer is cached unless requirements.txt changes
    COPY requirements.txt requirements-testing.txt requirements-docling.txt* ./

    # Use BuildKit cache mount for pip cache
    # --mount=type=cache caches pip downloads across builds
    RUN --mount=type=cache,target=/root/.cache/pip \
        pip install --no-cache-dir --upgrade pip && \
        pip install --no-cache-dir -r requirements.txt

    # Optional: Test dependencies (separate layer)
    RUN --mount=type=cache,target=/root/.cache/pip \
        if [ -f requirements-testing.txt ]; then \
            pip install --no-cache-dir -r requirements-testing.txt; \
        fi

    # Optional: Docling dependencies (separate layer, only if enabled)
    RUN if [ "$ENABLE_DOCLING" = "true" ] && [ -f requirements-docling.txt ]; then \
        pip install --no-cache-dir -r requirements-docling.txt; \
        fi

    # Copy source code AFTER dependencies
    # This layer is rebuilt on every code change (but dependencies remain cached)
    COPY . .

    # Create non-root user
    RUN useradd -m -u 1000 atomuser && \
        chown -R atomuser:atomuser /app

    # Production stage
    FROM python:3.11-slim as production

    # Copy Python dependencies from builder stage
    COPY --from=builder /usr/local/lib/python3.11/site-packages /usr/local/lib/python3.11/site-packages
    COPY --from=builder /usr/local/bin /usr/local/bin

    # Copy application code from builder stage
    COPY --from=builder --chown=atomuser:atomuser /app /app

    # Set working directory and user
    WORKDIR /app
    USER atomuser

    # Health check
    HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
        CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health/live')" || exit 1

    # Expose port
    EXPOSE 8000

    # Run application
    CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```

    **Key optimizations**:
    1. **Requirements before source**: COPY requirements.txt before COPY . . (caches dependencies separately)
    2. **BuildKit cache mount**: `--mount=type=cache,target=/root/.cache/pip` for pip downloads
    3. **Multi-stage build**: Separate builder and production stages to reduce final image size
    4. **Non-root user**: atomuser with UID 1000 for security
    5. **Health check**: Built-in health check for Kubernetes probes

    Remove any existing Dockerfile backup:
    ```bash
    rm -f backend/Dockerfile.backup
    ```
  </action>
  <verify>
    Run: docker build -t atom-backend:test ./backend (build succeeds)
    Run: docker history atom-backend:test | grep -E "requirements|COPY" (shows layer ordering)
    Run: docker images atom-backend:test --format "{{.Size}}" (image size <1GB)
  </verify>
  <done>
    Dockerfile optimized with layer caching, dependency preloading, and BuildKit cache mounts. Dependencies cached separately from application code.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create comprehensive .dockerignore file</name>
  <files>backend/.dockerignore</files>
  <action>
    Create backend/.dockerignore to exclude unnecessary files from build context:

    ```
    # Git
    .git
    .gitignore
    .github

    # Python
    __pycache__
    *.py[cod]
    *$py.class
    *.so
    *.egg
    *.egg-info
    dist
    build
    .eggs
    .pip-cache
    .pip
    .pytest_cache
    .mypy_cache
    .coverage
    .cover
    *.cover
    htmlcov
    .tox
    .venv
    venv
    env
    ENV
    env.bak
    venv.bak

    # Development
    *.log
    *.db
    *.sqlite
    *.sqlite3
    .DS_Store
    .vscode
    .idea
    *.swp
    *.swo
    *~

    # Testing
    tests
    test_*.py
    *_test.py
    .pytest_cache
    coverage.xml
    *.cover
    .coverage
    htmlcov/

    # Documentation
    docs
    *.md
    README.md
    CHANGELOG.md
    CONTRIBUTING.md

    # CI/CD
    .gitlab-ci.yml
    .travis.yml
    circle.yml
    .circleci
    codecov.yml

    # Planning
    .planning

    # Data files
    data/
    *.csv
    *.json
    *.xlsx
    *.parquet

    # LanceDB (not needed in container)
    data/lancedb/
    *.lance

    # Alembic (not needed in production image)
    alembic/versions/*.pyc
    alembic/versions/__pycache__

    # Temporary files
    tmp/
    temp/
    *.tmp

    # OS
    Thumbs.db
    .DS_Store
    ```

    **Rationale**: Excluding test files, documentation, and development artifacts reduces build context size by ~80%, improving build performance.
  </action>
  <verify>
    Run: docker build -t atom-backend:test ./backend --progress=plain | grep "COPY" (shows reduced COPY operations)
    Run: du -sh backend/ (before .dockerignore ~500MB, after context reduction ~100MB)
  </verify>
  <done>
    .dockerignore file created with comprehensive exclusions. Build context reduced by ~80%, improving build performance.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update CI workflow with BuildKit cache configuration (mode=max)</name>
  <files>.github/workflows/ci.yml</files>
  <action>
    Update .github/workflows/ci.yml to use BuildKit cache with mode=max:

    **Add Docker build job** (after frontend-build job, line 114):
    ```yaml
  build-docker:
    runs-on: ubuntu-latest
    needs: backend-test-full

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-

      - name: Build Docker image (CI only, no push)
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: false  # Don't push to registry (CI only)
          tags: atom-backend:ci
          cache-from: |
            type=gha  # Restore from GitHub Actions cache
            type=registry,ref=atom-backend:buildcache  # Restore from registry cache
          cache-to: |
            type=gha,mode=max  # Save to GitHub Actions cache (all layers)
            type=inline,mode=max  # Embed cache in image for distributed builds
          build-args: |
            VERSION=${{ github.sha }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            ENABLE_DOCLING=false

      - name: Image digest
        run: echo "Image built with digest ${{ steps.build.outputs.digest }}"
    ```

    **Key changes from current ci.yml**:
    - Change `cache-to: type=gha,mode=min` to `cache-to: type=gha,mode=max`
    - Add inline cache export: `type=inline,mode=max`
    - Add registry cache fallback: `type=registry,ref=atom-backend:buildcache`
    - Add build-args for VERSION and BUILD_DATE (cache invalidation)

    Remove any existing Docker build steps in backend-test-full job (consolidate into build-docker job).
  </action>
  <verify>
    Run: grep -c "mode=max" .github/workflows/ci.yml returns >= 2
    Run: grep "type=inline" .github/workflows/ci.yml returns match
    Run: grep "cache-from:" .github/workflows/ci.yml returns match
  </verify>
  <done>
    CI workflow updated with BuildKit cache configuration (mode=max). Inline cache export enabled for distributed builds.
  </done>
</task>

<task type="auto">
  <name>Task 4: Update deploy workflow with BuildKit cache configuration</name>
  <files>.github/workflows/deploy.yml</files>
  <action>
    Update .github/workflows/deploy.yml build job with BuildKit cache optimization:

    **Update build job** (line 73-115):
    ```yaml
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to container registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_PASSWORD }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true  # Push to registry
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: |
            type=gha  # Restore from GitHub Actions cache
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache  # Restore from registry
          cache-to: |
            type=gha,mode=max  # Save to GitHub Actions cache (all layers)
            type=inline,mode=max  # Embed cache in image for distributed builds
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max  # Save to registry
          build-args: |
            VERSION=${{ github.sha }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            ENVIRONMENT=production
            ENABLE_DOCLING=true

      - name: Image digest
        run: echo "Image built with digest ${{ steps.meta.outputs.digest }}"

      - name: Image size
        run: |
          IMAGE_TAG="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"
          docker pull "$IMAGE_TAG"
          docker images "$IMAGE_TAG" --format "Size: {{.Size}}"
    ```

    **Key changes from current deploy.yml**:
    - Change `cache-from: type=gha` to multi-source cache (gha + registry)
    - Change `cache-to: type=gha,mode=max` to multi-destination cache (gha + inline + registry)
    - Add inline cache export: `type=inline,mode=max`
    - Add registry cache export: `type=registry,ref=...:buildcache,mode=max`
    - Add image size reporting step (detects image bloat)
    - Add build-args for VERSION, BUILD_DATE, ENVIRONMENT, ENABLE_DOCLING

    Update deploy-staging job to use new build cache:
    ```yaml
    - name: Update deployment image
      run: |
        export KUBECONFIG=kubeconfig
        kubectl set image deployment/atom atom=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

    - name: Verify image pull
      run: |
        export KUBECONFIG=kubeconfig
        kubectl rollout status deployment/atom --timeout=5m
        # Verify image was pulled successfully
        POD=$(kubectl get pod -l app=atom -o jsonpath='{.items[0].metadata.name}')
        kubectl describe pod "$POD" | grep "Image:" | grep "${{ github.sha }}"
    ```
  </action>
  <verify>
    Run: grep -c "mode=max" .github/workflows/deploy.yml returns >= 2
    Run: grep "type=inline" .github/workflows/deploy.yml returns match
    Run: grep "type=registry" .github/workflows/deploy.yml returns match
  </verify>
  <done>
    Deploy workflow updated with multi-source cache (gha + registry) and multi-destination cache export (inline + registry). Registry cache enables distributed build acceleration across CI runners.
  </done>
</task>

<task type="auto">
  <name>Task 5: Add BuildKit cache metrics and validation</name>
  <files>.github/workflows/ci.yml</files>
  <action>
    Add cache validation step to CI workflow to measure cache effectiveness:

    **Add after build-docker job** (line 200):
    ```yaml
      - name: Report build cache metrics
        run: |
          echo "=== Docker Build Cache Metrics ==="
          echo "Image: atom-backend:ci"
          docker images atom-backend:ci --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}\t{{.CreatedAt}}"

          # Report cache size
          if [ -d "/tmp/.buildx-cache" ]; then
            CACHE_SIZE=$(du -sh /tmp/.buildx-cache | cut -f1)
            echo "BuildKit cache size: $CACHE_SIZE"
          fi

          # Report layer count
          LAYERS=$(docker history atom-backend:ci --format "{{.ID}}" | wc -l)
          echo "Total layers: $LAYERS"

          # Report cache hit rate (if available in build output)
          # BuildKit outputs cache hit/miss statistics in build output
          echo "✅ Build completed - check build output for cache hit/miss statistics"

      - name: Validate layer caching
        run: |
          echo "=== Validating Layer Caching ==="

          # Check if requirements layer is cached
          docker history atom-backend:ci --format "{{.CreatedBy}}" | grep -q "requirements.txt" && \
            echo "✅ Requirements layer found" || \
            echo "⚠️ Requirements layer not found"

          # Check if build cache mount was used
          docker history atom-backend:ci --format "{{.CreatedBy}}" | grep -q "/root/.cache/pip" && \
            echo "✅ BuildKit cache mount used" || \
            echo "⚠️ BuildKit cache mount not detected"

          # Verify multi-stage build
          STAGES=$(docker history atom-backend:ci --format "{{.CreatedBy}}" | grep -c "FROM python")
          if [ "$STAGES" -ge 2 ]; then
            echo "✅ Multi-stage build detected ($STAGES stages)"
          else
            echo "⚠️ Multi-stage build not detected"
          fi
    ```

    **Add cache hit rate tracking to deploy.yml** (after build job):
    ```yaml
      - name: Report production build metrics
        if: always()
        run: |
          echo "=== Production Build Metrics ==="
          IMAGE_TAG="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}"
          docker pull "$IMAGE_TAG"

          echo "Image: $IMAGE_TAG"
          docker images "$IMAGE_TAG" --format "Size: {{.Size}}"
          docker history "$IMAGE_TAG" --no-trunc --format "table {{.CreatedBy}}\t{{.Size}}" | head -20

          # Estimate cache hit rate from build output
          # BuildKit outputs: "CACHED" for cached layers, "DONE" for new layers
          echo "✅ Build completed - check GitHub Actions log for cache hit/miss statistics"
    ```

    Add cache size monitoring step (prevents cache bloat):
    ```yaml
      - name: Monitor cache size
        run: |
          # Check GitHub Actions cache size
          echo "GitHub Actions cache usage:"
          gh cache list --repo ${{ github.repository }} --json key,sizeInBytes --jq '.[] | select(.key | contains("buildx")) | "\(.key): \(.sizeInBytes / 1024 / 1024) MB"'

          # Warn if cache exceeds 5GB
          CACHE_SIZE=$(gh cache list --repo ${{ github.repository }} --json sizeInBytes --jq '[.[] | select(.key | contains("buildx")) | .sizeInBytes] | add / 1024 / 1024 / 1024')
          if (( $(echo "$CACHE_SIZE > 5" | bc -l) )); then
            echo "⚠️ Cache size large: $CACHE_SIZE GB (consider cleanup)"
          fi
    ```
  </action>
  <verify>
    Run: grep "cache metrics" .github/workflows/ci.yml returns match
    Run: grep "validate layer caching" .github/workflows/ci.yml returns match
    Run: docker history atom-backend:ci --format "{{.CreatedBy}}" | grep "requirements.txt" (layer exists)
  </verify>
  <done>
    Build cache metrics and validation steps added to CI and deploy workflows. Cache hit rate monitored, layer caching validated, cache size tracked to prevent bloat.
  </done>
</task>

</tasks>

<verification>
Overall phase verification steps:

1. **Dockerfile Optimization Verification**:
   ```bash
   # Verify layer ordering (requirements before source)
   grep -A 5 "COPY requirements.txt" backend/Dockerfile | grep -q "COPY . ."

   # Verify BuildKit cache mount
   grep -q "type=cache,target=/root/.cache/pip" backend/Dockerfile

   # Verify multi-stage build
   grep -c "^FROM python" backend/Dockerfile  # Should return 2

   # Test build performance
   time docker build -t atom-backend:test ./backend

   # Verify image size (<1GB)
   docker images atom-backend:test --format "{{.Size}}"
   ```

2. **BuildKit Cache Verification**:
   ```bash
   # Verify mode=max in both workflows
   grep "mode=max" .github/workflows/ci.yml
   grep "mode=max" .github/workflows/deploy.yml

   # Verify inline cache export
   grep "type=inline,mode=max" .github/workflows/ci.yml
   grep "type=inline,mode=max" .github/workflows/deploy.yml

   # Verify registry cache
   grep "type=registry" .github/workflows/deploy.yml
   ```

3. **Build Performance Verification**:
   ```bash
   # First build (no cache)
   time docker build -t atom-backend:base ./backend
   # Expected: 5-7 minutes

   # Second build (with cache)
   time docker build -t atom-backend:cached ./backend
   # Expected: <2 minutes (75% reduction)

   # Third build (code change only)
   echo "# test" >> backend/README.md
   time docker build -t atom-backend:code-change ./backend
   # Expected: <2 minutes (requirements cached)
   ```

4. **Cache Hit Rate Verification**:
   ```bash
   # Run CI workflow and check build output
   gh run view --log | grep "CACHED"

   # Verify cache hit rate >75%
   # BuildKit outputs: "CACHED" for cached layers, "DONE" for new layers
   # Calculate: (CACHED / (CACHED + DONE)) * 100
   ```

**Success Criteria**:
- [ ] mode=max configured in both ci.yml and deploy.yml
- [ ] Inline cache export enabled (type=inline,mode=max)
- [ ] Registry cache configured for distributed builds
- [ ] Build time reduced by 60%+ (6m 42s → <2m 40s)
- [ ] Cache hit rate >75% on consecutive builds
- [ ] .dockerignore reduces build context by ~80%
- [ ] Multi-stage Dockerfile separates dependencies from code
</verification>

<success_criteria>
**Docker Build Optimization Complete When:**

1. **Build Time Reduction**: 60-75% faster builds with cache hits (6m 42s → 1m 35s target)
2. **Cache Hit Rate**: >75% layer cache hit rate on consecutive builds
3. **BuildKit Configuration**: mode=max enabled in CI and deploy workflows
4. **Inline Cache Export**: Embedded cache metadata in images for distributed builds
5. **Dependency Preloading**: Requirements.txt copied before source code (layer separation)
6. **Build Context Reduction**: .dockerignore reduces context size by ~80%

**Measurable Outcomes**:
- First build (cold cache): 5-7 minutes
- Second build (warm cache): <2 minutes (60-75% reduction)
- Code-only change: <90 seconds (requirements cached)
- Dependency change: 2-3 minutes (code cached)
- Cache hit rate: 75-85% on average
</success_criteria>

<output>
After completion, create `.planning/phases/67-ci-cd-pipeline-fixes/67-02-SUMMARY.md` with:
- Build time comparison (before vs after optimization)
- Cache hit rate statistics from 5 consecutive CI runs
- Layer cache breakdown (requirements layer, code layer, base image layer)
- Dockerfile optimization changes (multi-stage, cache mounts, layer ordering)
- Build context size reduction (before vs after .dockerignore)
</output>
