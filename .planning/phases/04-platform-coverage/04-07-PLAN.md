---
phase: 04-platform-coverage
plan: 07
type: execute
wave: 2
depends_on: ["04-05"]
files_modified:
  - frontend-nextjs/src-tauri/tests/integration/device_capabilities_test.rs
  - backend/tests/test_desktop_device_governance.py
autonomous: true

must_haves:
  truths:
    - "Desktop camera tests verify camera capture with platform-specific implementations"
    - "Screen recording tests verify start/stop recording with ffmpeg"
    - "Location service tests verify IP geolocation fallback"
    - "Notification tests verify desktop notification sending"
    - "Governance tests verify device capability authorization for desktop"
  artifacts:
    - path: "frontend-nextjs/src-tauri/tests/integration/device_capabilities_test.rs"
      provides: "Desktop device capability tests"
      min_lines: 150
    - path: "backend/tests/test_desktop_device_governance.py"
      provides: "Desktop device governance tests"
      min_lines: 100
  key_links:
    - from: "device_capabilities_test.rs"
      to: "main.rs device commands"
      via: "test camera_snap, screen_record_start, get_location"
      pattern: "#\[tauri::command\].*camera|location|notification"
    - from: "test_desktop_device_governance.py"
      to: "backend device governance"
      via: "test desktop device permissions"
      pattern: "desktop.*device|governance"
---

<objective>
Create desktop device capability tests for camera, screen recording, location, and notifications with governance validation.

**Purpose:** Test desktop-specific device capabilities that differ from mobile implementations. Desktop uses platform-specific tools (ffmpeg for camera/recording, IP geolocation for location, native notifications) and needs governance validation to ensure proper authorization.

**Output:**
- `device_capabilities_test.rs` - Rust tests for desktop device commands
- `test_desktop_device_governance.py` - Python tests for desktop device governance
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/04-platform-coverage/04-RESEARCH.md
@.planning/REQUIREMENTS.md

# Existing Code
@frontend-nextjs/src-tauri/src/main.rs
@backend/tests/test_device_governance.py
@backend/tests/test_mobile_auth.py
@.planning/phases/04-platform-coverage/04-05-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Create desktop device capability tests</name>
  <files>frontend-nextjs/src-tauri/tests/integration/device_capabilities_test.rs</files>
  <action>
    Create `frontend-nextjs/src-tauri/tests/integration/device_capabilities_test.rs` with:
    1. Test suite for camera capture command (camera_snap)
    2. Test suite for screen recording commands (screen_record_start, screen_record_stop)
    3. Test suite for location service (get_location with IP geolocation fallback)
    4. Test suite for notification sending (send_notification)
    5. Test suite for shell command execution (execute_shell_command with whitelist)
    6. Mock external dependencies (ffmpeg, IP geolocation API, notification service)

    Pattern:
    ```rust
    #[cfg(test)]
    mod tests {
        use super::*;
        use std::process::Command;

        #[test(tokio::test)]
        async fn test_get_system_info() {
            let result = get_system_info().await;
            assert!(result.is_ok());
            let json = result.unwrap();
            assert_eq!(json["platform"], "macos"); // or "windows", "linux"
        }

        #[test(tokio::test)]
        async fn test_send_notification() {
            // Mock notification service
            // Test notification builder
            let result = send_notification(
                app_handle,
                "Test Title".to_string(),
                "Test Body".to_string(),
                None,
                None,
            ).await;
            assert!(result.is_ok());
        }

        #[test]
        fn test_command_whitelist() {
            // Test that only allowed commands can execute
            let allowed = vec!["ls", "pwd", "cat"];
            let command = "ls";
            assert!(allowed.contains(&command));
        }
    }
    ```

    IMPORTANT: The main.rs has extensive device capability code (lines 868-1652):
    - camera_snap: Platform-specific ffmpeg commands for macOS (avfoundation), Windows (dshow), Linux (v4l2)
    - screen_record_start/stop: ffmpeg recording with platform-specific arguments
    - get_location: IP geolocation fallback (curl to ipinfo.io)
    - send_notification: tauri_plugin_notification
    - execute_shell_command: Whitelist validation

    Focus testing on:
    - System info platform detection (macos/windows/linux)
    - Command whitelist validation
    - Notification result structure
    - Mock external calls (ffmpeg, curl, IP geolocation)

    For camera and screen recording:
    - Test ffmpeg availability detection logic
    - Test platform-specific argument construction
    - Test file path generation for temp directory
    - Add TODO for full integration tests (require ffmpeg installed)

    For location:
    - Test IP geolocation JSON parsing
    - Test fallback behavior when services unavailable
    - Test error handling for network failures

    NOTE: Full device capability testing requires actual hardware and ffmpeg. Add TODO comments documenting integration test requirements.
  </action>
  <verify>
    Run `cd frontend-nextjs/src-tauri && cargo test device_capabilities_test` - tests pass
  </verify>
  <done>
    Device capability tests verify system info, notifications, command whitelist, error handling with >75% coverage
  </done>
</task>

<task type="auto">
  <name>Create desktop device governance tests</name>
  <files>backend/tests/test_desktop_device_governance.py</files>
  <action>
    Create `backend/tests/test_desktop_device_governance.py` with:
    1. Test suite for desktop device registration (similar to mobile but with desktop-specific fields)
    2. Test suite for desktop device capability governance (camera, screen recording, shell execution)
    3. Test suite for desktop permission requirements (AUTONOMOUS agents only for shell execution)
    4. Test suite for desktop device session management
    5. Use factory_boy patterns and TestClient (follow test_device_governance.py and test_mobile_auth.py)

    Pattern:
    ```python
    import pytest
    from fastapi.testclient import TestClient
    from unittest.mock import patch
    from core.models import DesktopDevice, User
    from factories.user_factory import UserFactory

    @pytest.mark.asyncio
    async def test_desktop_device_registration(db_session: Session):
        """Test desktop device registration."""
        user = await UserFactory.create_async(db_session)

        device = DesktopDevice(
            user_id=str(user.id),
            platform="macos",
            device_info={"model": "MacBook Pro", "os_version": "14.0"},
            status="active"
        )
        db_session.add(device)
        db_session.commit()

        assert device.device_id is not None
        assert device.platform == "macos"

    @pytest.mark.asyncio
    async def test_desktop_shell_command_governance(db_session: Session, test_client):
        """Test that shell execution requires AUTONOMOUS agent maturity."""
        # Test governance check for desktop commands
        pass
    ```

    IMPORTANT: Check if desktop device governance is separate from mobile device governance. If DesktopDevice model exists, test it. If desktop uses MobileDevice model with a different platform type, document that.

    Verify governance rules:
    - Shell execution: AUTONOMOUS agents only (action complexity 4)
    - Screen recording: SUPERVISED+ agents (action complexity 3)
    - Camera capture: INTERN+ agents (action complexity 2)
    - Notifications: INTERN+ agents (action complexity 2)

    Follow existing device governance test patterns from test_device_governance.py.

    NOTE: If desktop governance is not yet implemented separately, add TODO comments indicating tests are ready for implementation.
  </action>
  <verify>
    Run `cd backend && pytest tests/test_desktop_device_governance.py -v` - all tests pass
  </verify>
  <done>
    Desktop governance tests verify device registration, capability permissions, maturity-based authorization with >75% coverage
  </done>
</task>

</tasks>

<verification>
1. Run `cargo test` from src-tauri/ - all device capability tests pass
2. Run `pytest tests/test_desktop_device_governance.py` from backend/ - all governance tests pass
3. Verify platform-specific code paths are tested (macos, windows, linux)
4. Verify ffmpeg detection logic is tested
5. Verify command whitelist validation is tested
6. Verify governance maturity levels are enforced
7. Check coverage reports for both Rust and Python code
</verification>

<success_criteria>
1. Device capability tests verify system info, notifications, command whitelist
2. Platform-specific implementations tested (argument construction for each OS)
3. Governance tests verify maturity-based permissions for desktop commands
4. External dependencies mocked (ffmpeg, IP geolocation)
5. Coverage >75% for testable device capability and governance code
6. Tests follow existing backend test patterns
7. Tests can run in CI without actual hardware
</success_criteria>

<output>
After completion, create `.planning/phases/04-platform-coverage/04-07-SUMMARY.md` with:
- Coverage metrics for device capabilities and governance
- List of platform-specific code paths tested
- Notes on hardware-dependent tests deferred (require ffmpeg, actual devices)
- List of governance rules validated
</output>
