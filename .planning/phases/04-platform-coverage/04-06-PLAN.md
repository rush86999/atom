---
phase: 04-platform-coverage
plan: 06
type: execute
wave: 2
depends_on: ["04-05"]
files_modified:
  - frontend-nextjs/src-tauri/tests/integration/commands_test.rs
  - backend/tests/test_tauri_commands.py
autonomous: true

must_haves:
  truths:
    - "Tauri command tests verify file operations, system info, dialog operations"
    - "Backend integration tests verify Tauri API endpoints with FastAPI TestClient"
    - "Desktop-backend integration tests validate command invocation and response handling"
    - "Tests mock external dependencies (file system, commands) for isolation"
  artifacts:
    - path: "frontend-nextjs/src-tauri/tests/integration/commands_test.rs"
      provides: "Tauri command integration tests"
      min_lines: 120
    - path: "backend/tests/test_tauri_commands.py"
      provides: "Backend API integration tests for Tauri endpoints"
      min_lines: 100
  key_links:
    - from: "commands_test.rs"
      to: "main.rs invoke_handler"
      via: "test each #[tauri::command]"
      pattern: "#\[tauri::command\]"
    - from: "test_tauri_commands.py"
      to: "main.rs commands"
      via: "FastAPI TestClient to backend endpoints"
      pattern: "test_client.post|test_client.get"
---

<objective>
Create desktop-backend integration tests for Tauri commands and API endpoints.

**Purpose:** Test the integration between Tauri desktop commands and the backend API. Tauri commands invoke backend services, and these tests validate the full flow from desktop command invocation through backend processing to response handling.

**Output:**
- `commands_test.rs` - Rust tests for Tauri commands (file operations, system info, dialogs)
- `test_tauri_commands.py` - Python backend tests for Tauri-specific endpoints
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/04-platform-coverage/04-RESEARCH.md
@.planning/REQUIREMENTS.md

# Existing Code
@frontend-nextjs/src-tauri/src/main.rs
@backend/tests/test_mobile_auth.py
@backend/tests/factories/
@.planning/phases/04-platform-coverage/04-05-PLAN.md
@.planning/phases/03-integration-security-tests/03-01-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Create Tauri command integration tests</name>
  <files>frontend-nextjs/src-tauri/tests/integration/commands_test.rs</files>
  <action>
    Create `frontend-nextjs/src-tauri/tests/integration/commands_test.rs` with:
    1. Test suite for file dialog commands (open_file_dialog, open_folder_dialog, save_file_dialog)
    2. Test suite for file operations (read_file_content, write_file_content, list_directory)
    3. Test suite for system info command (get_system_info)
    4. Test suite for command execution (execute_command with whitelist)
    5. Test suite for OCR commands (check_ocr_availability, process_local_ocr)
    6. Test suite for notification command (send_notification)
    7. Mock external dependencies (fs::read_to_string, std::process::Command)

    Pattern:
    ```rust
    #[cfg(test)]
    mod tests {
        use super::*;
        use std::fs;
        use std::path::PathBuf;

        #[test(tokio::test)]
        async fn test_read_file_content() {
            // Test file reading with mock file system
            let temp_dir = std::env::temp_dir();
            let test_file = temp_dir.join("test_read.txt");
            fs::write(&test_file, "test content").unwrap();

            let result = read_file_content(test_file.to_str().unwrap()).await;
            assert!(result.is_ok());
            let json = result.unwrap();
            assert!(json["success"].as_bool().unwrap());
        }

        #[test(tokio::test)]
        async fn test_get_system_info() {
            let result = get_system_info().await;
            assert!(result.is_ok());
            let json = result.unwrap();
            assert!(json["platform"].is_string());
        }
    }
    ```

    IMPORTANT: The main.rs has many commands (lines 24-1652). Focus on testing the key command categories:
    - File dialogs: open_file_dialog, open_folder_dialog, save_file_dialog
    - File operations: read_file_content, write_file_content, list_directory
    - System info: get_system_info
    - Command execution: execute_shell_command (with whitelist validation)
    - Notifications: send_notification
    - OCR: check_ocr_availability, process_local_ocr

    Mock external calls:
    - Use actual temp directory for file operations (create test files, verify results)
    - Mock std::process::Command for execute_command tests
    - Mock IP geolocation for get_location tests

    NOTE: Commands that spawn actual processes (install_satellite_dependencies, start_satellite, screen recording) are harder to test. Add TODO comments for these, documenting test challenges.
  </action>
  <verify>
    Run `cd frontend-nextjs/src-tauri && cargo test commands_test` - tests pass
  </verify>
  <done>
    Command tests verify file operations, dialogs, system info, notifications with >75% coverage of command logic
  </done>
</task>

<task type="auto">
  <name>Create backend API tests for Tauri-specific endpoints</name>
  <files>backend/tests/test_tauri_commands.py</files>
  <action>
    Create `backend/tests/test_tauri_commands.py` with:
    1. Test suite for desktop device registration
    2. Test suite for desktop-specific authentication (if separate from mobile)
    3. Test suite for file upload/download endpoints used by desktop
    4. Test suite for desktop configuration endpoints
    5. Test suite for satellite management endpoints (install_dependencies, start, stop)
    6. Use FastAPI TestClient and factory_boy fixtures (follow test_mobile_auth.py pattern)

    Pattern:
    ```python
    import pytest
    from fastapi.testclient import TestClient
    from unittest.mock import patch, Mock
    from factories.user_factory import UserFactory

    @pytest.mark.asyncio
    async def test_desktop_device_registration(db_session, test_client):
        """Test desktop device registration on login."""
        user = await UserFactory.create_async(db_session)

        response = test_client.post("/api/auth/login", json={
            "email": user.email,
            "password": "test_password",
            "device_type": "desktop",
            "platform": "macos"
        })

        assert response.status_code == 200
        data = response.json()
        assert "access_token" in data
        assert data["user"]["email"] == user.email
    ```

    IMPORTANT: Check if backend has Tauri-specific endpoints. If not, add TODO comments indicating desktop API integration tests are ready for implementation.

    Follow Phase 3 integration test patterns:
    - Use TestClient for API calls
    - Use transaction rollback pattern from test_integration patterns
    - Mock external dependencies (file system, OCR services)

    Test satellite management commands if endpoints exist:
    - POST /api/satellite/install
    - POST /api/satellite/start
    - POST /api/satellite/stop

    NOTE: The main.rs has satellite commands (install_satellite_dependencies, start_satellite, stop_satellite). These likely call backend endpoints - verify the integration path.
  </action>
  <verify>
    Run `cd backend && pytest tests/test_tauri_commands.py -v` - all tests pass
  </verify>
  <done>
    Backend tests verify desktop-specific endpoints, satellite management, file operations with >75% coverage
  </done>
</task>

</tasks>

<verification>
1. Run `cargo test` from src-tauri/ - all command tests pass
2. Run `pytest tests/test_tauri_commands.py` from backend/ - all backend tests pass
3. Verify file operations use temp directory for test isolation
4. Verify external dependencies are mocked (Commands, OCR services)
5. Check coverage reports for both Rust and Python code
6. Verify tests follow existing backend test patterns (factory_boy, TestClient)
</verification>

<success_criteria>
1. Tauri command tests verify file operations, dialogs, system info
2. Backend tests verify desktop API endpoints
3. External dependencies mocked for test isolation
4. Coverage >75% for testable command and endpoint code
5. Tests follow existing backend patterns (factory_boy, transaction rollback)
6. Tests can run in CI without actual desktop GUI
</success_criteria>

<output>
After completion, create `.planning/phases/04-platform-coverage/04-06-SUMMARY.md` with:
- Coverage metrics for Tauri commands and backend endpoints
- List of commands tested vs deferred (hard-to-test commands)
- Notes on backend API integration patterns discovered
- Any Tauri-specific endpoints not yet implemented
</output>
