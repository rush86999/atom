---
phase: 05-coverage-quality-validation
plan: 05
type: execute
wave: 2
depends_on: ["05-04"]
files_modified:
  - backend/tests/docs/COVERAGE_GUIDE.md
  - backend/tests/docs/TEST_ISOLATION_PATTERNS.md
  - backend/tests/docs/FLAKY_TEST_GUIDE.md
  - backend/.github/workflows/coverage-report.yml
  - backend/tests/coverage_reports/trends/coverage_trend.json
  - backend/tests/README.md
autonomous: true

must_haves:
  truths:
    - "Comprehensive test documentation exists for coverage interpretation"
    - "Test isolation patterns are documented with examples"
    - "Flaky test prevention guide exists with common causes and fixes"
    - "Coverage trending is configured in CI with historical tracking"
    - "Coverage reports are generated in HTML, JSON, and terminal formats"
    - "Test suite README with run instructions exists"
  artifacts:
    - path: "backend/tests/docs/COVERAGE_GUIDE.md"
      provides: "Coverage report interpretation guide"
      contains: "# Coverage Report Interpretation Guide"
    - path: "backend/tests/docs/TEST_ISOLATION_PATTERNS.md"
      provides: "Test isolation patterns and examples"
      contains: "# Test Isolation Patterns"
    - path: "backend/tests/docs/FLAKY_TEST_GUIDE.md"
      provides: "Flaky test prevention and fixing guide"
      contains: "# Flaky Test Guide"
    - path: "backend/.github/workflows/coverage-report.yml"
      provides: "GitHub Actions workflow for coverage trending"
      contains: "name: Coverage Report"
    - path: "backend/tests/coverage_reports/trends/coverage_trend.json"
      provides: "Historical coverage trend data"
      contains: "coverage_history"
    - path: "backend/tests/README.md"
      provides: "Test suite documentation and run instructions"
      contains: "# Atom Test Suite"
  key_links:
    - from: "COVERAGE_GUIDE.md"
      to: "coverage_reports/html/index.html"
      via: "coverage report links"
      pattern: "coverage_reports/html"
    - from: "TEST_ISOLATION_PATTERNS.md"
      to: "conftest.py"
      via: "fixture documentation"
      pattern: "unique_resource_name"
    - from: "FLAKY_TEST_GUIDE.md"
      to: "pytest.ini"
      via: "pytest-rerunfailures configuration"
      pattern: "--reruns"
    - from: "coverage-report.yml"
      to: "Codecov or Coveralls"
      via: "coverage upload"
      pattern: "codecov"
---

<objective>
Create comprehensive test documentation and set up coverage trending infrastructure. Document test isolation patterns, flaky test prevention, and coverage report interpretation.

Purpose: Documentation ensures test quality knowledge is shared and maintainable. Coverage trending enables detection of coverage regressions over time. This plan completes the Phase 5 goal of comprehensive documentation and quality validation.

Output: Three test documentation guides, GitHub Actions workflow for coverage trending, updated test suite README, and initial coverage trend data.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-coverage-quality-validation/05-RESEARCH.md

@backend/tests/property_tests/INVARIANTS.md
@backend/tests/property_tests/README.md
@backend/tests/factories/README.md
@backend/.planning/phases/01-test-infrastructure/01-test-infrastructure-03-SUMMARY.md

# Phase 1 created coverage reporting infrastructure
# This plan adds trending, documentation, and CI integration
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Coverage Report Interpretation Guide</name>
  <files>backend/tests/docs/COVERAGE_GUIDE.md</files>
  <action>
Create comprehensive guide for interpreting coverage reports covering:

1. **Coverage metrics explained**:
   - Line coverage vs branch coverage (why branch is more accurate)
   - Coverage percentage interpretation (80% target, diminishing returns above 90%)
   - Coverage paradox (high coverage, low quality)
   - Missing coverage (what 0% coverage means)

2. **Reading coverage reports**:
   - HTML report navigation (coverage_reports/html/index.html)
   - JSON report structure (coverage.json format)
   - Terminal report interpretation (term-missing output)
   - Color coding (red <50%, yellow 50-80%, green >80%)

3. **Coverage by domain**:
   - Governance domain coverage target and current status
   - Security domain coverage target and current status
   - Episode domain coverage target and current status
   - Backend overall coverage target and current status

4. **Coverage trending**:
   - How to track coverage over time
   - How to detect coverage regressions
   - How to use coverage_trend.json
   - Coverage thresholds and quality gates

5. **Improving coverage**:
   - How to identify uncovered lines
   - How to prioritize coverage gaps (critical paths first)
   - How to write tests for uncovered code
   - When NOT to chase 100% coverage (generated code, config, etc.)

6. **Coverage tools reference**:
   - pytest-cov command reference
   - Coverage.py CLI reference
   - Codecov/Coveralls integration (if configured)

Include examples and screenshots where helpful.
Link to existing documentation (INVARIANTS.md, factory README).

DO NOT duplicate existing documentation.
Focus on interpretation and actionable guidance.
  </action>
  <verify>
test -f backend/tests/docs/COVERAGE_GUIDE.md
grep -q "Coverage Report Interpretation" backend/tests/docs/COVERAGE_GUIDE.md
  </verify>
  <done>
COVERAGE_GUIDE.md exists
Coverage metrics explained
Report navigation documented
Domain coverage targets documented
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Test Isolation Patterns Guide</name>
  <files>backend/tests/docs/TEST_ISOLATION_PATTERNS.md</files>
  <action>
Create comprehensive guide for test isolation patterns covering:

1. **Why test isolation matters**:
   - False positives/negatives from shared state
   - Flaky tests from resource conflicts
   - Parallel execution requirements

2. **Isolation patterns**:
   - unique_resource_name fixture (worker ID + UUID)
   - Database transaction rollback (db_session fixture)
   - Factory pattern (dynamic data, no hardcoded IDs)
   - Mock external dependencies (APIs, databases, file systems)
   - Fixture cleanup (yield, finalizers)

3. **Anti-patterns to avoid**:
   - Hardcoded test data (causes collisions)
   - Global state mutations (affects other tests)
   - Time-based tests without mocking (non-deterministic)
   - File system operations without temp directories
   - Database commits in tests (use rollback)

4. **Examples**:
   - Good: Using unique_resource_name for filenames
   - Bad: Hardcoded "test_file.txt"
   - Good: Using db_session with automatic rollback
   - Bad: Manually creating and deleting test data
   - Good: Mocking external APIs
   - Bad: Calling real APIs in tests

5. **Debugging isolation issues**:
   - How to identify shared state problems (runs pass alone, fail in suite)
   - How to find resource conflicts (port already in use, file exists)
   - How to verify isolation (run tests 10 times, check results)

6. **pytest-xdist integration**:
   - Worker ID environment variable (PYTEST_XDIST_WORKER_ID)
   - Load scope scheduling (group tests by scope)
   - Parallel execution verification (pytest -n auto)

Include code examples for each pattern.
Reference conftest.py fixtures.

DO NOT duplicate conftest.py documentation.
Focus on patterns and examples.
  </action>
  <verify>
test -f backend/tests/docs/TEST_ISOLATION_PATTERNS.md
grep -q "Test Isolation Patterns" backend/tests/docs/TEST_ISOLATION_PATTERNS.md
  </verify>
  <done>
TEST_ISOLATION_PATTERNS.md exists
Isolation patterns documented
Anti-patterns documented
Code examples included
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Flaky Test Prevention Guide</name>
  <files>backend/tests/docs/FLAKY_TEST_GUIDE.md</files>
  <action>
Create comprehensive guide for flaky test prevention covering:

1. **What are flaky tests**:
   - Definition (tests that pass/fail non-deterministically)
   - Impact (erodes confidence, wastes time, masks real failures)
   - Common symptoms (passes locally, fails in CI; passes alone, fails in suite)

2. **Common causes**:
   - Race conditions (timing dependencies, async issues)
   - Shared state (global variables, singletons, database rows)
   - External dependencies (network, APIs, databases)
   - Time dependencies (time.sleep, datetime.now, timeouts)
   - Resource contention (ports, files, memory)
   - Order dependency (tests must run in specific order)

3. **Prevention patterns**:
   - Use explicit synchronization (events, barriers) instead of sleep
   - Mock external dependencies (APIs, databases, file systems)
   - Use unique resource names (worker ID + UUID)
   - Use transaction rollback (don't commit test data)
   - Avoid global state (use fixtures, reset between tests)
   - Make tests order-independent

4. **Detection strategies**:
   - pytest-rerunfailures (--reruns flag)
   - Run tests multiple times (for loop in bash)
   - Run tests in parallel (pytest -n auto)
   - Run tests in random order (pytest-randomly)

5. **Fixing flaky tests**:
   - Step 1: Identify the cause (add logging, run in isolation)
   - Step 2: Fix the root cause (don't just add retries)
   - Step 3: Verify fix (run 100 times, check parallel execution)
   - Step 4: Document fix (add comment explaining the issue)

6. **When to use @pytest.mark.flaky**:
   - Temporary workaround while fixing root cause
   - Known issues filed as bugs
   - NEVER a permanent solution
   - Must include TODO comment with issue link

Include real examples from the codebase if available.
Reference pytest-rerunfailures documentation.

DO NOT encourage using @pytest.mark.flaky as permanent fix.
Focus on root cause resolution.
  </action>
  <verify>
test -f backend/tests/docs/FLAKY_TEST_GUIDE.md
grep -q "Flaky Test" backend/tests/docs/FLAKY_TEST_GUIDE.md
  </verify>
  <done>
FLAKY_TEST_GUIDE.md exists
Common causes documented
Prevention patterns documented
Fixing strategy documented
  </done>
</task>

<task type="auto">
  <name>Task 4: Create GitHub Actions workflow for coverage trending</name>
  <files>backend/.github/workflows/coverage-report.yml</files>
  <action>
Create GitHub Actions workflow for coverage trending:

1. **Workflow trigger**:
   - Run on push to main branch
   - Run on pull requests to main
   - Allow manual workflow dispatch

2. **Test execution with coverage**:
   - Set up Python 3.11
   - Install dependencies (pytest, pytest-cov, pytest-xdist)
   - Run tests with coverage (--cov flags)
   - Generate coverage reports (HTML, JSON, terminal)

3. **Coverage trending setup**:
   - Archive coverage.json as workflow artifact
   - Copy coverage.json to trends/ directory with date stamp
   - Update coverage_trend.json with new data point
   - Commit coverage_trend.json to repo (or use external service)

4. **Coverage reporting options** (choose based on project needs):
   - Option A: Codecov upload (codecov/codecov-action@v4)
   - Option B: Coveralls upload (coverallsapp/github-action@v2)
   - Option C: Git-tracked JSON (simpler, no external service)

5. **PR comments** (if using Codecov/Coveralls):
   - Post coverage diff as PR comment
   - Show coverage changes by file
   - Fail if coverage decreases significantly

6. **Performance tracking**:
   - Measure test execution time
   - Track performance regression over time
   - Fail if tests take too long (>5 minutes warning, >10 minutes fail)

Create workflow YAML file in .github/workflows/.
Follow GitHub Actions best practices.
Use checkout@v4, setup-python@v5, actions/upload-artifact@v4.

DO NOT require Codecov token (use fail_ci_if_error: false).
DO NOT fail PR if coverage service is down.
Focus on Git-tracked trending as fallback.
  </action>
  <verify>
test -f backend/.github/workflows/coverage-report.yml
grep -q "coverage" backend/.github/workflows/coverage-report.yml

# Verify workflow is valid YAML
python -c "import yaml; yaml.safe_load(open('backend/.github/workflows/coverage-report.yml'))"

# Verify trending configuration is present
grep -q "coverage_trend.json\|trends/" backend/.github/workflows/coverage-report.yml
  </verify>
  <done>
coverage-report.yml workflow created
Coverage JSON archiving configured
Coverage trending setup documented
Workflow is valid YAML
Trending configuration verified
  </done>
</task>

<task type="auto">
  <name>Task 5: Initialize coverage trend data</name>
  <files>backend/tests/coverage_reports/trends/coverage_trend.json</files>
  <action>
Create initial coverage trend data file:

1. **Create trends directory**:
   - Create tests/coverage_reports/trends/ if it doesn't exist

2. **Initialize coverage_trend.json**:
   - Create JSON file with structure:
     ```json
     {
       "coverage_history": [
         {
           "date": "2026-02-11",
           "commit": "initial",
           "overall_percent": 15.57,
           "governance_percent": 13.37,
           "security_percent": 22.40,
           "episodes_percent": 15.52,
           "test_count": 0
         }
       ],
       "targets": {
         "overall": 80,
         "governance": 80,
         "security": 80,
         "episodes": 80
       }
     }
     ```

3. **Create dated snapshot**:
   - Copy current coverage.json to trends/2026-02-11_coverage.json
   - This creates historical baseline

4. **Document update process**:
   - Add README.md in trends/ directory explaining format
   - Document how to update (manual or via CI workflow)
   - Document how to interpret trend data

5. **Add .gitignore rule if needed**:
   - DO NOT ignore coverage_trend.json (track it)
   - Consider ignoring dated snapshots (too many files)
   - Or commit all snapshots for full history

Use current coverage data from RESEARCH.md as baseline.
Update with actual current coverage if available.

DO NOT commit sensitive data in coverage reports.
DO NOT include file paths in trend JSON (domain-level only).
  </action>
  <verify>
test -f backend/tests/coverage_reports/trends/coverage_trend.json
test -f backend/tests/coverage_reports/trends/README.md
jq empty backend/tests/coverage_reports/trends/coverage_trend.json
  </verify>
  <done>
coverage_trend.json created with baseline
trends/README.md created
Format documented
  </done>
</task>

<task type="auto">
  <name>Task 6: Create comprehensive Test Suite README</name>
  <files>backend/tests/README.md</files>
  <action>
Create comprehensive test suite README covering:

1. **Overview**:
   - Test suite purpose (quality, confidence, regression prevention)
   - Coverage goals (80% across all domains)
   - Test execution time target (<5 minutes)

2. **Running tests**:
   - Basic command: `pytest tests/ -v`
   - Parallel execution: `pytest tests/ -n auto`
   - Coverage report: `pytest tests/ --cov`
   - Specific test: `pytest tests/path/to/test.py -v`
   - By marker: `pytest tests/ -m unit`

3. **Test structure**:
   - unit/ (isolated component tests)
   - integration/ (component interaction tests)
   - property_tests/ (Hypothesis invariant tests)
   - security/ (security validation tests)
   - factories/ (test data factories)

4. **Fixtures and utilities**:
   - unique_resource_name (collision-free test resources)
   - db_session (database with transaction rollback)
   - factories (dynamic test data generation)

5. **Coverage reports**:
   - HTML: coverage_reports/html/index.html
   - JSON: coverage_reports/metrics/coverage.json
   - Terminal: pytest --cov-report=term-missing

6. **Common tasks**:
   - Run tests for a specific domain
   - Run tests in parallel
   - Generate coverage report
   - Run flaky test detection
   - Debug test failures

7. **Troubleshooting**:
   - Import errors (check PYTHONPATH)
   - Database errors (use db_session fixture)
   - Flaky tests (see FLAKY_TEST_GUIDE.md)
   - Coverage not updating (delete .coverage file)

8. **Related documentation**:
   - COVERAGE_GUIDE.md (coverage interpretation)
   - TEST_ISOLATION_PATTERNS.md (isolation best practices)
   - FLAKY_TEST_GUIDE.md (flaky test prevention)
   - property_tests/INVARIANTS.md (property test invariants)
   - factories/README.md (factory usage)

Include command examples and expected output.
Link to all related documentation.

DO NOT duplicate existing documentation.
Focus on quick reference and getting started.
  </action>
  <verify>
test -f backend/tests/README.md
grep -q "Atom Test Suite" backend/tests/README.md
  </verify>
  <done>
README.md created in tests/
Running tests documented
Test structure explained
Troubleshooting guide included
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify all documentation exists:
   ```bash
   ls -la backend/tests/docs/
   ls -la backend/tests/coverage_reports/trends/
   cat backend/tests/README.md
   ```

2. Verify GitHub Actions workflow:
   ```bash
   cat backend/.github/workflows/coverage-report.yml
   ```

3. Verify coverage trend data:
   ```bash
   cat backend/tests/coverage_reports/trends/coverage_trend.json | jq
   ```

4. Verify documentation quality:
   - All guides have clear sections
   - All code examples are valid
   - All links work
   - Spelling and grammar are correct
</verification>

<success_criteria>
1. COVERAGE_GUIDE.md exists with coverage interpretation
2. TEST_ISOLATION_PATTERNS.md exists with patterns and examples
3. FLAKY_TEST_GUIDE.md exists with prevention strategies
4. coverage-report.yml workflow exists and is valid YAML
5. coverage_trend.json exists with baseline data
6. tests/README.md exists with run instructions
7. All documentation is linked and cross-referenced
8. Coverage trending workflow is verified to execute successfully (COVR-07)
9. coverage_trend.json gets updated when workflow runs
</success_criteria>

<output>
After completion, create `.planning/phases/05-coverage-quality-validation/05-05-SUMMARY.md` with:
- List of all documentation created
- Coverage trending configuration summary
- Next steps for documentation maintenance
- Phase 5 completion summary (all plans complete)
</output>
