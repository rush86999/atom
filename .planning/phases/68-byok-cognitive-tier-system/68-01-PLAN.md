---
phase: 68-byok-cognitive-tier-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/core/llm/cognitive_tier_system.py
  - backend/core/llm/byok_handler.py
  - backend/tests/test_cognitive_tier_classification.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - Queries are automatically classified into 5 cognitive tiers (Micro/Standard/Versatile/Heavy/Complex)
    - Classification uses multi-factor analysis (token count, semantic complexity, task type)
    - Existing QueryComplexity enum is extended/migrated to CognitiveTier
    - Tier classification completes in <50ms for routing decisions
    - Each tier maps to appropriate model quality/cost bands
  artifacts:
    - path: backend/core/llm/cognitive_tier_system.py
      provides: CognitiveTier enum, CognitiveClassifier class
      min_lines: 200
    - path: backend/core/llm/byok_handler.py
      provides: Extended routing with CognitiveTier support
      exports: ["classify_query", "get_ranked_providers"]
    - path: backend/tests/test_cognitive_tier_classification.py
      provides: Comprehensive tier classification tests
      min_lines: 250
  key_links:
    - from: backend/core/llm/byok_handler.py
      to: backend/core/llm/cognitive_tier_system.py
      via: import CognitiveTier, CognitiveClassifier
      pattern: "from core.llm.cognitive_tier_system import"
---

## Objective

Implement the 5-tier cognitive classification system for automatic LLM query complexity analysis. This extends the existing 4-level QueryComplexity enum with a more granular 5-tier system (Micro, Standard, Versatile, Heavy, Complex) that considers token count, semantic patterns, and task type for intelligent routing decisions.

**Purpose:** Enable more granular cost optimization by matching query complexity to the most cost-effective model tier.

**Output:** CognitiveTier system integrated into BYOK routing with comprehensive test coverage.

## Context

@/Users/rushiparikh/projects/atom/.planning/ROADMAP.md
@/Users/rushiparikh/projects/atom/.planning/phases/68-byok-cognitive-tier-system/68-RESEARCH.md
@/Users/rushiparikh/projects/atom/backend/core/llm/byok_handler.py
@/Users/rushiparikh/projects/atom/backend/core/benchmarks.py
@/Users/rushiparikh/projects/atom/backend/core/dynamic_pricing_fetcher.py

## Tasks

<task type="auto">
  <name>Task 1: Create CognitiveTier system with classifier</name>
  <files>backend/core/llm/cognitive_tier_system.py</files>
  <action>
Create new file `backend/core/llm/cognitive_tier_system.py` with:

1. **CognitiveTier enum** (extends QueryComplexity):
   - MICRO: <100 tokens, simple queries
   - STANDARD: 100-500 tokens, moderate complexity
   - VERSATILE: 500-2k tokens, multi-step reasoning
   - HEAVY: 2k-5k tokens, complex tasks
   - COMPLEX: >5k tokens or code/math/advanced reasoning

2. **CognitiveClassifier class** with methods:
   - `classify(prompt: str, task_type: Optional[str]) -> CognitiveTier`: Main classification
   - `_calculate_complexity_score(prompt: str, task_type: Optional[str]) -> int`: Semantic analysis
   - `_estimate_tokens(prompt: str) -> int`: Token estimation (1 token ≈ 4 chars)
   - `get_tier_models(tier: CognitiveTier) -> List[str]`: Map tier to candidate models

3. **Complexity patterns** (extend existing byok_handler patterns):
   - Code patterns: ```, function, class, def, import, async, await
   - Math/technical: calculate, equation, integral, derivative
   - Advanced: architecture, security, optimization, distributed
   - Task type adjustment: code=+2, chat=-1

4. **Tier thresholds** config:
   ```python
   TIER_THRESHOLDS = {
       CognitiveTier.MICRO: {"max_tokens": 100, "complexity_score": 0},
       CognitiveTier.STANDARD: {"max_tokens": 500, "complexity_score": 2},
       CognitiveTier.VERSATILE: {"max_tokens": 2000, "complexity_score": 5},
       CognitiveTier.HEAVY: {"max_tokens": 5000, "complexity_score": 8},
       CognitiveTier.COMPLEX: {"max_tokens": float("inf"), "complexity_score": float("inf")},
   }
   ```

DO NOT duplicate existing byok_handler patterns - extract shared regex to a common module.

Add comprehensive docstrings with examples for each tier.
</action>
  <verify>
pytest tests/test_cognitive_tier_classification.py -v --tb=short
  </verify>
  <done>
CognitiveTier enum with 5 levels defined, CognitiveClassifier class with classify(), _calculate_complexity_score(), _estimate_tokens(), get_tier_models() methods, all tests pass
</done>
</task>

<task type="auto">
  <name>Task 2: Integrate CognitiveTier into BYOK routing</name>
  <files>backend/core/llm/byok_handler.py</files>
  <action>
Extend `backend/core/llm/byok_handler.py`:

1. Add import at top:
   ```python
   from core.llm.cognitive_tier_system import CognitiveTier, CognitiveClassifier
   ```

2. Add classifier instance initialization in __init__:
   ```python
   self.cognitive_classifier = CognitiveClassifier()
   ```

3. Extend get_ranked_providers() with new parameter:
   - Add `cognitive_tier: Optional[CognitiveTier] = None` parameter
   - If tier provided, filter candidates by tier quality thresholds
   - Add MIN_QUALITY_BY_TIER mapping:
     ```python
     MIN_QUALITY_BY_TIER = {
         CognitiveTier.MICRO: 0,
         CognitiveTier.STANDARD: 80,
         CognitiveTier.VERSATILE: 86,
         CognitiveTier.HEAVY: 90,
         CognitiveTier.COMPLEX: 94,
     }
     ```

4. Keep backward compatibility - if tier not provided, use existing QueryComplexity logic

5. Add method `classify_cognitive_tier(prompt: str, task_type: Optional[str]) -> CognitiveTier` that wraps the classifier

DO NOT break existing BYOK API contracts. The new tier system should be opt-in via parameter.
</action>
  <verify>
# Test backward compatibility
pytest tests/test_cognitive_tier_classification.py::test_backward_compatibility -v
# Test new tier routing
pytest tests/test_cognitive_tier_classification.py::test_tier_based_routing -v
  </verify>
  <done>
BYOKHandler extended with cognitive_classifier, get_ranked_providers() accepts optional cognitive_tier parameter, MIN_QUALITY_BY_TIER filtering applied, backward compatibility maintained
</done>
</task>

<task type="auto">
  <name>Task 3: Create comprehensive tier classification tests</name>
  <files>backend/tests/test_cognitive_tier_classification.py</files>
  <action>
Create `backend/tests/test_cognitive_tier_classification.py` with:

1. **Token-based classification tests** (5 tests):
   - test_classify_micro_tier: <100 tokens → MICRO
   - test_classify_standard_tier: 100-500 tokens → STANDARD
   - test_classify_versatile_tier: 500-2k tokens → VERSATILE
   - test_classify_heavy_tier: 2k-5k tokens → HEAVY
   - test_classify_complex_tier: >5k tokens → COMPLEX

2. **Semantic complexity tests** (8 tests):
   - test_code_detection: ``` triggers higher tier
   - test_math_keywords: calculate/equation trigger HEAVY
   - test_architecture_keywords: architecture/security trigger COMPLEX
   - test_task_type_code: task_type="code" adds +2 score
   - test_task_type_chat: task_type="chat" subtracts -1 score
   - test_combined_factors: Multi-factor classification works
   - test_code_block_weight: ```` weighted correctly

3. **BYOK integration tests** (4 tests):
   - test_tier_quality_filtering: Each tier filters by MIN_QUALITY_BY_TIER
   - test_backward_compatibility: Existing QueryComplexity still works
   - test_classify_cognitive_tier_method: Wrapper method works
   - test_get_tier_models: Returns valid model list

4. **Performance tests** (2 tests):
   - test_classification_performance: Classification <50ms (pytest-benchmark)
   - test_batch_classification: 100 classifications <1s

Use pytest fixtures for test prompts at each tier boundary. Mock pricing cache for integration tests.
</action>
  <verify>
pytest tests/test_cognitive_tier_classification.py -v --cov=backend/core/llm/cognitive_tier_system.py --cov=backend/core/llm/byok_handler.py --cov-report=term-missing
  </verify>
  <done>
19 tests created, all passing, >80% coverage for cognitive_tier_system.py, classification performance <50ms verified
</done>
</task>

## Verification

1. **Tier classification accuracy**:
   ```bash
   python -c "
   from core.llm.cognitive_tier_system import CognitiveClassifier
   c = CognitiveClassifier()
   assert c.classify('hi').value == 'micro'
   assert c.classify('explain this in detail').value in ['standard', 'versatile']
   assert c.classify('debug this distributed system architecture').value == 'complex'
   "
   ```

2. **Performance requirement met**: Classification <50ms for 1000 char prompt

3. **Test coverage**: >80% for new cognitive_tier_system module

4. **Backward compatibility**: All existing BYOK tests still pass

## Success Criteria

1. 5-tier CognitiveTier enum defined (MICRO, STANDARD, VERSATILE, HEAVY, COMPLEX)
2. CognitiveClassifier class with multi-factor analysis (token count + semantic + task type)
3. BYOK routing integration with MIN_QUALITY_BY_TIER filtering
4. 19+ tests covering all classification scenarios
5. Classification performance <50ms (measured via pytest-benchmark)
6. Zero breaking changes to existing BYOK API

## Output

After completion, create `.planning/phases/68-byok-cognitive-tier-system/68-01-SUMMARY.md` with:
- Tier classification accuracy metrics
- Performance benchmark results
- Test coverage report
- Any deviations from plan
