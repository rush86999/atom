---
phase: 68-byok-cognitive-tier-system
plan: 06
type: execute
wave: 3
depends_on: [68-01, 68-05]
files_modified:
  - backend/core/llm/cognitive_tier_service.py
  - backend/core/llm/byok_handler.py
  - backend/tests/test_cognitive_tier_service.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - CognitiveTierService integrates all tier components (classifier, cache router, escalation)
    - BYOKHandler uses tier service for routing decisions
    - Workspace preferences override default tier selection
    - Cost-aware routing respects monthly budgets
    - Auto-escalation respects user preferences
  artifacts:
    - path: backend/core/llm/cognitive_tier_service.py
      provides: CognitiveTierService orchestration class
      min_lines: 400
    - path: backend/core/llm/byok_handler.py
      provides: Extended BYOK routing with full tier integration
      exports: ["generate_with_cognitive_tier"]
    - path: backend/tests/test_cognitive_tier_service.py
      provides: Integration tests for tier service
      min_lines: 500
  key_links:
    - from: backend/core/llm/cognitive_tier_service.py
      to: backend/core/llm/cognitive_tier_system.py
      via: from core.llm.cognitive_tier_system import CognitiveTier, CognitiveClassifier
      pattern: "from core.llm.cognitive_tier_system import CognitiveTier"
    - from: backend/core/llm/cognitive_tier_service.py
      to: backend/core/llm/cache_aware_router.py
      via: from core.llm.cache_aware_router import CacheAwareRouter
      pattern: "from core.llm.cache_aware_router import CacheAwareRouter"
    - from: backend/core/llm/cognitive_tier_service.py
      to: backend/core/llm/escalation_manager.py
      via: from core.llm.escalation_manager import EscalationManager
      pattern: "from core.llm.escalation_manager import EscalationManager"
    - from: backend/core/llm/cognitive_tier_service.py
      to: backend/core/models.py
      via: from core.models import CognitiveTierPreference
      pattern: "from core.models import CognitiveTierPreference"

## Objective

Create the CognitiveTierService that orchestrates all tier components (classification, cache-aware routing, escalation) with workspace preferences. This service integrates with BYOKHandler to provide end-to-end intelligent routing that respects user settings while optimizing for cost and quality.

**Purpose:** Provide a unified service layer for cognitive tier management that considers all factors (query complexity, caching, escalation, preferences).

**Output:** CognitiveTierService with full integration into BYOKHandler routing.

## Context

@/Users/rushiparikh/projects/atom/.planning/phases/68-byok-cognitive-tier-system/68-RESEARCH.md
@/Users/rushiparikh/projects/atom/backend/core/llm/cognitive_tier_system.py (Plan 01)
@/Users/rushiparikh/projects/atom/backend/core/llm/cache_aware_router.py (Plan 02)
@/Users/rushiparikh/projects/atom/backend/core/llm/escalation_manager.py (Plan 03)
@/Users/rushiparikh/projects/atom/backend/core/models.py (Plan 05)

## Tasks

<task type="auto">
  <name>Task 1: Create CognitiveTierService orchestration class</name>
  <files>backend/core/llm/cognitive_tier_service.py</files>
  <action>
Create new file `backend/core/llm/cognitive_tier_service.py` with:

1. **CognitiveTierService class**:
   ```python
   class CognitiveTierService:
       """Orchestrates cognitive tier classification, routing, and escalation"""

       def __init__(self, workspace_id: str = "default", db_session=None):
           self.workspace_id = workspace_id
           self.db = db_session
           self.classifier = CognitiveClassifier()
           from core.dynamic_pricing_fetcher import get_pricing_fetcher
           self.cache_router = CacheAwareRouter(get_pricing_fetcher())
           self.escalation_manager = EscalationManager(db_session)
   ```

2. **Key methods**:

   **`select_tier(prompt, task_type, user_tier_override=None) -> CognitiveTier`**:
   - Classify prompt using CognitiveClassifier
   - Load workspace preference from database
   - Apply min_tier/max_tier constraints from preference
   - Return user_tier_override if provided
   - Return preference.default_tier if set
   - Otherwise return classified tier

   **`get_optimal_model(tier, estimated_tokens, requires_tools=False) -> Tuple[str, str]`**:
   - Get workspace preference
   - Filter by preferred_providers if set
   - Get ranked providers from BYOKHandler
   - Apply cache-aware cost scoring
   - Filter by tier quality requirements
   - Return (provider_id, model) tuple

   **`calculate_request_cost(prompt, tier, model) -> Dict`**:
   - Estimate tokens from prompt
   - Get model pricing from DynamicPricingFetcher
   - Calculate cache hit probability
   - Return effective_cost, full_cost, cache_discount

   **`check_budget_constraint(request_cost_cents) -> bool`**:
   - Load workspace preference
   - Check monthly_budget_cents if set
   - Check max_cost_per_request_cents if set
   - Return True if within budget, False otherwise

   **`handle_escalation(current_tier, response_quality, error, rate_limited, request_id) -> Optional[CognitiveTier]`**:
   - Check if auto_escalation enabled in preference
   - Call escalation_manager.should_escalate()
   - Log escalation to EscalationLog
   - Return target_tier or None

   **`get_workspace_preference() -> Optional[CognitiveTierPreference]`**:
   - Query database for workspace preference
   - Return None if not set (use defaults)

3. **Workspace preference loading**:
   ```python
   from core.models import CognitiveTierPreference

   def get_workspace_preference(self):
       if self.db:
           return self.db.query(CognitiveTierPreference).filter_by(
               workspace_id=self.workspace_id
           ).first()
       return None
   ```

4. **Add comprehensive docstrings** explaining:
   - Service orchestrates all tier components
   - Workspace preferences override defaults
   - Budget constraints enforced before generation
   - Auto-escalation respects enable_auto_escalation flag

DO NOT implement database session management - service accepts db_session parameter.
</action>
  <verify>
pytest tests/test_cognitive_tier_service.py::test_select_tier -v
pytest tests/test_cognitive_tier_service.py::test_get_optimal_model -v
  </verify>
  <done>
CognitiveTierService created with select_tier(), get_optimal_model(), calculate_request_cost(), check_budget_constraint(), handle_escalation(), get_workspace_preference() methods
</done>
</task>

<task type="auto">
  <name>Task 2: Integrate CognitiveTierService into BYOKHandler</name>
  <files>backend/core/llm/byok_handler.py</files>
  <action>
Extend `backend/core/llm/byok_handler.py`:

1. Add import and initialization:
   ```python
   from core.llm.cognitive_tier_service import CognitiveTierService

   def __init__(self, workspace_id: str = "default", provider_id: str = "auto"):
       # ... existing code ...
       from core.database import get_db_session
       self.db_session = get_db_session().__enter__()  # Get session for service
       self.tier_service = CognitiveTierService(workspace_id, self.db_session)
   ```

2. Add new method `generate_with_cognitive_tier()`:
   ```python
   async def generate_with_cognitive_tier(
       self,
       prompt: str,
       system_instruction: str = "You are a helpful assistant.",
       task_type: Optional[str] = None,
       user_tier_override: Optional[str] = None,
       agent_id: Optional[str] = None,
       image_payload: Optional[str] = None
   ) -> Dict[str, Any]:
       '''Generate response using full cognitive tier pipeline'''
       import uuid
       request_id = str(uuid.uuid4())

       # 1. Select tier
       from core.llm.cognitive_tier_system import CognitiveTier
       tier = self.tier_service.select_tier(prompt, task_type, user_tier_override)

       # 2. Check budget
       estimated_cost = self.tier_service.calculate_request_cost(prompt, tier, None)
       if not self.tier_service.check_budget_constraint(estimated_cost.get('cost_cents', 0)):
           return {"error": "Budget exceeded", "tier": tier.value}

       # 3. Get optimal model
       estimated_tokens = len(prompt) // 4
       provider_id, model = self.tier_service.get_optimal_model(tier, estimated_tokens, agent_id is not None)

       # 4. Generate with escalation
       current_tier = tier
       max_escalations = 2

       for attempt in range(max_escalations + 1):
           try:
               response = await self.generate_response(
                   prompt=prompt,
                   system_instruction=system_instruction,
                   model_type=model,  # Use specific model
                   task_type=task_type,
                   agent_id=agent_id,
                   image_payload=image_payload
               )

               # 5. Check escalation
               should_escalate, reason, target_tier = self.tier_service.handle_escalation(
                   current_tier, None, None, False, request_id
               )

               if not should_escalate:
                   return {"response": response, "tier": current_tier.value, "provider": provider_id, "model": model}

               # Escalate and retry
               current_tier = target_tier

           except Exception as e:
               # Check for rate limit escalation
               should_escalate, reason, target_tier = self.tier_service.handle_escalation(
                   current_tier, None, str(e), "rate limit" in str(e).lower(), request_id
               )
               if should_escalate and target_tier:
                   current_tier = target_tier
                   continue
               raise

       return {"response": response, "tier": current_tier.value, "provider": provider_id, "model": model}
   ```

3. Update existing `generate_response()` to support tier_service for cache outcome recording.

DO NOT break existing generate_response() signature - new method is opt-in.
</action>
  <verify>
pytest tests/test_cognitive_tier_service.py::test_byok_integration -v
pytest tests/test_cognitive_tier_service.py::test_generate_with_cognitive_tier -v
  </verify>
  <done>
BYOKHandler extended with tier_service, generate_with_cognitive_tier() method created, escalation loop implemented, budget checking added
</done>
</task>

<task type="auto">
  <name>Task 3: Create cognitive tier service integration tests</name>
  <files>backend/tests/test_cognitive_tier_service.py</files>
  <action>
Create `backend/tests/test_cognitive_tier_service.py` with:

1. **Tier selection tests** (5 tests):
   - test_select_tier_uses_classifier: Calls CognitiveClassifier.classify()
   - test_select_tier_applies_min_constraint: Enforces min_tier from preference
   - test_select_tier_applies_max_constraint: Enforces max_tier from preference
   - test_select_tier_user_override: user_tier_override bypasses classification
   - test_select_tier_default_preference: Uses preference.default_tier when set

2. **Model selection tests** (4 tests):
   - test_get_optimal_model_uses_cache_routing: Calls CacheAwareRouter
   - test_get_optimal_model_filters_by_preferred_providers: Respects provider preference
   - test_get_optimal_model_enforces_tier_quality: Filters by tier quality requirements
   - test_get_optimal_model_fallback_on_no_match: Returns None when no models match

3. **Cost calculation tests** (4 tests):
   - test_calculate_request_cost_estimates_tokens: Token estimation from prompt length
   - test_calculate_request_cost_uses_pricing_fetcher: Gets real model pricing
   - test_calculate_request_cost_includes_cache_discount: Applies cache hit probability
   - test_calculate_request_cost_returns_dict: Returns cost_cents, effective_cost, full_cost

4. **Budget constraint tests** (3 tests):
   - test_check_budget_within_limits: Returns True when under budget
   - test_check_budget_monthly_exceeded: Returns False when monthly exceeded
   - test_check_budget_per_request_exceeded: Returns False when per-request exceeded

5. **Escalation handling tests** (4 tests):
   - test_handle_escalation_checks_preference_enabled: Respects enable_auto_escalation
   - test_handle_escalation_delegates_to_manager: Calls EscalationManager
   - test_handle_escalation_logs_to_database: Creates EscalationLog record
   - test_handle_escalation_returns_target_tier: Returns next tier on escalation

6. **BYOK integration tests** (6 tests):
   - test_generate_with_cognitive_tier_full_pipeline: End-to-end flow works
   - test_generate_with_cognitive_tier_escalation_loop: Escalates on quality issues
   - test_generate_with_cognitive_tier_budget_check: Blocks when budget exceeded
   - test_generate_with_cognitive_tier_user_override: Respects user tier selection
   - test_cache_outcome_recording: Records cache results after generation
   - test_workspace_preference_isolation: Different workspaces have independent preferences

Use pytest fixtures for database sessions and mock providers.
</action>
  <verify>
pytest tests/test_cognitive_tier_service.py -v --cov=backend/core/llm/cognitive_tier_service.py --cov-report=term-missing
  </verify>
  <done>
26 tests created, all passing, >80% coverage for cognitive_tier_service.py, full pipeline integration verified
</done>
</task>

## Verification

1. **Service orchestrates all components**:
   ```bash
   python -c "
   from core.llm.cognitive_tier_service import CognitiveTierService
   from core.database import get_db_session
   db = get_db_session().__enter__()
   s = CognitiveTierService('default', db)
   print('Has classifier:', hasattr(s, 'classifier'))
   print('Has cache_router:', hasattr(s, 'cache_router'))
   print('Has escalation_manager:', hasattr(s, 'escalation_manager'))
   "
   ```

2. **BYOK integration works**:
   ```bash
   python -c "
   from core.llm.byok_handler import BYOKHandler
   h = BYOKHandler()
   print('Has tier_service:', hasattr(h, 'tier_service'))
   print('Has generate_with_cognitive_tier:', hasattr(h, 'generate_with_cognitive_tier'))
   "
   ```

3. **Test coverage**: >80% for cognitive_tier_service module

4. **End-to-end flow**: select_tier -> get_optimal_model -> check_budget -> generate -> handle_escalation

## Success Criteria

1. CognitiveTierService orchestrates classifier, cache_router, escalation_manager
2. select_tier() applies workspace preferences (min_tier, max_tier, default_tier)
3. get_optimal_model() uses cache-aware cost scoring
4. check_budget_constraint() enforces both monthly and per-request limits
5. handle_escalation() respects enable_auto_escalation preference
6. BYOKHandler.generate_with_cognitive_tier() implements full pipeline
7. 26+ tests covering service methods and BYOK integration
8. Performance <100ms for tier selection + model routing

## Output

After completion, create `.planning/phases/68-byok-cognitive-tier-system/68-06-SUMMARY.md` with:
- Service orchestration diagram (text-based)
- Integration test results
- Performance benchmarks (tier selection, model routing)
- Test coverage report
