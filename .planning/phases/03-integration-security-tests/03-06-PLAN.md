---
phase: 03-integration-security-tests
plan: 06
type: execute
wave: 3
depends_on: ["03-01"]
files_modified:
  - backend/tests/integration/test_external_services.py
  - backend/tests/integration/test_multi_agent_coordination.py
autonomous: true

must_haves:
  truths:
    - External LLM providers are mocked appropriately
    - Slack/GitHub integrations use mocked responses
    - Multi-agent coordination works correctly
    - Agent handoffs between maturity levels are validated
    - Parallel agent execution is handled properly
  artifacts:
    - path: backend/tests/integration/test_external_services.py
      contains: "mock"
      min_lines: 200
    - path: backend/tests/integration/test_multi_agent_coordination.py
      contains: "coordination"
      min_lines: 150
  key_links:
    - from: backend/tests/integration/test_external_services.py
      to: backend/core/llm/byok_handler.py
      pattern: "openai"
    - from: backend/tests/integration/test_multi_agent_coordination.py
      to: backend/core/agent_governance_service.py
      pattern: "coordination"
---
<objective>
Create integration tests for external service mocking and multi-agent coordination.

Purpose: Test external service mocking (LLM providers, Slack, GitHub integrations) as required by INTG-04 and multi-agent coordination integration as required by INTG-05.

Output: Integration test files for external service mocking with responses library and multi-agent coordination tests.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/03-integration-security-tests/03-RESEARCH.md

@backend/core/llm/byok_handler.py
@backend/integrations/slack_enhanced_service.py
@backend/integrations/github_integration.py
@backend/core/agent_governance_service.py
</context>

<tasks>

<task type="auto">
  <name>Create external service mocking integration tests (INTG-04)</name>
  <files>backend/tests/integration/test_external_services.py</files>
<action>
    Create integration tests for external service mocking:

    Use `responses` library for HTTP mocking:
    - Mock OpenAI API responses
    - Mock Anthropic API responses
    - Mock Slack API responses
    - Mock GitHub API responses
    - Mock Google OAuth responses

    ```python
    """
    External service mocking integration tests (INTG-04).

    Tests cover:
    - LLM provider mocking (OpenAI, Anthropic)
    - Slack integration mocking
    - GitHub integration mocking
    - Google OAuth mocking
    - Error handling for external service failures
    """
    import pytest
    import responses
    from fastapi.testclient import TestClient
    from sqlalchemy.orm import Session
    from unittest.mock import Mock, AsyncMock, patch
    import json

    class TestOpenAIMocking:
        """Test OpenAI API mocking."""

        @responses.activate
        def test_openai_chat_completion_mock(self, client: TestClient, admin_token: str):
            """Test OpenAI chat completion with mocked response."""
            # Mock OpenAI API
            responses.add(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                json={
                    "id": "chatcmpl-test123",
                    "object": "chat.completion",
                    "created": 1234567890,
                    "model": "gpt-4",
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": "Mocked response from OpenAI"
                        },
                        "finish_reason": "stop"
                    }],
                    "usage": {
                        "prompt_tokens": 10,
                        "completion_tokens": 5,
                        "total_tokens": 15
                    }
                },
                status=200
            )

            response = client.post(
                "/api/llm/openai/chat",
                json={
                    "model": "gpt-4",
                    "messages": [{"role": "user", "content": "Hello"}]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code == 200
            data = response.json()
            assert "content" in data or "choices" in data

        @responses.activate
        def test_openai_error_handling(self, client: TestClient, admin_token: str):
            """Test OpenAI API error handling."""
            # Mock error response
            responses.add(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                json={
                    "error": {
                        "message": "Invalid API key",
                        "type": "invalid_request_error",
                        "code": "invalid_api_key"
                    }
                },
                status=401
            )

            response = client.post(
                "/api/llm/openai/chat",
                json={
                    "model": "gpt-4",
                    "messages": [{"role": "user", "content": "Hello"}]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Should handle error gracefully
            assert response.status_code in [400, 500, 502, 503]
            data = response.json()
            assert "error" in data or "detail" in data

        @responses.activate
        def test_openai_rate_limiting(self, client: TestClient, admin_token: str):
            """Test OpenAI rate limit handling."""
            responses.add(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                json={
                    "error": {
                        "message": "Rate limit exceeded",
                        "type": "rate_limit_error"
                    }
                },
                status=429
            )

            response = client.post(
                "/api/llm/openai/chat",
                json={
                    "model": "gpt-4",
                    "messages": [{"role": "user", "content": "Hello"}]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [429, 503]

    class TestAnthropicMocking:
        """Test Anthropic API mocking."""

        @responses.activate
        def test_anthropic_message_mock(self, client: TestClient, admin_token: str):
            """Test Anthropic message API with mocked response."""
            responses.add(
                responses.POST,
                "https://api.anthropic.com/v1/messages",
                json={
                    "id": "msg_test123",
                    "type": "message",
                    "role": "assistant",
                    "content": [{"type": "text", "text": "Mocked Anthropic response"}],
                    "model": "claude-3-sonnet",
                    "stop_reason": "end_turn"
                },
                status=200
            )

            response = client.post(
                "/api/llm/anthropic/message",
                json={
                    "model": "claude-3-sonnet",
                    "messages": [{"role": "user", "content": "Hello"}]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code == 200
            data = response.json()
            assert "content" in data or "completion" in data

    class TestSlackIntegrationMocking:
        """Test Slack integration with mocking."""

        @responses.activate
        def test_slack_message_send_mock(self, client: TestClient, admin_token: str):
            """Test Slack message sending with mocked response."""
            responses.add(
                responses.POST,
                "https://slack.com/api/chat.postMessage",
                json={
                    "ok": True,
                    "channel": "C12345",
                    "ts": "1234567890.123456",
                    "message": {
                        "text": "Test message",
                        "username": "Test Bot"
                    }
                },
                status=200
            )

            response = client.post(
                "/api/integrations/slack/send",
                json={
                    "channel": "C12345",
                    "text": "Test message"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 201]

        @responses.activate
        def test_slack_error_handling(self, client: TestClient, admin_token: str):
            """Test Slack API error handling."""
            responses.add(
                responses.POST,
                "https://slack.com/api/chat.postMessage",
                json={
                    "ok": False,
                    "error": "channel_not_found"
                },
                status=200
            )

            response = client.post(
                "/api/integrations/slack/send",
                json={
                    "channel": "invalid-channel",
                    "text": "Test message"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Should handle Slack errors
            assert response.status_code in [400, 500]

    class TestGitHubIntegrationMocking:
        """Test GitHub integration with mocking."""

        @responses.activate
        def test_github_issue_creation_mock(self, client: TestClient, admin_token: str):
            """Test GitHub issue creation with mocked response."""
            responses.add(
                responses.POST,
                "https://api.github.com/repos/test/repo/issues",
                json={
                    "id": 12345,
                    "number": 1,
                    "title": "Test Issue",
                    "state": "open",
                    "user": {"login": "testuser"}
                },
                status=201
            )

            response = client.post(
                "/api/integrations/github/issues",
                json={
                    "repo": "test/repo",
                    "title": "Test Issue",
                    "body": "Issue description"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 201]

        @responses.activate
        def test_github_authentication_error(self, client: TestClient, admin_token: str):
            """Test GitHub authentication error handling."""
            responses.add(
                responses.POST,
                "https://api.github.com/repos/test/repo/issues",
                json={
                    "message": "Bad credentials",
                    "documentation_url": "https://docs.github.com/rest"
                },
                status=401
            )

            response = client.post(
                "/api/integrations/github/issues",
                json={
                    "repo": "test/repo",
                    "title": "Test Issue"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [401, 502]

    class TestGoogleOAuthMocking:
        """Test Google OAuth with mocking."""

        @responses.activate
        def test_google_oauth_flow_mock(self, client: TestClient):
            """Test Google OAuth flow with mocked responses."""
            # Mock Google token endpoint
            responses.add(
                responses.POST,
                "https://oauth2.googleapis.com/token",
                json={
                    "access_token": "mock_access_token",
                    "expires_in": 3600,
                    "refresh_token": "mock_refresh_token",
                    "token_type": "Bearer"
                },
                status=200
            )

            # Mock Google user info endpoint
            responses.add(
                responses.GET,
                "https://www.googleapis.com/oauth2/v2/userinfo",
                json={
                    "id": "123456789",
                    "email": "test@example.com",
                    "verified_email": True,
                    "name": "Test User"
                },
                status=200
            )

            response = client.get(
                "/api/auth/google/callback?code=test_code&state=test_state"
            )

            # Should complete OAuth flow
            assert response.status_code in [200, 302]

    class TestExternalServiceTimeout:
        """Test timeout handling for external services."""

        @responses.activate
        def test_slow_llm_response_timeout(self, client: TestClient, admin_token: str):
            """Test timeout handling for slow LLM responses."""
            # Add delayed response
            import time

            def request_callback(request):
                time.sleep(35)  # Simulate slow response (>30s timeout)
                return (200, {}, json.dumps({"choices": [{"message": {"content": "Response"}}]}))

            responses.add_callback(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                callback=request_callback,
                content_type="application/json"
            )

            # Should timeout or handle gracefully
            # This test verifies timeout mechanism
            pass

        @responses.activate
        def test_external_service_unavailable(self, client: TestClient, admin_token: str):
            """Test handling when external service is unavailable."""
            # Mock connection error
            responses.add(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                body=Exception("Connection refused"),
                status=503
            )

            response = client.post(
                "/api/llm/openai/chat",
                json={
                    "model": "gpt-4",
                    "messages": [{"role": "user", "content": "Hello"}]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Should handle service unavailable gracefully
            assert response.status_code in [503, 504]

    class TestLLMProviderFailover:
        """Test LLM provider failover logic."""

        @responses.activate
        def test_failover_to_backup_provider(self, client: TestClient, admin_token: str):
            """Test failover from primary to backup LLM provider."""
            # Primary provider fails
            responses.add(
                responses.POST,
                "https://api.openai.com/v1/chat/completions",
                json={"error": {"message": "Service unavailable"}},
                status=503
            )

            # Backup provider succeeds
            responses.add(
                responses.POST,
                "https://api.anthropic.com/v1/messages",
                json={
                    "id": "msg_backup",
                    "content": [{"type": "text", "text": "Backup response"}]
                },
                status=200
            )

            response = client.post(
                "/api/llm/chat",
                json={
                    "messages": [{"role": "user", "content": "Hello"}],
                    "enable_failover": True
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Should successfully failover
            assert response.status_code == 200
            assert "Backup" in response.json().get("content", "") or \
                   "content" in response.json()
    ```

    Ensure tests cover:
    - OpenAI API mocking with success/error cases
    - Anthropic API mocking
    - Slack integration mocking
    - GitHub integration mocking
    - Google OAuth mocking
    - Timeout handling
    - Service unavailable scenarios
    - Failover logic
  </action>
  <verify>grep -c "def test_" backend/tests/integration/test_external_services.py</verify>
  <done>
    At least 15 test methods covering external service mocking
    Tests use responses library for HTTP mocking
    Tests cover error handling and failover scenarios
  </done>
</task>

<task type="auto">
  <name>Create multi-agent coordination integration tests (INTG-05)</name>
  <files>backend/tests/integration/test_multi_agent_coordination.py</files>
  <action>
    Create multi-agent coordination integration tests:

    Test cases covering:
    - Agent handoffs between maturity levels
    - Parallel agent execution
    - Sequential agent workflows
    - Agent coordination patterns
    - Shared state management
    - Conflict resolution

    ```python
    """
    Multi-agent coordination integration tests (INTG-05).

    Tests cover:
    - Agent handoffs between maturity levels
    - Parallel agent execution
    - Sequential workflows
    - Coordination patterns
    - Conflict resolution
    """
    import pytest
    import asyncio
    from fastapi.testclient import TestClient
    from sqlalchemy.orm import Session
    from tests.factories.agent_factory import (
        StudentAgentFactory,
        InternAgentFactory,
        SupervisedAgentFactory,
        AutonomousAgentFactory
    )
    from tests.factories.execution_factory import ExecutionFactory

    class TestAgentHandoffs:
        """Test agent handoffs between maturity levels."""

        def test_handoff_student_to_intern_blocked(self, client: TestClient, admin_token: str, db_session: Session):
            """Test handoff from STUDENT to INTERN is blocked without graduation."""
            student = StudentAgentFactory()
            intern = InternAgentFactory()
            db_session.add_all([student, intern])
            db_session.commit()

            response = client.post(
                f"/api/agents/{student.id}/handoff",
                json={
                    "to_agent_id": intern.id,
                    "context": {"task": "Continue this work"}
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Handoff should require graduation or approval
            assert response.status_code in [403, 202]

        def test_handoff_supervised_to_autonomous_requires_approval(self, client: TestClient, admin_token: str, db_session: Session):
            """Test handoff from SUPERVISED to AUTONOMOUS requires approval."""
            supervised = SupervisedAgentFactory()
            autonomous = AutonomousAgentFactory()
            db_session.add_all([supervised, autonomous])
            db_session.commit()

            response = client.post(
                f"/api/agents/{supervised.id}/handoff",
                json={
                    "to_agent_id": autonomous.id,
                    "context": {"task": "Elevate to autonomous"}
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # Should create proposal for approval
            assert response.status_code == 202
            data = response.json()
            assert "proposal_id" in data or "approval_required" in str(data).lower()

        def test_handoff_with_shared_context(self, client: TestClient, admin_token: str, db_session: Session):
            """Test handoff transfers shared context correctly."""
            agent1 = AutonomousAgentFactory(name="Agent1")
            agent2 = AutonomousAgentFactory(name="Agent2")
            db_session.add_all([agent1, agent2])
            db_session.commit()

            shared_context = {
                "user_id": "user123",
                "session_data": {"key": "value"},
                "conversation_history": [
                    {"role": "user", "content": "Initial request"},
                    {"role": "assistant", "content": "Agent1 response"}
                ]
            }

            response = client.post(
                f"/api/agents/{agent1.id}/handoff",
                json={
                    "to_agent_id": agent2.id,
                    "context": shared_context
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

            # Verify context was transferred
            if response.status_code == 200:
                data = response.json()
                assert "context_transferred" in data or data.get("success") == True

    class TestParallelAgentExecution:
        """Test parallel agent execution patterns."""

        def test_parallel_execution_independent_agents(self, client: TestClient, admin_token: str, db_session: Session):
            """Test parallel execution of independent agents."""
            agent1 = AutonomousAgentFactory(name="Parallel1")
            agent2 = AutonomousAgentFactory(name="Parallel2")
            agent3 = AutonomousAgentFactory(name="Parallel3")
            db_session.add_all([agent1, agent2, agent3])
            db_session.commit()

            # Execute agents in parallel
            response = client.post(
                "/api/agents/parallel-execute",
                json={
                    "agent_ids": [agent1.id, agent2.id, agent3.id],
                    "tasks": [
                        {"agent_id": agent1.id, "task": "Task 1"},
                        {"agent_id": agent2.id, "task": "Task 2"},
                        {"agent_id": agent3.id, "task": "Task 3"}
                    ]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]
            data = response.json()
            assert "executions" in data or "results" in data

        def test_parallel_execution_with_dependency_blocks(self, client: TestClient, admin_token: str, db_session: Session):
            """Test parallel execution respects agent dependencies."""
            agent1 = AutonomousAgentFactory(name="Dependent1")
            agent2 = SupervisedAgentFactory(name="Dependent2")
            db_session.add_all([agent1, agent2])
            db_session.commit()

            # agent2 depends on agent1 result
            response = client.post(
                "/api/agents/parallel-execute",
                json={
                    "tasks": [
                        {
                            "agent_id": agent1.id,
                            "task": "Independent task",
                            "dependencies": []
                        },
                        {
                            "agent_id": agent2.id,
                            "task": "Dependent task",
                            "dependencies": [agent1.id]
                        }
                    ]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

        def test_parallel_execution_governance_enforcement(self, client: TestClient, admin_token: str, db_session: Session):
            """Test parallel execution enforces governance for all agents."""
            student = StudentAgentFactory()
            autonomous = AutonomousAgentFactory()
            db_session.add_all([student, autonomous])
            db_session.commit()

            response = client.post(
                "/api/agents/parallel-execute",
                json={
                    "tasks": [
                        {"agent_id": student.id, "task": "Student task"},
                        {"agent_id": autonomous.id, "task": "Autonomous task"}
                    ]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            # STUDENT should be blocked
            data = response.json()
            if "results" in data:
                # Partial results - STUDENT blocked
                assert any("blocked" in str(r).lower() or "error" in str(r).lower()
                          for r in data["results"])
            else:
                # Entire request blocked
                assert response.status_code in [400, 403]

    class TestSequentialAgentWorkflows:
        """Test sequential agent workflow patterns."""

        def test_sequential_workflow_execution(self, client: TestClient, admin_token: str, db_session: Session):
            """Test sequential agent workflow."""
            agent1 = AutonomousAgentFactory(name="Step1")
            agent2 = AutonomousAgentFactory(name="Step2")
            agent3 = AutonomousAgentFactory(name="Step3")
            db_session.add_all([agent1, agent2, agent3])
            db_session.commit()

            response = client.post(
                "/api/workflows/sequential",
                json={
                    "steps": [
                        {"agent_id": agent1.id, "action": "analyze"},
                        {"agent_id": agent2.id, "action": "process"},
                        {"agent_id": agent3.id, "action": "finalize"}
                    ]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

        def test_sequential_workflow_stops_on_error(self, client: TestClient, admin_token: str, db_session: Session):
            """Test sequential workflow stops when an agent fails."""
            agent1 = AutonomousAgentFactory(name="SuccessAgent")
            agent2 = AutonomousAgentFactory(name="FailingAgent")
            agent3 = AutonomousAgentFactory(name="SkippedAgent")
            db_session.add_all([agent1, agent2, agent3])
            db_session.commit()

            # Mock agent2 to fail
            with patch('core.agent_governance_service.AgentGovernanceService.execute_agent') as mock_execute:
                mock_execute.side_effect = [
                    {"status": "success"},  # agent1 succeeds
                    Exception("Agent 2 failed"),  # agent2 fails
                ]

                response = client.post(
                    "/api/workflows/sequential",
                    json={
                        "steps": [
                            {"agent_id": agent1.id, "action": "step1"},
                            {"agent_id": agent2.id, "action": "step2"},
                            {"agent_id": agent3.id, "action": "step3"}
                        ]
                    },
                    headers={"Authorization": f"Bearer {admin_token}"}
                )

                # Should stop at agent2 error
                assert response.status_code in [500, 202]

        def test_sequential_workflow_passes_context(self, client: TestClient, admin_token: str, db_session: Session):
            """Test sequential workflow passes context between steps."""
            agent1 = AutonomousAgentFactory()
            agent2 = AutonomousAgentFactory()
            db_session.add_all([agent1, agent2])
            db_session.commit()

            response = client.post(
                "/api/workflows/sequential",
                json={
                    "steps": [
                        {
                            "agent_id": agent1.id,
                            "action": "extract",
                            "output_key": "extracted_data"
                        },
                        {
                            "agent_id": agent2.id,
                            "action": "process",
                            "input_from": "extracted_data"
                        }
                    ]
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

    class TestAgentCoordinationPatterns:
        """Test various agent coordination patterns."""

        def test_coordinator_agent_pattern(self, client: TestClient, admin_token: str, db_session: Session):
            """Test coordinator agent delegating to worker agents."""
            coordinator = AutonomousAgentFactory(name="Coordinator")
            worker1 = AutonomousAgentFactory(name="Worker1")
            worker2 = AutonomousAgentFactory(name="Worker2")
            db_session.add_all([coordinator, worker1, worker2])
            db_session.commit()

            response = client.post(
                f"/api/agents/{coordinator.id}/coordinate",
                json={
                    "pattern": "delegate",
                    "workers": [worker1.id, worker2.id],
                    "task": "Process these items"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

        def test_ensemble_agent_pattern(self, client: TestClient, admin_token: str, db_session: Session):
            """Test ensemble pattern where multiple agents contribute."""
            agents = [
                AutonomousAgentFactory(name=f"Ensemble{i}")
                for i in range(3)
            ]
            db_session.add_all(agents)
            db_session.commit()

            response = client.post(
                "/api/agents/ensemble",
                json={
                    "agent_ids": [a.id for a in agents],
                    "input": "Analyze this request",
                    "aggregation": "consensus"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]
            data = response.json()
            # Should have aggregated result
            assert "result" in data or "consensus" in data

        def test_peer_review_agent_pattern(self, client: TestClient, admin_token: str, db_session: Session):
            """Test peer review pattern where agents review each other."""
            reviewer1 = AutonomousAgentFactory(name="Reviewer1")
            reviewer2 = AutonomousAgentFactory(name="Reviewer2")
            author = AutonomousAgentFactory(name="Author")
            db_session.add_all([reviewer1, reviewer2, author])
            db_session.commit()

            response = client.post(
                "/api/agents/peer-review",
                json={
                    "author_agent_id": author.id,
                    "reviewer_agent_ids": [reviewer1.id, reviewer2.id],
                    "content": "Content to review"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

    class TestConflictResolution:
        """Test conflict resolution in multi-agent scenarios."""

        def test_conflicting_actions_resolution(self, client: TestClient, admin_token: str, db_session: Session):
            """Test resolution when agents propose conflicting actions."""
            agent1 = AutonomousAgentFactory(name="AgentA")
            agent2 = AutonomousAgentFactory(name="AgentB")
            db_session.add_all([agent1, agent2])
            db_session.commit()

            response = client.post(
                "/api/agents/resolve-conflict",
                json={
                    "proposals": [
                        {"agent_id": agent1.id, "action": "delete"},
                        {"agent_id": agent2.id, "action": "keep"}
                    ],
                    "resolution_strategy": "majority_vote"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]

        def test_resource_contention_resolution(self, client: TestClient, admin_token: str, db_session: Session):
            """Test resolution when agents contend for same resource."""
            agent1 = AutonomousAgentFactory()
            agent2 = AutonomousAgentFactory()
            db_session.add_all([agent1, agent2])
            db_session.commit()

            response = client.post(
                "/api/agents/allocate-resource",
                json={
                    "resource_id": "resource_123",
                    "requesting_agents": [agent1.id, agent2.id],
                    "allocation_strategy": "priority"
                },
                headers={"Authorization": f"Bearer {admin_token}"}
            )

            assert response.status_code in [200, 202]
    ```

    Ensure tests cover:
    - Agent handoffs between maturity levels
    - Parallel execution patterns
    - Sequential workflows
    - Coordinator/ensemble/peer-review patterns
    - Conflict resolution
  </action>
  <verify>grep -c "def test_" backend/tests/integration/test_multi_agent_coordination.py</verify>
  <done>
    At least 15 test methods covering multi-agent coordination
    Tests validate handoff governance
    Tests cover parallel and sequential patterns
    Tests include conflict resolution scenarios
  </done>
</task>

</tasks>

<verification>
After completion:
1. Run external service tests: pytest backend/tests/integration/test_external_services.py -v
2. Run multi-agent coordination tests: pytest backend/tests/integration/test_multi_agent_coordination.py -v
3. Verify responses library mocking works correctly
4. Verify failover logic is tested
5. Run all tests: pytest backend/tests/integration/test_external_services.py backend/tests/integration/test_multi_agent_coordination.py -v
</verification>

<success_criteria>
1. External service mocking tests created (INTG-04)
2. Multi-agent coordination tests created (INTG-05)
3. At least 30 test methods created across 2 files
4. Tests use responses library for HTTP mocking
5. Tests cover failover and error scenarios
</success_criteria>

<output>
After completion, create `.planning/phases/03-integration-security-tests/03-06-SUMMARY.md`
</output>
