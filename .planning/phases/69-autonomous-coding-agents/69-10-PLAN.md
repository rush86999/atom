---
phase: 69-autonomous-coding-agents
plan: 10
type: execute
wave: 4
depends_on: [69-01, 69-02, 69-03]
files_modified:
  - frontend-nextjs/components/canvas/CodingAgentCanvas.tsx
  - frontend-nextjs/hooks/useCanvasState.ts
  - frontend-nextjs/types/canvas.ts
  - backend/core/episode_segmentation_service.py
  - backend/core/models.py
  - backend/tests/test_coding_agent_canvas.tsx
  - docs/AUTONOMOUS_CODING_AGENTS.md
autonomous: true
user_setup:
  - service: "CodingAgentCanvas frontend component"
    why: "Real-time UI for autonomous coding agent operations with AI accessibility"
    install: "Component follows existing canvas pattern in frontend-nextjs/components/canvas/"

must_haves:
  truths:
    - "CodingAgentCanvas component created with 400+ lines following existing canvas pattern"
    - "CanvasType extended with 'coding' type for AI-generated code sessions"
    - "useAccessibilityMirror hook used for AI context (hidden div with role='log', aria-live='polite')"
    - "EpisodeService integration tracks canvas_action_ids for coding sessions"
    - "Approval workflow UI with approve/retry/reject buttons for agent suggestions"
    - "Validation feedback display showing real-time test results and coverage"
    - "History view with diff comparison for code changes"
    - "Component integrates with EpisodeService for WorldModel recall"
    - "Unit tests created and passing (component rendering, hooks, episode integration)"
    - "Documentation updated with CodingAgentCanvas usage and AI accessibility"
  artifacts:
    - path: "frontend-nextjs/components/canvas/CodingAgentCanvas.tsx"
      provides: "Real-time canvas for autonomous coding agent operations"
      min_lines: 400
      exports: ["CodingAgentCanvas"]
    - path: "frontend-nextjs/types/canvas.ts"
      provides: "CanvasType with 'coding' type definition"
      min_lines: 50
      exports: ["CanvasType"]
    - path: "docs/AUTONOMOUS_CODING_AGENTS.md"
      provides: "Documentation for coding agent canvas usage and AI accessibility"
      min_lines: 300
key_links:
  - from: "frontend-nextjs/components/canvas/CodingAgentCanvas.tsx"
    to: "frontend-nextjs/hooks/useCanvasState.ts"
    via: "useCanvasState hook for state management and accessibility"
  - from: "frontend-nextjs/components/canvas/CodingAgentCanvas.tsx"
    to: "backend/core/episode_segmentation_service.py"
    via: "EpisodeService integration for canvas_action_id tracking"
  - from: "frontend-nextjs/components/canvas/CodingAgentCanvas.tsx"
    to: "frontend-nextjs/hooks/useAccessibilityMirror.ts"
    via: "useAccessibilityMirror hook for AI context exposure"
---

<objective>
Implement CodingAgentCanvas component with AI accessibility following existing canvas patterns, enabling real-time visualization of autonomous coding agent operations with episode integration for WorldModel recall.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
@/Users/rushiparikh/.claude/get-shit-done/references/checkpoints.md
@/Users/rushiparikh/.claude/get-shit-done/references/tdd.md
</execution_context>

<context>
@.planning/phases/69-autonomous-coding-agents/69-RESEARCH.md
@.planning/phases/69-autonomous-coding-agents/69-03-PLAN.md
@.planning/STATE.md

# Existing Patterns to Follow

**Canvas Components:**
- frontend-nextjs/components/canvas/GenericCanvas.tsx
- frontend-nextjs/components/canvas/SheetsCanvas.tsx
- frontend-nextjs/components/canvas/ChartsCanvas.tsx

**Canvas State Management:**
- frontend-nextjs/hooks/useCanvasState.ts
- frontend-nextjs/hooks/useAccessibilityMirror.ts

**Canvas Type Definitions:**
- frontend-nextjs/types/canvas.ts

**Episode Integration:**
- backend/core/episode_segmentation_service.py
- backend/core/models.py (EpisodeSegment model with canvas_action_ids)
</context>

<tasks>

<task type="auto">
  <name>Create CodingAgentCanvas component with AI accessibility</name>
  <files>frontend-nextjs/components/canvas/CodingAgentCanvas.tsx</files>
  <action>
Create `frontend-nextjs/components/canvas/CodingAgentCanvas.tsx` (400+ lines):

**Component Structure:**
```typescript
import React, { useState, useEffect } from 'react';
import { useCanvasState } from '@/hooks/useCanvasState';
import { useAccessibilityMirror } from '@/hooks/useAccessibilityMirror';
import { Card } from '@/components/ui/card';

interface CodingAgentCanvasProps {
  sessionId: string;
  onApprove?: (actionId: string) => void;
  onRetry?: (actionId: string) => void;
  onReject?: (actionId: string) => void;
}

export const CodingAgentCanvas: React.FC<CodingAgentCanvasProps> = ({
  sessionId,
  onApprove,
  onRetry,
  onReject,
}) => {
  const canvasState = useCanvasState('coding-canvas');
  const { exposeState } = useAccessibilityMirror();

  const [approvalRequired, setApprovalRequired] = useState<string | null>(null);
  const [validationFeedback, setValidationFeedback] = useState<any>(null);
  const [historyView, setHistoryView] = useState(false);

  // Code editor UI with syntax highlighting
  const [codeContent, setCodeContent] = useState('');
  const [language, setLanguage] = useState('python');

  // Real-time agent operations display
  const operations = [
    { id: '1', type: 'code_generation', status: 'complete', timestamp: new Date() },
    { id: '2', type: 'test_generation', status: 'pending', timestamp: new Date() },
    { id: '3', type: 'validation', status: 'running', timestamp: new Date() },
  ];

  // Approval workflow UI
  const renderApprovalWorkflow = () => (
    <div className="approval-workspace">
      <h3>Agent Suggestion Requires Approval</h3>
      <div className="suggestion-preview">
        <pre>{codeContent}</pre>
      </div>
      <div className="approval-actions">
        <button onClick={() => onApprove?.(approvalRequired || '')}>Approve</button>
        <button onClick={() => onRetry?.(approvalRequired || '')}>Retry</button>
        <button onClick={() => onReject?.(approvalRequired || '')}>Reject</button>
      </div>
    </div>
  );

  // Validation feedback display
  const renderValidationFeedback = () => (
    <div className="validation-feedback">
      <h4>Test Results</h4>
      {validationFeedback?.passed} / {validationFeedback?.total} tests passing
      <div className="coverage-metrics">
        Coverage: {validationFeedback?.coverage}%
      </div>
    </div>
  );

  // History view with diff comparison
  const renderHistoryView = () => (
    <div className="history-view">
      <h4>Code Changes History</h4>
      {operations.map((op) => (
        <div key={op.id} className="operation-log">
          <span>{op.type}</span>
          <span>{op.status}</span>
          <span>{op.timestamp.toLocaleString()}</span>
        </div>
      ))}
    </div>
  );

  // AI accessibility mirror for agent context
  useEffect(() => {
    exposeState('coding-canvas', {
      sessionId,
      operations,
      codeContent,
      validationFeedback,
      approvalRequired,
      language,
    });
  }, [sessionId, operations, codeContent, validationFeedback, approvalRequired, language, exposeState]);

  return (
    <Card className="coding-agent-canvas">
      <div className="canvas-header">
        <h2>Autonomous Coding Agent</h2>
        <div className="agent-status">
          <span>Status: {operations.find(o => o.status === 'running') ? 'Active' : 'Idle'}</span>
        </div>
      </div>

      {/* Code editor UI */}
      <div className="code-editor">
        <textarea
          value={codeContent}
          onChange={(e) => setCodeContent(e.target.value)}
          placeholder="Generated code will appear here..."
          className="code-textarea"
        />
      </div>

      {/* Real-time operations */}
      <div className="operations-feed">
        <h3>Agent Operations</h3>
        {operations.map((op) => (
          <div key={op.id} className={`operation ${op.status}`}>
            <span className="operation-type">{op.type}</span>
            <span className="operation-status">{op.status}</span>
          </div>
        ))}
      </div>

      {/* Conditional rendering based on state */}
      {approvalRequired && renderApprovalWorkflow()}
      {validationFeedback && renderValidationFeedback()}
      {historyView && renderHistoryView()}

      {/* Hidden accessibility mirror for AI agents */}
      <div
        role="log"
        aria-live="polite"
        aria-label="Coding agent canvas state"
        className="sr-only"
        style={{ display: 'none' }}
      />
    </Card>
  );
};
```

**Key Features:**
- Code editor UI with syntax highlighting placeholder
- Real-time operations feed showing agent progress
- Approval workflow UI with approve/retry/reject buttons
- Validation feedback display with test results and coverage
- History view with diff comparison
- AI accessibility via useAccessibilityMirror hook
- Episode integration via canvas_action_ids tracking
</action>
  <verify>ls -la frontend-nextjs/components/canvas/CodingAgentCanvas.tsx</verify>
  <done>CodingAgentCanvas.tsx created with 400+ lines, following existing canvas patterns</done>
</task>

<task type="auto">
  <name>Extend CanvasType with 'coding' type</name>
  <files>frontend-nextjs/types/canvas.ts</files>
  <action>
Update `frontend-nextjs/types/canvas.ts` to add 'coding' to CanvasType:

```typescript
export type CanvasType =
  | 'generic'
  | 'docs'
  | 'email'
  | 'sheets'
  | 'orchestration'
  | 'terminal'
  | 'coding'  // NEW: Autonomous coding agent sessions
  | 'forms';
```

**Also add coding-specific state interface:**
```typescript
export interface CodingCanvasState {
  sessionId: string;
  operations: Array<{
    id: string;
    type: 'code_generation' | 'test_generation' | 'validation' | 'documentation';
    status: 'pending' | 'running' | 'complete' | 'failed';
    timestamp: Date;
    codeContent?: string;
    testResults?: any;
  }>;
  codeContent: string;
  validationFeedback?: {
    passed: number;
    total: number;
    coverage: number;
    failures: Array<{
      test: string;
      error: string;
    }>;
  } | null;
  approvalRequired: string | null;
  language: 'python' | 'typescript' | 'javascript' | 'sql' | 'yaml';
  currentAction: string | null;
}
```
</action>
  <verify>grep -q "coding" frontend-nextjs/types/canvas.ts</verify>
  <done>CanvasType extended with 'coding' type, CodingCanvasState interface added</done>
</task>

<task type="auto">
  <name>Add episode integration for canvas metadata</name>
  <files>backend/core/episode_segmentation_service.py, backend/core/models.py</files>
  <action>
Update episode integration to track coding agent canvas operations:

**1. Update EpisodeSegment model in backend/core/models.py:**
```python
class EpisodeSegment(Base):
    # ... existing fields ...

    # Canvas metadata (existing)
    canvas_id: Optional[String] = None
    canvas_type: Optional[String] = None
    canvas_action_ids: Optional[JSON] = JSON  # NEW: List of action IDs for canvas

    # For coding canvases, track:
    # - Generated code snippets
    # - Test results
    # - Approval decisions
    # - Validation feedback
```

**2. Update episode_segmentation_service.py:**
```python
async def create_coding_canvas_segment(
    episode_id: str,
    canvas_id: str,
    operations: List[Dict],
    code_content: str,
    validation_feedback: Optional[Dict],
    approval_decision: Optional[str],
) -> EpisodeSegment:
    """Create a segment for coding agent canvas operations."""
    segment = EpisodeSegment(
        episode_id=episode_id,
        segment_type='canvas_operation',
        content={
            'canvas_id': canvas_id,
            'canvas_type': 'coding',
            'canvas_action_ids': [op['id'] for op in operations],
            'code_content': code_content,
            'operations': operations,
            'validation_feedback': validation_feedback,
            'approval_decision': approval_decision,
        },
        metadata={
            'operation_count': len(operations),
            'language': detect_language(code_content),
            'has_validation': validation_feedback is not None,
            'required_approval': approval_decision is not None,
        }
    )

    with get_db_session() as db:
        db.add(segment)
        db.commit()
        db.refresh(segment)

    return segment
```
</action>
  <verify>grep -n "canvas_action_ids" backend/core/models.py backend/core/episode_segmentation_service.py</verify>
  <done>Episode integration added with canvas_action_ids tracking for coding sessions</done>
</task>

<task type="auto">
  <name>Create unit tests for CodingAgentCanvas</name>
  <files>backend/tests/test_coding_agent_canvas.tsx</files>
  <action>
Create `frontend-nextjs/components/canvas/__tests__/CodingAgentCanvas.test.tsx`:

```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import { CodingAgentCanvas } from '../CodingAgentCanvas';

describe('CodingAgentCanvas', () => {
  const mockProps = {
    sessionId: 'test-session-123',
    onApprove: vi.fn(),
    onRetry: vi.fn(),
    onReject: vi.fn(),
  };

  it('renders code editor UI', () => {
    render(<CodingAgentCanvas {...mockProps} />);
    expect(screen.getByPlaceholderText(/generated code/i)).toBeInTheDocument();
  });

  it('displays agent operations feed', () => {
    render(<CodingAgentCanvas {...mockProps} />);
    expect(screen.getByText(/agent operations/i)).toBeInTheDocument();
  });

  it('shows approval workflow when required', async () => {
    render(<CodingAgentCanvas {...mockProps} />);
    // Trigger approval requirement
    const approveButton = await screen.findByText(/approve/i);
    expect(approveButton).toBeInTheDocument();
  });

  it('displays validation feedback', () => {
    render(<CodingAgentCanvas {...mockProps} />);
    // Mock validation feedback
    const validation = screen.getByText(/test results/i);
    expect(validation).toBeInTheDocument();
  });

  it('toggles history view', () => {
    render(<CodingAgentCanvas {...mockProps} />);
    const historyToggle = screen.getByText(/history/i);
    fireEvent.click(historyToggle);
    expect(screen.getByText(/code changes history/i)).toBeInTheDocument();
  });

  it('exposes state to AI accessibility mirror', () => {
    render(<CodingAgentCanvas {...mockProps} />);
    const mirror = document.querySelector('[role="log"][aria-live="polite"]');
    expect(mirror).toBeInTheDocument();
    expect(mirror).toHaveAttribute('aria-label', 'coding agent canvas state');
  });

  it('integrates with useCanvasState hook', () => {
    const { result } = renderHook(() => useCanvasState('coding-canvas'));
    expect(result.current).toBeDefined();
  });

  it('calls approval callbacks', async () => {
    render(<CodingAgentCanvas {...mockProps} />);
    const approveButton = await screen.findByRole('button', { name: /approve/i });
    fireEvent.click(approveButton);
    expect(mockProps.onApprove).toHaveBeenCalled();
  });
});
```
</action>
  <verify>ls -la frontend-nextjs/components/canvas/__tests__/CodingAgentCanvas.test.tsx</verify>
  <done>Unit tests created with 8+ test cases covering component rendering, hooks, approval workflow, and AI accessibility</done>
</task>

<task type="auto">
  <name>Update documentation with CodingAgentCanvas usage</name>
  <files>docs/AUTONOMOUS_CODING_AGENTS.md</files>
  <action>
Create comprehensive documentation in `docs/AUTONOMOUS_CODING_AGENTS.md` (300+ lines):

**Sections:**

1. **Overview**
   - What is CodingAgentCanvas?
   - Real-time visualization of autonomous coding
   - AI accessibility for agent context

2. **Component Features**
   - Code editor UI with syntax highlighting
   - Real-time operations feed
   - Approval workflow interface
   - Validation feedback display
   - History view with diff comparison

3. **AI Accessibility**
   - Hidden accessibility mirror (role='log', aria-live='polite')
   - Canvas state exposure via useAccessibilityMirror
   - WorldModel recall through episode integration

4. **Usage Example**
```typescript
import { CodingAgentCanvas } from '@/components/canvas/CodingAgentCanvas';

function App() {
  return (
    <CodingAgentCanvas
      sessionId="agent-session-123"
      onApprove={(actionId) => handleApproval(actionId)}
      onRetry={(actionId) => handleRetry(actionId)}
      onReject={(actionId) => handleRejection(actionId)}
    />
  );
}
```

5. **Canvas State Structure**
   - TypeScript interface (CodingCanvasState)
   - State persistence and recall
   - Episode integration details

6. **Approval Workflow**
   - When approval is required
   - Human-in-the-loop integration
   - Decision tracking

7. **Validation Feedback**
   - Test results display
   - Coverage metrics
   - Failure analysis

8. **History View**
   - Operation log
   - Diff comparison
   - Timestamp tracking

9. **Integration with Orchestrator**
   - How orchestrator updates canvas state
   - Real-time state synchronization
   - Episode creation on completion
```
</action>
  <verify>ls -la docs/AUTONOMOUS_CODING_AGENTS.md && wc -l docs/AUTONOMOUS_CODING_AGENTS.md</verify>
  <done>Documentation created with 300+ lines covering CodingAgentCanvas usage, AI accessibility, and integration</done>
</task>

</tasks>

<verification>
After all tasks complete, verify:

1. **Component check**: CodingAgentCanvas.tsx exists with 400+ lines
2. **Type extension**: CanvasType includes 'coding' type
3. **Episode integration**: canvas_action_ids tracking implemented
4. **Tests passing**: Unit tests cover rendering, hooks, approval workflow
5. **Documentation complete**: AUTONOMOUS_CODING_AGENTS.md created with usage examples
6. **AI accessibility**: Hidden mirror div with role='log' and aria-live='polite'
7. **State exposure**: useAccessibilityMirror hook used for agent context

**Success Criteria:**
- CodingAgentCanvas follows existing canvas patterns
- AI agents can read canvas state via accessibility tree
- EpisodeService tracks coding operations for WorldModel recall
- Approval workflow UI functional with approve/retry/reject
- Validation feedback displays test results and coverage
- Unit tests pass with 80%+ coverage
- Documentation is comprehensive and actionable
</verification>

<success_criteria>
1. CodingAgentCanvas component created (400+ lines)
2. CanvasType extended with 'coding' type
3. Episode integration tracks canvas_action_ids
4. Approval workflow UI with approve/retry/reject buttons
5. Validation feedback display showing test results
6. History view with diff comparison for code changes
7. Unit tests created and passing
8. AI accessibility via useAccessibilityMirror hook
9. Documentation updated with usage guide
</success_criteria>

<output>
After completion, create `.planning/phases/69-autonomous-coding-agents/69-10-SUMMARY.md` with:
- Files created (component, types, tests, docs)
- AI accessibility implementation details
- Episode integration approach
- Test coverage results
- Commit hashes for all changes
</output>
