---
phase: 69-autonomous-coding-agents
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/core/requirement_parser_service.py
  - backend/core/models.py
  - backend/api/autonomous_coding_routes.py
  - backend/tests/test_requirement_parser_service.py
  - alembic/versions/xxx_add_autonomous_coding_models.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Natural language feature requests are parsed into structured user stories"
    - "Acceptance criteria are extracted in Gherkin format (Given/When/Then)"
    - "Dependencies and integration points are identified"
    - "Complexity estimation is accurate (simple/moderate/complex/advanced)"
    - "Parser integrates with BYOK handler for LLM calls"
    - "Parsed requirements are stored in AutonomousWorkflow model"
  artifacts:
    - path: "backend/core/requirement_parser_service.py"
      provides: "Feature request parsing with LLM"
      min_lines: 300
      exports: ["RequirementParserService", "parse_requirements", "extract_acceptance_criteria"]
    - path: "backend/core/models.py"
      provides: "AutonomousWorkflow database model"
      contains: "class AutonomousWorkflow"
    - path: "backend/api/autonomous_coding_routes.py"
      provides: "REST API for requirement parsing"
      exports: ["POST /api/autonomous/parse-requirements"]
    - path: "backend/tests/test_requirement_parser_service.py"
      provides: "Test coverage for parser"
      min_lines: 200
  key_links:
    - from: "backend/core/requirement_parser_service.py"
      to: "core/llm/byok_handler.py"
      via: "BYOK handler for LLM provider routing"
      pattern: "from core.llm.byok_handler import BYOKHandler"
    - from: "backend/api/autonomous_coding_routes.py"
      to: "core/models.py"
      via: "AutonomousWorkflow model for persistence"
      pattern: "AutonomousWorkflow"
---

<objective>
Implement Feature Request Parser Service that converts natural language feature requests into structured requirements with user stories, acceptance criteria, dependencies, and complexity estimates.

Purpose: Enable autonomous coding agents to understand and structure user requests before implementation begins.
Output: RequirementParserService with LLM integration, AutonomousWorkflow model, REST API endpoint, comprehensive tests
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/69-autonomous-coding-agents/69-RESEARCH.md
@.planning/STATE.md
@backend/core/agent_governance_service.py
@backend/core/models.py
@backend/core/llm/byok_handler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AutonomousWorkflow database model</name>
  <files>backend/core/models.py</files>
  <action>
    Add AutonomousWorkflow model to backend/core/models.py with the following fields:
    - id (String, primary key, UUID)
    - workspace_id (String, ForeignKey to workspaces.id)
    - feature_request (Text, nullable=False)
    - status (String, default="pending") - pending, running, paused, completed, failed
    - current_phase (String, nullable)
    - completed_phases (JSON, default=list)
    - requirements (JSON, nullable) - Parsed requirements
    - user_stories (JSON, nullable) - List of user stories
    - acceptance_criteria (JSON, nullable) - List of Gherkin scenarios
    - implementation_plan (JSON, nullable) - Plan from planner agent
    - estimated_duration_seconds (Integer, nullable)
    - files_created (JSON, default=list)
    - files_modified (JSON, default=list)
    - test_results (JSON, nullable)
    - started_at (DateTime, default=datetime.utcnow)
    - completed_at (DateTime, nullable)
    - error_message (Text, nullable)
    - Relationships: checkpoints (to AutonomousCheckpoint), agent_logs (to AgentLog)

    Follow Atom model patterns: use SQLAlchemy ORM, proper imports, relationship definitions matching existing models like AgentRegistry.
  </action>
  <verify>grep -n "class AutonomousWorkflow" backend/core/models.py</verify>
  <done>AutonomousWorkflow model exists with all required fields and relationships</done>
</task>

<task type="auto">
  <name>Task 2: Create AutonomousCheckpoint and AgentLog models</name>
  <files>backend/core/models.py</files>
  <action>
    Add two additional models for checkpoint tracking and agent logging:

    AutonomousCheckpoint:
    - id (String, primary key, UUID)
    - workflow_id (String, ForeignKey to autonomous_workflows.id)
    - checkpoint_sha (String) - Git commit SHA for rollback
    - phase (String, nullable)
    - agent_states (JSON, nullable) - State snapshots of all agents
    - shared_state (JSON, nullable) - Shared context between agents
    - artifacts (JSON, nullable) - Files created at checkpoint
    - created_at (DateTime, default=datetime.utcnow)
    - is_rollback_point (Boolean, default=False)
    - Relationship: workflow (back to AutonomousWorkflow)

    AgentLog:
    - id (String, primary key, UUID)
    - workflow_id (String, ForeignKey to autonomous_workflows.id)
    - agent_id (String, nullable=False) - e.g., "parser-01", "coder-backend"
    - phase (String, nullable)
    - action (String, nullable)
    - input_data (JSON, nullable)
    - output_data (JSON, nullable)
    - status (String) - running, completed, failed
    - error_message (Text, nullable)
    - started_at (DateTime, default=datetime.utcnow)
    - completed_at (DateTime, nullable)
    - duration_seconds (Float, nullable)
    - Relationship: workflow (back to AutonomousWorkflow)

    Follow Atom patterns: proper ForeignKey definitions, back_populates for relationships.
  </action>
  <verify>grep -n "class AutonomousCheckpoint\|class AgentLog" backend/core/models.py</verify>
  <done>Both models exist with all fields and proper relationships</done>
</task>

<task type="auto">
  <name>Task 3: Create Alembic migration for autonomous coding models</name>
  <files>alembic/versions/xxx_add_autonomous_coding_models.py</files>
  <action>
    Create Alembic migration file for the three new models:
    - Filename format: alembic/versions/{timestamp}_add_autonomous_coding_models.py
    - Create autonomous_workflows table with all columns
    - Create autonomous_checkpoints table with foreign key to autonomous_workflows
    - Create agent_logs table with foreign key to autonomous_workflows
    - Add indexes on workflow_id, status, workspace_id for query performance
    - Use revision with downgrades for rollback support

    Follow existing Alembic migration patterns in alembic/versions/.
  </action>
  <verify>ls -la alembic/versions/*autonomous_coding*.py 2>/dev/null && echo "Migration file exists"</verify>
  <done>Migration file created with upgrade() and downgrade() methods</done>
</task>

<task type="auto">
  <name>Task 4: Implement RequirementParserService</name>
  <files>backend/core/requirement_parser_service.py</files>
  <action>
    Create RequirementParserService with LLM-based parsing:

    Class structure:
    ```python
    class RequirementParserService:
        def __init__(self, db: Session, byok_handler: BYOKHandler):
            self.db = db
            self.byok_handler = byok_handler

        async def parse_requirements(
            self,
            feature_request: str,
            workspace_id: str,
            context: Optional[dict] = None
        ) -> dict:
            \"\"\"
            Parse natural language feature request into structured requirements.

            Returns:
                {
                    "user_stories": [
                        {
                            "id": "US-001",
                            "title": "...",
                            "role": "user",
                            "action": "...",
                            "value": "...",
                            "acceptance_criteria": ["Given...", "When...", "Then..."],
                            "priority": "high|medium|low",
                            "complexity": "simple|moderate|complex|advanced"
                        }
                    ],
                    "dependencies": ["..."],
                    "integration_points": ["..."],
                    "estimated_complexity": "moderate",
                    "estimated_time": "4-6 hours"
                }
            \"\"\"

        def _extract_user_stories(self, llm_response: str) -> list:
            \"\"\"Parse LLM response into structured user stories.\"\"\"

        def _extract_acceptance_criteria(self, llm_response: str) -> list:
            \"\"\"Extract Gherkin-style scenarios from LLM response.\"\"\"

        def _estimate_complexity(self, user_stories: list) -> str:
            \"\"\"Estimate complexity based on story count and dependencies.\"\"\"

        async def create_workflow(
            self,
            feature_request: str,
            workspace_id: str,
            parsed_requirements: dict
        ) -> AutonomousWorkflow:
            \"\"\"Create AutonomousWorkflow record with parsed requirements.\"\"\"
    ```

    LLM Prompt Strategy (SYSTEM_PROMPT):
    - Use Anthropic Claude for best intent understanding
    - Output JSON with user stories, acceptance criteria, dependencies
    - Follow INVEST principles (Independent, Negotiable, Valuable, Estimable, Small, Testable)
    - Extract Gherkin scenarios (Given/When/Then)

    Integrate with BYOK handler for multi-provider LLM calls.
    Add logging for all operations (logger.info, logger.error).
    Follow Atom service patterns: Session in __init__, error handling with try/except.

    Minimum 300 lines including docstrings, error handling, and helper methods.
  </action>
  <verify>grep -n "class RequirementParserService" backend/core/requirement_parser_service.py && wc -l backend/core/requirement_parser_service.py</verify>
  <done>RequirementParserService implemented with all required methods and BYOK integration</done>
</task>

<task type="auto">
  <name>Task 5: Create REST API endpoint for requirement parsing</name>
  <files>backend/api/autonomous_coding_routes.py</files>
  <action>
    Create autonomous_coding_routes.py with FastAPI router:

    Endpoint 1: POST /api/autonomous/parse-requirements
    - Request body: {"feature_request": str, "workspace_id": str, "context": dict}
    - Response: {"workflow_id": str, "user_stories": [...], "acceptance_criteria": [...], "complexity": str}
    - Governance: AUTONOMOUS maturity required (critical operation)
    - Creates AutonomousWorkflow record
    - Returns workflow_id for tracking

    Endpoint 2: GET /api/autonomous/workflows/{workflow_id}
    - Returns workflow status, current phase, completed phases
    - Includes files_created, files_modified, test_results

    Router setup:
    - from fastapi import APIRouter, Depends, HTTPException
    - from sqlalchemy.orm import Session
    - from core.database import get_db
    - from core.requirement_parser_service import RequirementParserService
    - from core.agent_governance_service import get_governance_cache
    - Use governance check before allowing operations

    Follow Atom API route patterns (see backend/api/auth_routes.py for reference).
    Add OpenAPI documentation with examples.
  </action>
  <verify>grep -n "router.*=.*APIRouter" backend/api/autonomous_coding_routes.py && grep -n "parse-requirements" backend/api/autonomous_coding_routes.py</verify>
  <done>API routes created with proper governance checks and OpenAPI docs</done>
</task>

<task type="auto">
  <name>Task 6: Register autonomous coding router in main app</name>
  <files>backend/main.py</files>
  <action>
    Import and register the autonomous coding router in main.py:
    - Add import: from api.autonomous_coding_routes import router as autonomous_router
    - Register with app: app.include_router(autonomous_router, prefix="/api/autonomous", tags=["Autonomous Coding"])

    Follow existing router registration patterns in main.py.
    Place import with other API route imports (alphabetically or by group).
  </action>
  <verify>grep "autonomous" backend/main.py</verify>
  <done>Router registered and accessible at /api/autonomous prefix</done>
</task>

<task type="auto">
  <name>Task 7: Create comprehensive tests for RequirementParserService</name>
  <files>backend/tests/test_requirement_parser_service.py</files>
  <action>
    Create test file with 200+ lines covering:

    Test cases:
    1. test_parse_requirements_simple_feature - Basic feature request parsing
    2. test_parse_requirements_with_dependencies - Dependency extraction
    3. test_extract_user_stories - User story structure validation
    4. test_extract_acceptance_criteria_gherkin - Gherkin format validation
    5. test_estimate_complexity_simple - Simple complexity (< 50 tokens, 1-2 deps)
    6. test_estimate_complexity_moderate - Moderate complexity (50-150 tokens, 3-5 deps)
    7. test_estimate_complexity_complex - Complex (150-300 tokens, 5-10 deps)
    8. test_estimate_complexity_advanced - Advanced (300+ tokens, 10+ deps)
    9. test_create_workflow_persistence - Database record creation
    10. test_llm_integration_with_byok - BYOK handler integration
    11. test_error_handling_invalid_input - Invalid request handling
    12. test_error_handling_llm_failure - LLM failure recovery

    Fixtures:
    - db_session (SQLAlchemy session with rollback)
    - mock_byok_handler (Mock BYOKHandler with predefined responses)
    - sample_feature_request (test OAuth feature request)
    - parser_service (RequirementParserService instance)

    Use pytest, pytest-asyncio for async tests.
    Mock LLM responses to avoid actual API calls in tests.
    Validate JSON structure of parsed requirements.
    Test coverage: >= 80% for RequirementParserService.

    Follow Atom test patterns: fixtures at top, parametrize for multiple cases, clear test names.
  </action>
  <verify>pytest backend/tests/test_requirement_parser_service.py -v --cov=backend/core/requirement_parser_service --cov-report=term-missing</verify>
  <done>All tests passing with 80%+ coverage</done>
</task>

</tasks>

<verification>
1. Run database migration: alembic upgrade head
2. Run tests: pytest backend/tests/test_requirement_parser_service.py -v
3. Verify coverage: pytest --cov=backend/core/requirement_parser_service --cov-report=html
4. Test API endpoint: curl -X POST http://localhost:8000/api/autonomous/parse-requirements -d '{"feature_request": "Add OAuth2 login"}'
5. Check governance: Verify AUTONOMOUS gate is enforced
6. Verify BYOK integration: Check LLM calls route through BYOK handler
</verification>

<success_criteria>
1. Natural language requests are parsed into structured user stories with role/action/value format
2. Acceptance criteria follow Gherkin format (Given/When/Then)
3. Dependencies and integration points are identified accurately
4. Complexity estimation matches research specifications (simple/moderate/complex/advanced)
5. BYOK handler routes LLM calls to appropriate provider
6. AutonomousWorkflow records are persisted with parsed requirements
7. API endpoint is accessible with proper governance enforcement
8. Test coverage >= 80% for RequirementParserService
9. All tests passing with no flaky tests
</success_criteria>

<output>
After completion, create `.planning/phases/69-autonomous-coding-agents/69-01-SUMMARY.md` with:
- Files created/modified
- Lines of code added
- Test coverage achieved
- Next steps (Plan 69-02 depends on this plan)
</output>
