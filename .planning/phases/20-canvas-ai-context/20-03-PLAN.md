---
phase: 20-canvas-ai-context
plan: 03
type: execute
wave: 2
depends_on: []
files_modified:
  - backend/core/models.py
  - backend/alembic/versions/XXXX_add_canvas_context_to_episode_segment.py
  - backend/core/episode_segmentation_service.py
autonomous: true

must_haves:
  truths:
    - "EpisodeSegment model has canvas_context JSONB field"
    - "Database migration adds canvas_context column with default NULL"
    - "episode_segmentation_service captures canvas context when creating segments"
    - "Canvas context includes canvas_type, presentation_summary, visual_elements"
    - "Migration runs successfully without errors"
  artifacts:
    - path: "backend/core/models.py"
      provides: "EpisodeSegment model with canvas_context"
      contains: "canvas_context = Column(JSON)"
    - path: "backend/alembic/versions/XXXX_add_canvas_context_to_episode_segment.py"
      provides: "Database migration for canvas_context field"
      contains: "op.add_column('episode_segments', 'canvas_context')"
    - path: "backend/core/episode_segmentation_service.py"
      provides: "Canvas context extraction logic"
      contains: "_extract_canvas_context method"
  key_links:
    - from: "backend/core/episode_segmentation_service.py"
      to: "backend/core/models.py EpisodeSegment"
      via: "Segment creation with canvas_context parameter"
      pattern: "EpisodeSegment(...canvas_context=canvas_context...)"
    - from: "alembic migration"
      to: "database schema"
      via: "alembic upgrade head"
      pattern: "ALTER TABLE episode_segments ADD COLUMN canvas_context"
---

<objective>
Enrich EpisodeSegment with canvas_context field to store semantic understanding of canvas presentations in episodes.

**Purpose**: Episodes currently track WHAT happened (audit events) but not WHAT IT MEANT (semantic content of canvases). Adding canvas_context enables richer semantic search.

**Output**: EpisodeSegment.canvas_context JSONB field with migration, and updated episode_segmentation_service to capture canvas context.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/20-canvas-ai-context/20-RESEARCH.md
@.planning/ROADMAP.md
@.planning/STATE.md

@backend/core/models.py
@backend/core/episode_segmentation_service.py
@backend/core/episode_retrieval_service.py
</context>

<tasks>

<task type="auto">
  <name>Add canvas_context field to EpisodeSegment model</name>
  <files>backend/core/models.py</files>
  <action>
    Add canvas_context JSONB field to the EpisodeSegment model.

    First, find the EpisodeSegment class in models.py (around line 1800-1900 based on file size).

    Add the canvas_context column after the feedback_context field (or at the end of the model definition):

    ```python
    # Add this column to EpisodeSegment class
    canvas_context = Column(JSON, nullable=True, comment="""
        Canvas presentation context for semantic understanding.
        Stores metadata about what was presented on canvases during episode creation.

        Schema:
        {
            "canvas_type": str,  # "generic", "docs", "email", "sheets", "orchestration", "terminal", "coding"
            "presentation_summary": str,  # "Agent presented 3 charts: user growth, revenue, engagement"
            "visual_elements": List[str],  # ["line_chart", "data_table", "approval_form"]
            "user_interaction": str,  # "User clicked 'Approve Workflow' button"
            "critical_data_points": {  # Business logic data
                "workflow_id": str,
                "approval_status": str,  # "approved", "rejected", "pending"
                "revenue": str,  # "$1.2M"
                "amount": float,
                "priority": int,
                "created_at": str,
                "updated_at": str
            }
        }

        Progressive detail levels:
        - summary: presentation_summary only (~50 tokens) - DEFAULT
        - standard: summary + critical_data_points (~200 tokens)
        - full: all fields including visual_elements (~500 tokens)
    """)
    ```

    The location should be after any existing JSON columns in EpisodeSegment (like feedback_context if it exists).
  </action>
  <verify>
    1. EpisodeSegment class has canvas_context column
    2. Column type is JSON (JSONB in PostgreSQL)
    3. Column is nullable (True) for backward compatibility
    4. Comment/description includes schema documentation
  </verify>
  <done>
    EpisodeSegment model now supports storing canvas context with semantic information.
  </done>
</task>

<task type="auto">
  <name>Create database migration for canvas_context field</name>
  <files>backend/alembic/versions/XXXX_add_canvas_context_to_episode_segment.py</files>
  <action>
    Create a new Alembic migration to add the canvas_context column to episode_segments table.

    1. First, check current migration version:
    ```bash
    cd /Users/rushiparikh/projects/atom/backend
    alembic current
    ```

    2. Create new migration:
    ```bash
    alembic revision -m "add canvas_context to episode_segment"
    ```

    3. Edit the generated migration file to add:
    ```python
    """add canvas_context to episode_segment

    Revision ID: XXXX
    Revises: [previous_revision_id]
    Create Date: 2026-02-18

    """
    from alembic import op
    import sqlalchemy as sa


    # revision identifiers, used by Alembic.
    revision = 'XXXX'
    down_revision = '[previous_revision_id]'  # Replace with actual previous revision
    branch_labels = None
    depends_on = None


    def upgrade():
        # Add canvas_context column as JSONB (JSON type maps to JSONB in PostgreSQL)
        op.add_column(
            'episode_segments',
            sa.Column(
                'canvas_context',
                sa.JSON(),
                nullable=True,
                comment='Canvas presentation context for semantic understanding'
            )
        )

        # Create GIN index on canvas_context for efficient JSON queries
        # This enables: WHERE canvas_context->>'canvas_type' = 'orchestration'
        op.execute("""
            CREATE INDEX idx_episode_segments_canvas_context
            ON episode_segments USING GIN (canvas_context)
        """)

        # Create index on canvas_type for common queries
        op.execute("""
            CREATE INDEX idx_episode_segments_canvas_type
            ON episode_segments ((canvas_context->>'canvas_type'))
            WHERE canvas_context IS NOT NULL
        """)


    def downgrade():
        # Drop indexes first
        op.execute("DROP INDEX IF EXISTS idx_episode_segments_canvas_type")
        op.execute("DROP INDEX IF EXISTS idx_episode_segments_canvas_context")

        # Remove column
        op.drop_column('episode_segments', 'canvas_context')
    ```

    4. Replace [previous_revision_id] with the actual revision ID from the current migration.

    Note: Use the actual revision ID format from your alembic/versions directory.
  </action>
  <verify>
    1. Migration file created in alembic/versions directory
    2. Migration adds canvas_context column
    3. Migration creates GIN index for JSON queries
    4. Migration creates canvas_type index for filtering
    5. downgrade() properly cleans up
  </verify>
  <done>
    Database migration ready to add canvas_context field to episode_segments table.
  </done>
</task>

<task type="auto">
  <name>Update episode_segmentation_service to capture canvas context</name>
  <files>backend/core/episode_segmentation_service.py</files>
  <action>
    Add canvas context extraction logic to episode_segmentation_service.py.

    1. Add a new method `_extract_canvas_context` to the EpisodeSegmentationService class (after the _fetch_canvas_context method around line 190-200):

    ```python
    def _extract_canvas_context(self, canvas_audits: List[CanvasAudit]) -> Optional[Dict[str, Any]]:
        """
        Extract semantic canvas context from CanvasAudit records.

        Args:
            canvas_audits: List of CanvasAudit records for the session

        Returns:
            Canvas context dict or None if no canvas audits
        """
        if not canvas_audits:
            return None

        # Aggregate canvas types and actions
        canvas_types = set()
        visual_elements = []
        user_interactions = []
        critical_data = {}

        for audit in canvas_audits:
            canvas_types.add(audit.canvas_type)

            # Extract visual elements from canvas metadata
            if audit.metadata_json:
                metadata = audit.metadata_json

                # Check for component type
                component = metadata.get('component', '')
                if component:
                    visual_elements.append(component)

                # Extract critical data points based on canvas type
                if audit.canvas_type == 'orchestration':
                    if 'workflow_id' in metadata:
                        critical_data['workflow_id'] = metadata['workflow_id']
                    if 'approval_status' in metadata:
                        critical_data['approval_status'] = metadata['approval_status']

                elif audit.canvas_type == 'sheets':
                    if 'revenue' in metadata:
                        critical_data['revenue'] = metadata['revenue']
                    if 'amount' in metadata:
                        critical_data['amount'] = metadata['amount']

                elif audit.canvas_type == 'terminal':
                    if 'command' in metadata:
                        critical_data['command'] = metadata['command']
                    if 'exit_code' in metadata:
                        critical_data['exit_code'] = metadata['exit_code']

            # Extract user interaction from action
            if audit.action:
                interaction_map = {
                    'submit': 'User submitted form',
                    'close': 'User closed canvas',
                    'update': 'User updated canvas content',
                    'execute': 'User executed action',
                    'present': 'Agent presented canvas',
                    'approve': 'User approved',
                    'reject': 'User rejected'
                }
                interaction = interaction_map.get(audit.action, f'User action: {audit.action}')
                if audit.action in ['submit', 'approve', 'reject', 'close']:
                    user_interactions.append(interaction)

        # Build presentation summary
        canvas_type_str = ', '.join(sorted(canvas_types)) if canvas_types else 'unknown'
        visual_elements_str = ', '.join(sorted(set(visual_elements))) if visual_elements else 'elements'

        if visual_elements_str:
            presentation_summary = f"Agent presented {visual_elements_str} on {canvas_type_str} canvas"
        else:
            presentation_summary = f"Agent presented {canvas_type_str} canvas"

        # Build canvas context object
        canvas_context = {
            'canvas_type': list(canvas_types)[0] if len(canvas_types) == 1 else 'generic',
            'presentation_summary': presentation_summary,
            'visual_elements': sorted(set(visual_elements)),
        }

        # Add user interaction (most recent)
        if user_interactions:
            canvas_context['user_interaction'] = user_interactions[-1]

        # Add critical data points
        if critical_data:
            canvas_context['critical_data_points'] = critical_data

        return canvas_context if canvas_context else None
    ```

    2. Update the `create_episode_from_session` method to use canvas context when creating segments.

    Find where EpisodeSegment is created (around line 250-300) and add canvas_context:

    ```python
    # After fetching canvas context (around line 190-195)
    # Add:
    canvas_context = self._extract_canvas_context(canvas_audits)
    ```

    Then find where EpisodeSegment objects are created and add canvas_context parameter:

    ```python
    # When creating EpisodeSegment, add canvas_context
    segment = EpisodeSegment(
        episode_id=episode.id,
        sequence_number=i,
        segment_type=segment_type,
        content=content,
        timestamp=timestamp,
        agent_id=agent_id,
        user_id=user_id,
        related_execution_id=execution.id if execution else None,
        canvas_audit_id=canvas_audit.id if canvas_audit else None,
        feedback_id=feedback.id if feedback else None,
        canvas_context=canvas_context if canvas_audit else None,  # NEW: Add canvas context for canvas-related segments
        metadata_json=segment_metadata
    )
    ```

    3. Also update the `create_segment` method if it exists to accept canvas_context.
  </action>
  <verify>
    1. _extract_canvas_context method exists in EpisodeSegmentationService
    2. Method handles all 7 canvas types (generic, docs, email, sheets, orchestration, terminal, coding)
    3. EpisodeSegment creation includes canvas_context parameter
    4. Canvas context includes presentation_summary, visual_elements, user_interaction, critical_data_points
  </verify>
  <done>
    Episode segments now capture canvas context for semantic understanding of canvas presentations.
  </done>
</task>

</tasks>

<verification>
After completion, verify:
1. Run `alembic upgrade head` to apply migration
2. Check episode_segments table schema for canvas_context column
3. Run pytest tests for episode_segmentation_service
4. Verify GIN index created on canvas_context
5. Test creating episode with canvas audits to see context captured
</verification>

<success_criteria>
1. canvas_context field exists in episode_segments table (JSONB type)
2. Database migration runs successfully without errors
3. EpisodeSegment creation includes canvas_context when canvas audits exist
4. Canvas context includes all required fields (canvas_type, presentation_summary, visual_elements)
5. GIN index enables efficient JSON queries on canvas_context
</success_criteria>

<output>
After completion, create `.planning/phases/20-canvas-ai-context/20-03-SUMMARY.md`
</output>
