---
phase: 19-coverage-push-and-bug-fixes
plan: 03
type: execute
wave: 2
depends_on: [19-01, 19-02]
files_modified:
  - backend/tests/unit/test_canvas_tool_expanded.py
  - backend/tests/property_tests/governance/test_agent_governance_invariants.py
  - backend/tests/coverage_reports/metrics/coverage.json
autonomous: true

must_haves:
  truths:
    - "tools/canvas_tool.py presentation and interaction functions are tested"
    - "core/agent_governance_service.py maturity checks and permissions are tested"
    - "Property tests verify governance cache invariants"
    - "Both files achieve 50%+ coverage target"
    - "All tests pass with proper fixture usage"
  artifacts:
    - path: "backend/tests/unit/test_canvas_tool_expanded.py"
      provides: "Expanded unit tests for tools/canvas_tool.py"
      min_lines: 500
      exports: ["TestCanvasPresentation", "TestCanvasInteraction", "TestCanvasComponents"]
    - path: "backend/tests/property_tests/governance/test_agent_governance_invariants.py"
      provides: "Property tests for core/agent_governance_service.py"
      min_lines: 600
      exports: ["TestGovernanceInvariants", "TestMaturityMatrix", "TestGovernanceCache"]
  key_links:
    - from: "test_canvas_tool_expanded.py"
      to: "tools/canvas_tool.py"
      via: "AsyncMock for canvas service and WebSocket manager"
      pattern: "AsyncMock.*canvas.*ws_manager"
    - from: "test_agent_governance_invariants.py"
      to: "core/agent_governance_service.py"
      via: "Hypothesis strategies for maturity levels and action complexity"
      pattern: "st.sampled_from.*MATURITY_LEVELS"
---

# Phase 19 Plan 03: Canvas Tool & Governance Service Coverage

**Objective:** Achieve 50% coverage on tools/canvas_tool.py (312 uncovered lines) and core/agent_governance_service.py (326 uncovered lines) using expanded unit tests for canvas presentations and property tests for governance invariants.

**Purpose:** These are Tier 2 high-impact files. Testing canvas components and governance matrix will provide +0.6% overall coverage contribution per file.

**Output:** Expanded unit tests for canvas tool, property tests for governance invariants, updated coverage report.

## <execution_context>

@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md

</execution_context>

## <context>

@.planning/phases/19-coverage-push-and-bug-fixes/19-RESEARCH.md
@.planning/phases/02-core-property-tests/02-core-property-tests-01-SUMMARY.md
@backend/tools/canvas_tool.py
@backend/core/agent_governance_service.py
@backend/tests/unit/test_canvas_tool.py
@backend/tests/unit/test_agent_governance_service.py

## <tasks>

<task type="auto">
  <name>Task 1: Create expanded unit tests for tools/canvas_tool.py</name>
  <files>backend/tests/unit/test_canvas_tool_expanded.py</files>
  <action>
Create `backend/tests/unit/test_canvas_tool_expanded.py` with ~500 lines covering:

1. **Canvas Presentation Tests (TestCanvasPresentation):**
   - test_present_chart_with_data
   - test_present_markdown_with_content
   - test_present_form_with_schema
   - test_present_sheet_with_rows
   - test_present_orchestration_canvas
   - test_present_email_canvas
   - test_present_terminal_canvas
   - test_present_coding_canvas

2. **Canvas Interaction Tests (TestCanvasInteraction):**
   - test_submit_form_with_valid_data
   - test_submit_form_with_validation_error
   - test_update_canvas_with_new_data
   - test_close_canvas_with_action
   - test_execute_canvas_command

3. **Canvas Component Tests (TestCanvasComponents):**
   - test_custom_component_validation
   - test_component_version_control
   - test_component_security_check
   - test_component_javascript_allowed_for_autonomous
   - test_component_html_requires_supervised

**Use AsyncMock for canvas service dependencies:**
```python
@pytest.fixture
def mock_canvas_service():
    service = AsyncMock()
    service.create_canvas = AsyncMock(return_value="canvas-123")
    service.update_canvas = AsyncMock()
    service.close_canvas = AsyncMock()
    return service

@pytest.fixture
def mock_ws_manager():
    manager = AsyncMock()
    manager.send_to_user = AsyncMock()
    manager.broadcast = AsyncMock()
    return manager
```

**Pattern from existing test_canvas_tool.py:**
- Use test fixtures for canvas data (chart_data, form_schema, sheet_rows)
- Mock WebSocket manager for send operations
- Test all 7 built-in canvas types

**Target:** 50% coverage on tools/canvas_tool.py (250+ of existing lines)
  </action>
  <verify>
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_canvas_tool_expanded.py -v --cov=tools/canvas_tool --cov-report=term-missing
  </verify>
  <done>
All canvas tests pass, coverage report shows 50%+ on tools/canvas_tool.py
  </done>
</task>

<task type="auto">
  <name>Task 2: Create property tests for core/agent_governance_service.py</name>
  <files>backend/tests/property_tests/governance/test_agent_governance_invariants.py</files>
  <action>
Create `backend/tests/property_tests/governance/test_agent_governance_invariants.py` with ~600 lines covering:

1. **Governance Invariants Tests (TestGovernanceInvariants):**
   - test_maturity_level_enumeration
   - test_action_complexity_bounds
   - test_confidence_score_range
   - test_governance_check_deterministic
   - test_permission_matrix_complete

2. **Maturity Matrix Tests (TestMaturityMatrix):**
   - @given test all 4x4 maturity/complexity combinations
   - test_student_blocked_from_high_complexity
   - test_intern_requires_approval_for_moderate
   - test_supervised_can_execute_high_with_monitoring
   - test_autonomous_full_access

3. **Governance Cache Tests (TestGovernanceCache):**
   - test_cache_hit_returns_same_result
   - test_cache_miss_calls_governance_check
   - test_cache_invalidation_on_agent_update
   - test_cache_performance_sub_millisecond

**Use Hypothesis strategies for exhaustive testing:**
```python
from hypothesis import given, strategies as st, settings, HealthCheck

@given(
    maturity=st.sampled_from(["STUDENT", "INTERN", "SUPERVISED", "AUTONOMOUS"]),
    complexity=st.integers(min_value=1, max_value=4),
    confidence=st.floats(min_value=0.0, max_value=1.0)
)
@settings(max_examples=100)
def test_maturity_complexity_permissions(self, maturity, complexity, confidence):
    """INVARIANT: Permission matrix is consistent for all maturity/complexity combinations"""
    service = AgentGovernanceService()
    allowed = service.check_permission(maturity, complexity, confidence)

    # Student cannot execute high complexity actions
    if maturity == "STUDENT" and complexity >= 3:
        assert not allowed

    # Autonomous agents with high confidence can execute anything
    if maturity == "AUTONOMOUS" and confidence > 0.9:
        assert allowed
```

**Pattern from Phase 02 property tests:**
- Use @example decorators for specific edge cases
- Document invariants in docstrings
- Use max_examples=100 for critical governance checks

**Target:** 50% coverage on core/agent_governance_service.py (300+ of existing lines)
  </action>
  <verify>
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/property_tests/governance/test_agent_governance_invariants.py -v --cov=core/agent_governance_service --cov-report=term-missing
  </verify>
  <done>
All governance tests pass, coverage report shows 50%+ on core/agent_governance_service.py
  </done>
</task>

<task type="auto">
  <name>Task 3: Generate coverage report and validate targets</name>
  <files>backend/tests/coverage_reports/metrics/coverage.json</files>
  <action>
1. Run coverage for both files:
```bash
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest \
  backend/tests/unit/test_canvas_tool_expanded.py \
  backend/tests/property_tests/governance/test_agent_governance_invariants.py \
  --cov=tools/canvas_tool \
  --cov=core/agent_governance_service \
  --cov-report=html \
  --cov-report=json \
  --cov-report=term-missing
```

2. Verify targets met:
- tools/canvas_tool.py: 50%+ coverage
- core/agent_governance_service.py: 50%+ coverage

3. Document coverage results in plan summary

4. If targets not met:
- Review coverage report for uncovered lines
- Add targeted tests for specific uncovered functions
- Re-run coverage until targets achieved
  </action>
  <verify>
python -c "import json; data = json.load(open('backend/tests/coverage_reports/metrics/coverage.json')); canvas = data['files'].get('tools/canvas_tool.py', {}); gov = data['files'].get('core/agent_governance_service.py', {}); print(f'canvas_tool.py: {canvas[\"summary\"][\"percent_covered\"]}%'); print(f'agent_governance_service.py: {gov[\"summary\"][\"percent_covered\"]}%')"
  </verify>
  <done>
Both files achieve 50%+ coverage, coverage.json updated with results
  </done>
</task>

</tasks>

## <verification>

After completion, verify:
1. Test files exist with minimum line counts (canvas ~500 lines, governance ~600 lines)
2. All tests pass: pytest backend/tests/unit/test_canvas_tool_expanded.py backend/tests/property_tests/governance/test_agent_governance_invariants.py -v
3. Coverage targets achieved: tools/canvas_tool.py 50%+, core/agent_governance_service.py 50%+
4. No property test health check failures (use suppress_health_check where needed)
5. Coverage report generated in backend/tests/coverage_reports/metrics/coverage.json

</verification>

## <success_criteria>

- [ ] test_canvas_tool_expanded.py created with 500+ lines
- [ ] test_agent_governance_invariants.py created with 600+ lines
- [ ] tools/canvas_tool.py coverage >= 50%
- [ ] core/agent_governance_service.py coverage >= 50%
- [ ] All tests pass (100% pass rate)
- [ ] Coverage report generated and documented

## <output>

After completion, create `.planning/phases/19-coverage-push-and-bug-fixes/19-03-SUMMARY.md`
</output>
