---
phase: 19-coverage-push-and-bug-fixes
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py
  - backend/tests/integration/test_workflow_analytics_integration.py
  - backend/tests/coverage_reports/metrics/coverage.json
autonomous: true

must_haves:
  truths:
    - "workflow_engine.py async execution paths are tested (error handling, retry logic, state manager integration)"
    - "workflow_analytics_engine.py metrics tracking and aggregation functions are tested"
    - "Property tests verify workflow state machine invariants (status transitions, DAG topology, cancellation)"
    - "Both files achieve 50%+ coverage target"
    - "All tests pass with no session management issues"
  artifacts:
    - path: "backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py"
      provides: "Async execution path tests for workflow_engine.py"
      min_lines: 600
      exports: ["TestAsyncWorkflowExecution", "TestRetryLogic", "TestStateManagerIntegration"]
    - path: "backend/tests/integration/test_workflow_analytics_integration.py"
      provides: "Integration tests for workflow_analytics_engine.py"
      min_lines: 400
      exports: ["TestWorkflowMetricsTracking", "TestAggregationQueries", "TestPerformanceReporting"]
  key_links:
    - from: "test_workflow_engine_async_execution.py"
      to: "core/workflow_engine.py"
      via: "AsyncMock for state_manager, ws_manager, analytics"
      pattern: "AsyncMock.*state_manager"
    - from: "test_workflow_analytics_integration.py"
      to: "core/workflow_analytics_engine.py"
      via: "Database session with factory-created workflows"
      pattern: "WorkflowExecutionFactory.*analytics"
---

# Phase 19 Plan 01: Workflow Engine & Analytics Coverage

**Objective:** Achieve 50% coverage on workflow_engine.py (1,089 uncovered lines) and workflow_analytics_engine.py (408 uncovered lines) using property tests for async execution invariants and integration tests for analytics tracking.

**Purpose:** These are Tier 1 high-impact files with the largest coverage gaps. Testing async execution paths and analytics will provide +1.2% overall coverage contribution per file.

**Output:** Property tests for workflow async invariants, integration tests for analytics metrics, updated coverage report.

## <execution_context>

@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md

</execution_context>

## <context>

@.planning/phases/19-coverage-push-and-bug-fixes/19-RESEARCH.md
@.planning/phases/12-tier-1-coverage-push/12-tier-1-coverage-push-01-SUMMARY.md
@.planning/phases/12-tier-1-coverage-push/12-tier-1-coverage-push-02-SUMMARY.md
@backend/core/workflow_engine.py
@backend/core/workflow_analytics_engine.py
@backend/tests/property_tests/workflows/test_workflow_engine_state_invariants.py

## <tasks>

<task type="auto">
  <name>Task 1: Create property tests for workflow_engine.py async execution paths</name>
  <files>backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py</files>
  <action>
Create `backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py` with ~600 lines covering:

1. **Async Workflow Execution Tests (TestAsyncWorkflowExecution):**
   - test_execute_workflow_graph_with_mocked_steps
   - test_execute_workflow_with_step_timeout
   - test_execute_workflow_with_step_failure_continue_on_error
   - test_execute_workflow_with_step_failure_stop_on_error
   - test_pause_workflow_execution
   - test_resume_workflow_execution
   - test_cancel_workflow_execution

2. **Retry Logic Tests (TestRetryLogic):**
   - test_retry_on_transient_failure
   - test_retry_respects_max_attempts
   - test_retry_with_exponential_backoff
   - test_no_retry_on_permanent_failure

3. **State Manager Integration Tests (TestStateManagerIntegration):**
   - test_create_execution_called_on_start
   - test_update_step_status_on_completion
   - test_update_execution_status_on_finish
   - test_get_execution_state_returns_current_state

4. **Concurrency Control Tests (TestConcurrencyControl):**
   - test_max_concurrent_steps_enforced
   - test_step_queue_ordering_preserved
   - test_blocking_step_waits_for_dependencies

**Use AsyncMock for all async dependencies:**
- state_manager: AsyncMock with create_execution, get_execution_state, update_step_status, update_execution_status
- ws_manager: AsyncMock with notify_workflow_status, notify_step_complete
- analytics: AsyncMock with track_step_execution, track_workflow_execution

**Pattern from Phase 12-01:**
```python
@given(
    current_status=st.sampled_from([
        WorkflowExecutionStatus.PENDING,
        WorkflowExecutionStatus.RUNNING,
        WorkflowExecutionStatus.COMPLETED,
        WorkflowExecutionStatus.FAILED,
        WorkflowExecutionStatus.PAUSED,
        WorkflowExecutionStatus.CANCELLED
    ])
)
@settings(max_examples=100, suppress_health_check=[HealthCheck.function_scoped_fixture])
async def test_async_status_transition(self, engine, current_status):
    """INVARIANT: Async execution respects valid status transitions"""
    # Test async transition logic
```

**Target:** 50% coverage on workflow_engine.py (582 of 1,163 lines)
  </action>
  <verify>
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py -v --cov=core/workflow_engine --cov-report=term-missing
  </verify>
  <done>
All async execution tests pass, coverage report shows 50%+ on workflow_engine.py
  </done>
</task>

<task type="auto">
  <name>Task 2: Create integration tests for workflow_analytics_engine.py</name>
  <files>backend/tests/integration/test_workflow_analytics_integration.py</files>
  <action>
Create `backend/tests/integration/test_workflow_analytics_integration.py` with ~400 lines covering:

1. **Metrics Tracking Tests (TestWorkflowMetricsTracking):**
   - test_track_step_execution_creates_metrics_record
   - test_track_workflow_execution_creates_summary
   - test_track_execution_time_recorded
   - test_track_error_counts_recorded
   - test_track_success_rates_calculated

2. **Aggregation Query Tests (TestAggregationQueries):**
   - test_get_workflow_metrics_by_id
   - test_get_workflow_metrics_by_date_range
   - test_get_average_execution_time
   - test_get_most_failed_steps
   - test_get_workflow_success_rate

3. **Performance Reporting Tests (TestPerformanceReporting):**
   - test_generate_performance_report
   - test_generate_comparison_report
   - test_export_metrics_to_csv
   - test_metrics_trend_analysis

**Use factory-boy for test data:**
- WorkflowExecutionFactory for creating workflow executions
- UserFactory for creating test users
- Use db_session fixture from backend/tests/integration/conftest.py

**Pattern from Phase 12-02:**
```python
def test_track_step_execution_creates_metrics_record(self, db: Session):
    execution = WorkflowExecutionFactory(status="completed")
    metrics = self.analytics.track_step_execution(
        execution_id=execution.id,
        step_id="step1",
        duration_ms=1500,
        status="success"
    )
    assert metrics.execution_id == execution.id
    assert metrics.step_id == "step1"
    assert metrics.duration_ms == 1500
```

**Target:** 50% coverage on workflow_analytics_engine.py (297 of 593 lines)
  </action>
  <verify>
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/integration/test_workflow_analytics_integration.py -v --cov=core/workflow_analytics_engine --cov-report=term-missing
  </verify>
  <done>
All analytics tests pass, coverage report shows 50%+ on workflow_analytics_engine.py
  </done>
</task>

<task type="auto">
  <name>Task 3: Generate coverage report and validate targets</name>
  <files>backend/tests/coverage_reports/metrics/coverage.json</files>
  <action>
1. Run coverage for both files:
```bash
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest \
  backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py \
  backend/tests/integration/test_workflow_analytics_integration.py \
  --cov=core/workflow_engine \
  --cov=core/workflow_analytics_engine \
  --cov-report=html \
  --cov-report=json \
  --cov-report=term-missing
```

2. Verify targets met:
- workflow_engine.py: 50%+ coverage (582+ of 1,163 lines)
- workflow_analytics_engine.py: 50%+ coverage (297+ of 593 lines)

3. Document coverage results in plan summary

4. If targets not met:
- Review coverage report for uncovered lines (see `htmlcov/` directory)
- Add targeted tests for specific uncovered functions
- Re-run coverage until targets achieved
  </action>
  <verify>
python -c "import json; data = json.load(open('backend/tests/coverage_reports/metrics/coverage.json')); we = data['files'].get('core/workflow_engine.py', {}); wae = data['files'].get('core/workflow_analytics_engine.py', {}); print(f'workflow_engine.py: {we[\"summary\"][\"percent_covered\"]}%'); print(f'workflow_analytics_engine.py: {wae[\"summary\"][\"percent_covered\"]}%')"
  </verify>
  <done>
Both files achieve 50%+ coverage, coverage.json updated with results
  </done>
</task>

</tasks>

## <verification>

After completion, verify:
1. Test files exist with minimum line counts (async execution ~600 lines, analytics ~400 lines)
2. All tests pass: pytest backend/tests/property_tests/workflows/test_workflow_engine_async_execution.py backend/tests/integration/test_workflow_analytics_integration.py -v
3. Coverage targets achieved: workflow_engine.py 50%+, workflow_analytics_engine.py 50%+
4. No session management issues (all tests use proper fixtures)
5. Coverage report generated in backend/tests/coverage_reports/metrics/coverage.json

</verification>

## <success_criteria>

- [ ] test_workflow_engine_async_execution.py created with 600+ lines
- [ ] test_workflow_analytics_integration.py created with 400+ lines
- [ ] workflow_engine.py coverage >= 50% (582+ lines)
- [ ] workflow_analytics_engine.py coverage >= 50% (297+ lines)
- [ ] All tests pass (100% pass rate)
- [ ] Coverage report generated and documented

## <output>

After completion, create `.planning/phases/19-coverage-push-and-bug-fixes/19-01-SUMMARY.md`
</output>
