---
phase: 19-coverage-push-and-bug-fixes
plan: 07
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/tests/unit/test_byok_handler_expanded.py
  - backend/core/llm/byok_handler.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "All 13 failing BYOK handler tests now pass"
    - "Tests use correct BYOKHandler API methods"
    - "AsyncMock coroutines properly awaited"
    - "No RuntimeWarning about unawaited coroutines"
  artifacts:
    - path: "backend/tests/unit/test_byok_handler_expanded.py"
      provides: "Fixed unit tests for BYOK handler"
      min_lines: 700
    - path: "backend/core/llm/byok_handler.py"
      contains: "class BYOKHandler"
  key_links:
    - from: "test_byok_handler_expanded.py"
      to: "core/llm/byok_handler.py"
      via: "real BYOKHandler methods (not mocked API)"
      pattern: "handler\\.(complete_chat|stream_tokens|query)"
---

<objective>
Fix the 13 failing BYOK handler tests caused by incorrect method names and AsyncMock coroutine handling issues.

**Root Causes (from VERIFICATION.md):**
1. AttributeError: 'BYOKHandler' object has no attribute 'complete_chat' - tests using wrong API method names
2. RuntimeWarning: coroutine was never awaited - AsyncMock returns coroutines that aren't properly awaited
3. Tests don't match actual BYOKHandler API (complete_chat doesn't exist)

**Gap Closed:** 13 failing tests in test_byok_handler_expanded.py

**Output:** Working unit tests that match actual BYOKHandler API
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
@.planning/phases/19-coverage-push-and-bug-fixes/19-VERIFICATION.md
</execution_context>

<context>
@.planning/phases/19-coverage-push-and-bug-fixes/19-02-SUMMARY.md
@.planning/phases/19-coverage-push-and-bug-fixes/19-04-FAILURES.md
@backend/core/llm/byok_handler.py
@backend/tests/unit/test_byok_handler_expanded.py
</context>

<tasks>

<task type="auto">
  <name>Identify correct BYOKHandler API methods</name>
  <files>backend/core/llm/byok_handler.py</files>
  <action>
    First, identify the actual API methods available on BYOKHandler class.

    Search for all public methods in BYOKHandler:
    ```bash
    grep -n "^\s*def\|^\s*async def" backend/core/llm/byok_handler.py | head -30
    ```

    The tests call `complete_chat()` but the actual API likely has different method names.

    Common patterns for LLM handlers:
    - `query()` or `chat()` for completion
    - `stream_chat()` or `stream()` for streaming
    - `acomplete()` or `async_complete()` for async

    Document the actual API and create mapping:
    - Test calls: `handler.complete_chat()` → Actual: `handler.???()`
    - Test calls: `handler.stream_tokens()` → Actual: `handler.???()`

    This task is analysis only - document findings in comments, no code changes yet.
  </action>
  <verify>
    # Output should show actual method names
    grep -E "^\s*(async )?def [a-z_]" backend/core/llm/byok_handler.py | grep -v "^_"
  </verify>
  <done>Actual BYOKHandler API methods documented</done>
</task>

<task type="auto">
  <name>Fix TestProviderFailover tests (5 failures)</name>
  <files>backend/tests/unit/test_byok_handler_expanded.py</files>
  <action>
    The TestProviderFailover class tests fail because:
    1. `handler.complete_chat()` method doesn't exist (AttributeError)
    2. Tests don't match actual BYOKHandler API

    Tests to fix (~lines 61-195):
    - test_openai_fails_over_to_anthropic
    - test_anthropic_fails_over_to_deepseek
    - test_all_providers_fail_raises_error
    - test_provider_timeout_triggers_failover
    - test_provider_rate_limit_triggers_failover

    Fix approach:
    1. Replace `handler.complete_chat()` with actual method name (from Task 1 discovery)
    2. Update response handling to match actual API
    3. Fix AsyncMock usage - use `AsyncMock(return_value=...)` not `AsyncMock().return_value`

    Common pattern for AsyncMock with async generators (streaming):
    ```python
    # Wrong - causes "coroutine was never awaited"
    mock_response.stream = AsyncMock(return_value=chunk_list)

    # Right for streaming
    async def mock_stream():
        for chunk in chunk_list:
            yield chunk
    mock_response.stream = mock_stream()
    ```

    Also update assertions to match actual response structure (may not have .choices[0].message.content).
  </action>
  <verify>
    PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py::TestProviderFailover -v --tb=short
  </verify>
  <done>All 5 TestProviderFailover tests pass</done>
</task>

<task type="auto">
  <name>Fix TestTokenStreaming tests (4 failures)</name>
  <files>backend/tests/unit/test_byok_handler_expanded.py</files>
  <action>
    The TestTokenStreaming class tests fail with:
    "'async for' received an object from __aiter__ that does not implement __anext__: coroutine"

    Tests to fix (~lines 197-310):
    - test_stream_tokens_openai
    - test_stream_tokens_anthropic
    - test_stream_tokens_with_stop_sequence
    - test_stream_tokens_error_handling

    Root cause: AsyncMock being used incorrectly for async generators.

    The BYOKHandler likely has a streaming method that returns an async generator. Tests need to properly mock this.

    Fix pattern:
    ```python
    # Instead of mocking the entire handler async_clients, mock at the LLM client level
    # Create a real async generator function for the mock

    async def mock_stream_generator():
        chunks = ["Hello", " world", "!"]
        for chunk in chunks:
            yield {"delta": {"content": chunk}}

    # Set up the mock to return this generator
    mock_openai.chat.completions.create.return_value = mock_stream_generator()
    ```

    Also update test assertions to handle async iteration correctly:
    ```python
    response = await handler.streaming_method(...)
    async for chunk in response:
        # Process chunk
    ```
  </action>
  <verify>
    PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py::TestTokenStreaming -v --tb=short
  </verify>
  <done>All 5 TestTokenStreaming tests pass (4 failures + 1 existing pass)</done>
</task>

<task type="auto">
  <name>Fix TestEdgeCases tests (4 failures)</name>
  <files>backend/tests/unit/test_byok_handler_expanded.py</files>
  <action>
    The TestEdgeCases class has tests that fail due to API mismatch.

    Tests to fix (~lines 597-700):
    - test_empty_messages_list
    - test_very_long_context
    - test_special_characters_in_prompt
    - test_concurrent_requests

    Issues:
    1. Method name mismatch (complete_chat → actual method)
    2. Response handling doesn't match actual API
    3. Concurrent requests test may need proper async handling

    For test_empty_messages_list:
    - The test expects empty messages to be handled (error or graceful)
    - Update to use actual method name
    - Check actual behavior (raises ValidationError? returns empty?)

    For test_very_long_context:
    - Verify actual context limit handling
    - Update assertions based on real behavior

    For test_special_characters_in_prompt:
    - Just needs method name fix

    For test_concurrent_requests:
    - Ensure asyncio.gather properly awaits all tasks
    - Check for proper exception handling
  </action>
  <verify>
    PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py::TestEdgeCases -v --tb=short
  </verify>
  <done>All 4 TestEdgeCases tests pass</done>
</task>

<task type="auto">
  <name>Run all BYOK handler tests and verify 100% pass rate</name>
  <files>backend/tests/unit/test_byok_handler_expanded.py</files>
  <action>
    Run the full test suite for BYOK handler:

    ```bash
    PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py -v --tb=short
    ```

    Verify all 29 tests pass:
    - TestProviderFailover (5 tests)
    - TestTokenStreaming (5 tests)
    - TestCostOptimization (4 tests)
    - TestMultiProviderRouting (4 tests)
    - TestEdgeCases (5 tests)
    - TestProviderSelection (4 tests)

    Total should be: 29 passed (16 currently passing + 13 fixed)

    If any fail, debug and fix.
  </action>
  <verify>
    PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py -v
    Expected: 29 passed
  </verify>
  <done>29/29 tests passing (100% pass rate)</done>
</task>

</tasks>

<verification>
Run full test suite to verify fixes:
```bash
PYTHONPATH=/Users/rushiparikh/projects/atom/backend pytest backend/tests/unit/test_byok_handler_expanded.py -v
```

Verify:
- [ ] All 29 tests pass
- [ ] No AttributeError: 'BYOKHandler' object has no attribute 'complete_chat'
- [ ] No RuntimeWarning about unawaited coroutines
- [ ] Tests use actual BYOKHandler API
</verification>

<success_criteria>
- 29/29 tests pass (100% pass rate)
- 0 AttributeError on method calls
- 0 RuntimeWarning about coroutines
- Tests match actual BYOKHandler API
</success_criteria>

<output>
After completion, create `.planning/phases/19-coverage-push-and-bug-fixes/19-07-SUMMARY.md` with:
- Number of tests fixed (13)
- API method mapping (what tests called vs actual API)
- Updated pass rate
</output>
