---
phase: 15-codebase-completion
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/api/health_routes.py
  - backend/core/monitoring.py
  - backend/requirements.txt
  - backend/main_api_app.py
autonomous: true

must_haves:
  truths:
    - "Application exposes /health/live endpoint returning 200 when process is alive"
    - "Application exposes /health/ready endpoint returning 200 when dependencies (DB, disk) are accessible"
    - "Health checks return 503 when dependencies are unavailable"
    - "Prometheus metrics endpoint exposes application metrics"
  artifacts:
    - path: "backend/api/health_routes.py"
      provides: "Health check endpoints with liveness and readiness probes"
      exports: ["/health/live", "/health/ready", "/health/metrics"]
    - path: "backend/core/monitoring.py"
      provides: "Prometheus metrics collection and structured logging configuration"
      contains: "prometheus_client"
  key_links:
    - from: "backend/main_api_app.py"
      to: "backend/api/health_routes.py"
      via: "router registration"
      pattern: "app.include_router.*health"
    - from: "backend/api/health_routes.py"
      to: "backend/core/database.py"
      via: "database dependency check"
      pattern: "db.execute\\(text\\(\"SELECT 1\"\\)\\)"
---

<objective>
Implement production monitoring infrastructure with health check endpoints, Prometheus metrics, and structured logging.

Purpose: Production readiness requires observability - health checks for orchestration (Kubernetes/ECS), metrics for monitoring, and structured logs for debugging. Currently zero monitoring infrastructure exists.

Output: Health check endpoints (/health/live, /health/ready), Prometheus metrics endpoint, structured logging configuration.
</objective>

<execution_context>
@/Users/rushiparikh/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rushiparikh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/15-codebase-completion/15-RESEARCH.md
@.planning/ROADMAP.md

# Standard stack from 15-RESEARCH.md
- Prometheus: Metrics collection (industry standard)
- Grafana: Metrics visualization (for dashboards)
- structlog: Structured logging (JSON-formatted)
- psutil: System health monitoring (CPU, memory, disk)

# Patterns from Phase 13-openclaw-integration
- Router registration in main_api_app.py
- Dependency injection for database sessions
- Error handling with HTTPException
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create health check endpoints with dependency verification</name>
  <files>backend/api/health_routes.py, backend/main_api_app.py</files>
  <action>
    1. Create backend/api/health_routes.py with:
       - GET /health/live: Returns {"status": "alive"} (liveness probe)
       - GET /health/ready: Checks database connectivity and disk space (readiness probe)
       - Database check: Execute "SELECT 1" with timeout
       - Disk check: Verify >1GB free space using psutil
       - Return 503 if any dependency check fails (not 200)
       - Include detailed error messages in 503 response

    2. Register health router in backend/main_api_app.py:
       - Import health_routes router
       - Include with app.include_router(health_routes.router, tags=["Health"])
       - Add to API docs for OpenAPI spec

    3. Add dependencies to backend/requirements.txt:
       - prometheus-client
       - psutil
       - structlog

    Per 15-RESEARCH.md health check pattern:
    - /health/live: App process is alive (no dependency checks)
    - /health/ready: Dependencies accessible (DB, disk space)
    - Use connection timeouts and fail-fast for dependency checks
    - Return 503 if dependencies are down
  </action>
  <verify>
    Command: `cd backend && python -c "from api.health_routes import router; print([r.path for r in router.routes])"`
    Expected: Routes list includes ['/health/live', '/health/ready']
  </verify>
  <done>
    Health check endpoints created and registered in main app
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Prometheus metrics and structured logging</name>
  <files>backend/core/monitoring.py</files>
  <action>
    1. Create backend/core/monitoring.py with:
       - Prometheus metrics initialization (Counter, Histogram, Gauge)
       - Metrics for: HTTP requests, agent executions, skill executions, DB queries
       - Structured logging configuration with structlog
       - JSON log output with processors (timestamp, log_level, logger_name, stack_info)
       - Context binding for request_id, agent_id, skill_id

    2. Implement metrics:
       - http_requests_total: Counter for HTTP requests (method, endpoint, status)
       - agent_executions_total: Counter for agent runs (agent_id, status)
       - skill_executions_total: Counter for skill runs (skill_id, status)
       - db_query_duration_seconds: Histogram for DB query performance
       - active_agents: Gauge for currently running agents

    3. Configure structlog:
       - Processors: filter_by_level, add_logger_name, add_log_level, TimeStamper, JSONRenderer
       - Output format: JSON (machine-readable)
       - Context class: dict (for context binding)

    4. Add GET /health/metrics endpoint in health_routes.py:
       - Expose Prometheus metrics in text format
       - Use generate_latest() from prometheus_client

    Per 15-RESEARCH.md:
    - Use prometheus_client for metrics (Prometheus ecosystem standard)
    - Use structlog with processors for structured logging
    - JSON output for machine-readable logs
  </action>
  <verify>
    Command: `cd backend && python -c "from core.monitoring import configure_structlog; print('structlog configured')"`
    Expected: No errors, structlog configured successfully
  </verify>
  <done>
    Monitoring module created with Prometheus metrics and structured logging
  </done>
</task>

<task type="auto">
  <name>Task 3: Create monitoring tests and documentation</name>
  <files>backend/tests/test_health_routes.py, backend/docs/MONITORING_SETUP.md, .planning/phases/15-codebase-completion/15-02-SUMMARY.md</files>
  <action>
    1. Create backend/tests/test_health_routes.py with tests:
       - Test /health/live returns 200
       - Test /health/ready returns 200 when dependencies are healthy
       - Test /health/ready returns 503 when database is unavailable
       - Test /health/ready returns 503 when disk space is insufficient
       - Test /health/metrics exposes Prometheus metrics format

    2. Create backend/docs/MONITORING_SETUP.md with:
       - Health check endpoint documentation (/health/live, /health/ready)
       - Prometheus metrics reference (available metrics, labels)
       - Structured logging configuration (processors, output format)
       - Grafana dashboard setup instructions
       - Kubernetes/ECS health check configuration examples

    3. Create SUMMARY.md documenting:
       - Health check endpoints implemented
       - Prometheus metrics exposed
       - Structured logging configured
       - Test coverage for health routes
       - Next steps: API documentation, runbooks
  </action>
  <verify>
    Command: `pytest backend/tests/test_health_routes.py -v`
    Expected: All health route tests pass
  </verify>
  <done>
    Health routes tested, monitoring documentation created, SUMMARY.md complete
  </done>
</task>

</tasks>

<verification>
1. Test health endpoints: `curl http://localhost:8000/health/live` should return 200
2. Test readiness: `curl http://localhost:8000/health/ready` should return 200 with dependency status
3. Test metrics: `curl http://localhost:8000/health/metrics` should return Prometheus text format
4. Verify structlog imports: `python -c "import structlog; print('OK')"`
5. Run tests: `pytest backend/tests/test_health_routes.py -v`
6. Read MONITORING_SETUP.md for documentation completeness
</verification>

<success_criteria>
1. /health/live endpoint returns 200 with {"status": "alive"}
2. /health/ready endpoint checks database and disk space, returns 200 or 503 appropriately
3. /health/metrics endpoint exposes Prometheus metrics
4. Structured logging configured with JSON output and context processors
5. Health routes have test coverage
6. MONITORING_SETUP.md documents setup and usage
</success_criteria>

<output>
After completion, create `.planning/phases/15-codebase-completion/15-02-SUMMARY.md`
</output>
